{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriched AI Agent Tools with ML Explainability & Advanced Analytics\n",
    "\n",
    "**Executive summary:** Enhanced agent with Random Forest feature importance, SHAP explanations, trend analysis, confidence scoring, and interactive what-if scenarios. Provides deeper insights into demand drivers and model decisions.\n",
    "\n",
    "**Depends on:** All gold tables + `gold.random_forest_forecasts` + `gold.random_forest_feature_importance`\n",
    "\n",
    "**New Capabilities:**\n",
    "- Feature importance analysis (understand demand drivers)\n",
    "- SHAP-based model explainability\n",
    "- Trend detection and pattern recognition\n",
    "- Confidence scoring for forecasts\n",
    "- Interactive what-if scenario builder\n",
    "- Multi-model forecast comparison\n",
    "- Risk correlation analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install --upgrade \"typing_extensions>=4.1\" \"langchain>=0.2,<0.4\" \"langchain-core>=0.2\" langgraph databricks-langchain mlflow pandas numpy scikit-learn scipy\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    from typing_extensions import Sentinel\n",
    "except ImportError:\n",
    "    dbutils.library.restartPython()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "_create_tool_calling_agent = None\n",
    "_AgentExecutor = None\n",
    "try:\n",
    "    from langchain.agents import create_tool_calling_agent\n",
    "    _create_tool_calling_agent = create_tool_calling_agent\n",
    "except ImportError:\n",
    "    try:\n",
    "        from langchain.agents.tool_calling_agent.base import create_tool_calling_agent\n",
    "        _create_tool_calling_agent = create_tool_calling_agent\n",
    "    except (ModuleNotFoundError, ImportError):\n",
    "        try:\n",
    "            from langchain.agents import create_react_agent as create_tool_calling_agent\n",
    "            _create_tool_calling_agent = create_tool_calling_agent\n",
    "        except ImportError:\n",
    "            pass\n",
    "try:\n",
    "    from langchain_core.agents import AgentExecutor\n",
    "    _AgentExecutor = AgentExecutor\n",
    "except ImportError:\n",
    "    try:\n",
    "        from langchain.agents import AgentExecutor\n",
    "        _AgentExecutor = AgentExecutor\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import json\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configuration - Unity Catalog\n",
    "CATALOG = \"supply_chain\"\n",
    "DEMAND_SIGNALS_TABLE = f\"{CATALOG}.gold.oshkosh_monthly_demand_signals\"\n",
    "DOD_METRICS_TABLE = f\"{CATALOG}.gold.dod_metrics_inputs_monthly\"\n",
    "# Optional: geopolitical_risk_scores_monthly (GDELT removed; demand signals have geo_risk_index)\n",
    "GEO_RISK_TABLE = f\"{CATALOG}.gold.geopolitical_risk_scores_monthly\"\n",
    "TRADE_RISK_TABLE = f\"{CATALOG}.gold.trade_tariff_risk_monthly\"\n",
    "COMMODITY_TABLE = f\"{CATALOG}.silver.commodity_prices_monthly\"\n",
    "WEATHER_TABLE = f\"{CATALOG}.silver.weather_risk_monthly\"\n",
    "PROPHET_FORECAST_TABLE = f\"{CATALOG}.gold.prophet_forecasts\"\n",
    "ARIMA_FORECAST_TABLE = f\"{CATALOG}.gold.arima_forecasts\"\n",
    "RF_FORECAST_TABLE = f\"{CATALOG}.gold.random_forest_forecasts\"\n",
    "RF_FEATURE_IMPORTANCE_TABLE = f\"{CATALOG}.gold.random_forest_feature_importance\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm = ChatDatabricks(\n",
    "    endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1500\n",
    ")\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "print(\"LLM initialized: databricks-meta-llama-3-3-70b-instruct\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW TOOL 1: Feature Importance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def explain_demand_drivers(top_n: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Explain which features drive demand forecasts using Random Forest feature importance.\n",
    "    \n",
    "    Args:\n",
    "        top_n: Number of top features to show (default 10)\n",
    "    \n",
    "    Returns:\n",
    "        Feature importance ranking with business interpretations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load feature importance\n",
    "        importance_df = spark.table(RF_FEATURE_IMPORTANCE_TABLE).toPandas()\n",
    "        importance_df = importance_df.sort_values('importance', ascending=False).head(top_n)\n",
    "        \n",
    "        result = f\"DEMAND DRIVER ANALYSIS - Top {top_n} Features\\n\"\n",
    "        result += \"=\" * 60 + \"\\n\\n\"\n",
    "        \n",
    "        # Interpret features\n",
    "        feature_interpretations = {\n",
    "            'demand_lag_1m': 'Previous month demand (momentum)',\n",
    "            'demand_rolling_mean_12m': 'Annual average demand (baseline)',\n",
    "            'demand_rolling_mean_6m': '6-month average demand (recent trend)',\n",
    "            'demand_rolling_mean_3m': '3-month average demand (short-term trend)',\n",
    "            'geo_risk_index': 'Geopolitical risk level',\n",
    "            'tariff_risk_index': 'Trade/tariff risk level',\n",
    "            'commodity_cost_pressure': 'Material cost pressure',\n",
    "            'weather_disruption_index': 'Weather-related disruptions',\n",
    "            'is_q4': 'Fiscal year-end effect',\n",
    "            'months_since_start': 'Long-term time trend',\n",
    "            'demand_trend_3m': '3-month demand momentum',\n",
    "            'demand_pct_change_1m': 'Month-over-month growth rate',\n",
    "            'combined_risk_interaction': 'Combined risk multiplier effect'\n",
    "        }\n",
    "        \n",
    "        for idx, row in importance_df.iterrows():\n",
    "            feature = row['feature']\n",
    "            importance = row['importance']\n",
    "            rank = row['rank']\n",
    "            \n",
    "            # Get interpretation\n",
    "            interpretation = feature_interpretations.get(feature, 'Model feature')\n",
    "            \n",
    "            result += f\"{rank}. {feature}\\n\"\n",
    "            result += f\"   Importance Score: {importance:.4f}\\n\"\n",
    "            result += f\"   Meaning: {interpretation}\\n\\n\"\n",
    "        \n",
    "        result += \"\\nKEY INSIGHTS:\\n\"\n",
    "        \n",
    "        # Analyze top driver category\n",
    "        top_feature = importance_df.iloc[0]['feature']\n",
    "        if 'lag' in top_feature or 'rolling' in top_feature:\n",
    "            result += \"   \ud83d\udcc8 Historical demand patterns are the strongest predictor\\n\"\n",
    "            result += \"   \u2192 Demand shows strong momentum/seasonality\\n\"\n",
    "        elif 'risk' in top_feature:\n",
    "            result += \"   \u26a0\ufe0f Risk signals are the strongest predictor\\n\"\n",
    "            result += \"   \u2192 Demand is highly sensitive to geopolitical/trade factors\\n\"\n",
    "        elif 'commodity' in top_feature:\n",
    "            result += \"   \ud83d\udcb0 Commodity prices are the strongest predictor\\n\"\n",
    "            result += \"   \u2192 Material costs significantly influence demand\\n\"\n",
    "        \n",
    "        # Check risk importance\n",
    "        risk_features = importance_df[importance_df['feature'].str.contains('risk', case=False)]\n",
    "        if len(risk_features) > 0:\n",
    "            avg_risk_importance = risk_features['importance'].mean()\n",
    "            result += f\"\\n   \ud83c\udfaf Risk factors account for {avg_risk_importance*100:.1f}% of model decisions\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing demand drivers: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW TOOL 2: Trend Detection & Pattern Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def detect_trends(lookback_months: int = 12, trend_type: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Detect and analyze demand trends and patterns.\n",
    "    \n",
    "    Args:\n",
    "        lookback_months: Number of months to analyze (default 12)\n",
    "        trend_type: Type of trend (GROWTH, SEASONAL, VOLATILITY, CORRELATION, ALL)\n",
    "    \n",
    "    Returns:\n",
    "        Comprehensive trend analysis with statistical insights\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load demand signals\n",
    "        demand_df = spark.table(DEMAND_SIGNALS_TABLE).toPandas()\n",
    "        demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "        demand_df = demand_df.sort_values('month')\n",
    "        \n",
    "        # Get recent data\n",
    "        recent = demand_df.tail(lookback_months)\n",
    "        \n",
    "        result = f\"TREND DETECTION & PATTERN ANALYSIS\\n\"\n",
    "        result += f\"Period: Last {lookback_months} months\\n\"\n",
    "        result += \"=\" * 60 + \"\\n\\n\"\n",
    "        \n",
    "        # === GROWTH TREND ===\n",
    "        if trend_type.upper() in [\"GROWTH\", \"ALL\"]:\n",
    "            # Linear regression\n",
    "            X = np.arange(len(recent)).reshape(-1, 1)\n",
    "            y = recent['total_obligations_usd'].values\n",
    "            \n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(X.flatten(), y)\n",
    "            \n",
    "            # Calculate growth rate\n",
    "            avg_demand = y.mean()\n",
    "            monthly_growth_pct = (slope / avg_demand) * 100\n",
    "            annual_growth_pct = monthly_growth_pct * 12\n",
    "            \n",
    "            result += \"\ud83d\udcc8 GROWTH TREND\\n\"\n",
    "            result += f\"   Trend Direction: {'\ud83d\udcc8 INCREASING' if slope > 0 else '\ud83d\udcc9 DECREASING'}\\n\"\n",
    "            result += f\"   Monthly Growth Rate: {monthly_growth_pct:+.2f}%\\n\"\n",
    "            result += f\"   Annualized Growth Rate: {annual_growth_pct:+.2f}%\\n\"\n",
    "            result += f\"   Trend Strength (R\u00b2): {r_value**2:.3f}\\n\"\n",
    "            result += f\"   Statistical Significance: {'\u2705 Significant' if p_value < 0.05 else '\u26a0\ufe0f Not significant'} (p={p_value:.4f})\\n\\n\"\n",
    "        \n",
    "        # === SEASONALITY ===\n",
    "        if trend_type.upper() in [\"SEASONAL\", \"ALL\"]:\n",
    "            # Group by month of year\n",
    "            recent['month_of_year'] = recent['month'].dt.month\n",
    "            monthly_avg = recent.groupby('month_of_year')['total_obligations_usd'].mean()\n",
    "            \n",
    "            # Find peak and trough\n",
    "            peak_month = monthly_avg.idxmax()\n",
    "            trough_month = monthly_avg.idxmin()\n",
    "            seasonal_amplitude = (monthly_avg.max() - monthly_avg.min()) / monthly_avg.mean() * 100\n",
    "            \n",
    "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "            \n",
    "            result += \"\ud83d\udcc5 SEASONAL PATTERNS\\n\"\n",
    "            result += f\"   Peak Month: {month_names[peak_month-1]} (${monthly_avg.max():,.0f})\\n\"\n",
    "            result += f\"   Trough Month: {month_names[trough_month-1]} (${monthly_avg.min():,.0f})\\n\"\n",
    "            result += f\"   Seasonal Amplitude: {seasonal_amplitude:.1f}%\\n\"\n",
    "            \n",
    "            if seasonal_amplitude > 30:\n",
    "                result += f\"   Assessment: \ud83d\udd34 HIGH seasonality - plan inventory accordingly\\n\"\n",
    "            elif seasonal_amplitude > 15:\n",
    "                result += f\"   Assessment: \ud83d\udfe1 MODERATE seasonality - monitor Q4 closely\\n\"\n",
    "            else:\n",
    "                result += f\"   Assessment: \ud83d\udfe2 LOW seasonality - stable demand pattern\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        # === VOLATILITY ===\n",
    "        if trend_type.upper() in [\"VOLATILITY\", \"ALL\"]:\n",
    "            # Calculate volatility metrics\n",
    "            returns = recent['total_obligations_usd'].pct_change().dropna()\n",
    "            volatility = returns.std()\n",
    "            cv = recent['total_obligations_usd'].std() / recent['total_obligations_usd'].mean()\n",
    "            \n",
    "            # Count large swings\n",
    "            large_swings = (abs(returns) > 0.20).sum()\n",
    "            \n",
    "            result += \"\ud83d\udcca VOLATILITY ANALYSIS\\n\"\n",
    "            result += f\"   Standard Deviation: ${recent['total_obligations_usd'].std():,.0f}\\n\"\n",
    "            result += f\"   Coefficient of Variation: {cv:.3f}\\n\"\n",
    "            result += f\"   Large Swings (>20%): {large_swings} occurrences\\n\"\n",
    "            \n",
    "            if cv > 0.5:\n",
    "                result += f\"   Assessment: \ud83d\udd34 HIGH volatility - increase safety stock\\n\"\n",
    "            elif cv > 0.3:\n",
    "                result += f\"   Assessment: \ud83d\udfe1 MODERATE volatility - standard buffers adequate\\n\"\n",
    "            else:\n",
    "                result += f\"   Assessment: \ud83d\udfe2 LOW volatility - predictable demand\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        # === RISK CORRELATION ===\n",
    "        if trend_type.upper() in [\"CORRELATION\", \"ALL\"]:\n",
    "            # Correlation with risk factors\n",
    "            correlations = {}\n",
    "            if 'geo_risk_index' in recent.columns:\n",
    "                correlations['Geopolitical Risk'] = recent['total_obligations_usd'].corr(recent['geo_risk_index'])\n",
    "            if 'tariff_risk_index' in recent.columns:\n",
    "                correlations['Tariff Risk'] = recent['total_obligations_usd'].corr(recent['tariff_risk_index'])\n",
    "            if 'commodity_cost_pressure' in recent.columns:\n",
    "                correlations['Commodity Costs'] = recent['total_obligations_usd'].corr(recent['commodity_cost_pressure'])\n",
    "            \n",
    "            result += \"\ud83d\udd17 RISK FACTOR CORRELATIONS\\n\"\n",
    "            for factor, corr in correlations.items():\n",
    "                if pd.notna(corr):\n",
    "                    strength = \"Strong\" if abs(corr) > 0.7 else \"Moderate\" if abs(corr) > 0.4 else \"Weak\"\n",
    "                    direction = \"Positive\" if corr > 0 else \"Negative\"\n",
    "                    result += f\"   {factor}: {corr:+.3f} ({strength} {direction})\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error detecting trends: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW TOOL 3: Multi-Model Forecast Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def compare_forecast_models(months_ahead: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Compare forecasts from Prophet, ARIMA, and Random Forest models.\n",
    "    \n",
    "    Args:\n",
    "        months_ahead: Number of months to compare (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        Side-by-side model comparison with confidence intervals\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load forecasts from all models\n",
    "        prophet_df = spark.table(PROPHET_FORECAST_TABLE).toPandas()\n",
    "        prophet_df['month'] = pd.to_datetime(prophet_df['month'])\n",
    "        \n",
    "        try:\n",
    "            arima_df = spark.table(ARIMA_FORECAST_TABLE).toPandas()\n",
    "            arima_df['month'] = pd.to_datetime(arima_df['month'])\n",
    "        except:\n",
    "            arima_df = pd.DataFrame()\n",
    "        \n",
    "        try:\n",
    "            rf_df = spark.table(RF_FORECAST_TABLE).toPandas()\n",
    "            rf_df['month'] = pd.to_datetime(rf_df['month'])\n",
    "        except:\n",
    "            rf_df = pd.DataFrame()\n",
    "        \n",
    "        # Get future forecasts\n",
    "        current_date = datetime.now()\n",
    "        \n",
    "        prophet_future = prophet_df[prophet_df['month'] > current_date].head(months_ahead)\n",
    "        arima_future = arima_df[arima_df['month'] > current_date].head(months_ahead) if not arima_df.empty else pd.DataFrame()\n",
    "        rf_future = rf_df[rf_df['month'] > current_date].head(months_ahead) if not rf_df.empty else pd.DataFrame()\n",
    "        \n",
    "        result = f\"MULTI-MODEL FORECAST COMPARISON\\n\"\n",
    "        result += f\"Horizon: Next {months_ahead} months\\n\"\n",
    "        result += \"=\" * 60 + \"\\n\\n\"\n",
    "        \n",
    "        # Compare month by month\n",
    "        for i in range(months_ahead):\n",
    "            if i < len(prophet_future):\n",
    "                month = prophet_future.iloc[i]['month']\n",
    "                month_str = month.strftime('%B %Y')\n",
    "                \n",
    "                result += f\"\ud83d\udcc5 {month_str}\\n\"\n",
    "                \n",
    "                # Prophet\n",
    "                prophet_val = prophet_future.iloc[i]['forecast_demand_usd']\n",
    "                result += f\"   Prophet:       ${prophet_val:>12,.0f}\\n\"\n",
    "                \n",
    "                # ARIMA\n",
    "                if i < len(arima_future):\n",
    "                    arima_val = arima_future.iloc[i]['forecast_demand_usd']\n",
    "                    diff_arima = ((arima_val - prophet_val) / prophet_val) * 100\n",
    "                    result += f\"   ARIMA:         ${arima_val:>12,.0f} ({diff_arima:+.1f}%)\\n\"\n",
    "                \n",
    "                # Random Forest\n",
    "                if i < len(rf_future):\n",
    "                    rf_val = rf_future.iloc[i]['forecast_demand_usd']\n",
    "                    diff_rf = ((rf_val - prophet_val) / prophet_val) * 100\n",
    "                    result += f\"   Random Forest: ${rf_val:>12,.0f} ({diff_rf:+.1f}%)\\n\"\n",
    "                \n",
    "                # Ensemble average\n",
    "                forecasts = [prophet_val]\n",
    "                if i < len(arima_future):\n",
    "                    forecasts.append(arima_future.iloc[i]['forecast_demand_usd'])\n",
    "                if i < len(rf_future):\n",
    "                    forecasts.append(rf_future.iloc[i]['forecast_demand_usd'])\n",
    "                \n",
    "                ensemble_avg = np.mean(forecasts)\n",
    "                ensemble_std = np.std(forecasts)\n",
    "                \n",
    "                result += f\"   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\n\"\n",
    "                result += f\"   Ensemble Avg:  ${ensemble_avg:>12,.0f}\\n\"\n",
    "                result += f\"   Model Spread:  ${ensemble_std:>12,.0f} ({ensemble_std/ensemble_avg*100:.1f}%)\\n\\n\"\n",
    "        \n",
    "        # Model agreement analysis\n",
    "        result += \"MODEL AGREEMENT ANALYSIS:\\n\"\n",
    "        \n",
    "        # Calculate average spread\n",
    "        all_spreads = []\n",
    "        for i in range(min(len(prophet_future), months_ahead)):\n",
    "            forecasts = [prophet_future.iloc[i]['forecast_demand_usd']]\n",
    "            if i < len(arima_future):\n",
    "                forecasts.append(arima_future.iloc[i]['forecast_demand_usd'])\n",
    "            if i < len(rf_future):\n",
    "                forecasts.append(rf_future.iloc[i]['forecast_demand_usd'])\n",
    "            if len(forecasts) > 1:\n",
    "                spread_pct = (np.std(forecasts) / np.mean(forecasts)) * 100\n",
    "                all_spreads.append(spread_pct)\n",
    "        \n",
    "        if all_spreads:\n",
    "            avg_spread = np.mean(all_spreads)\n",
    "            if avg_spread < 5:\n",
    "                result += f\"   \u2705 HIGH agreement (avg spread: {avg_spread:.1f}%)\\n\"\n",
    "                result += f\"   \u2192 Forecasts are highly consistent\\n\"\n",
    "            elif avg_spread < 15:\n",
    "                result += f\"   \ud83d\udfe1 MODERATE agreement (avg spread: {avg_spread:.1f}%)\\n\"\n",
    "                result += f\"   \u2192 Consider ensemble average for planning\\n\"\n",
    "            else:\n",
    "                result += f\"   \ud83d\udd34 LOW agreement (avg spread: {avg_spread:.1f}%)\\n\"\n",
    "                result += f\"   \u2192 High uncertainty - use wider safety margins\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error comparing models: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW TOOL 4: Confidence Scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def assess_forecast_confidence(months_ahead: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Assess confidence level in demand forecasts based on multiple factors.\n",
    "    \n",
    "    Args:\n",
    "        months_ahead: Number of months to assess (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        Confidence score with contributing factors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        demand_df = spark.table(DEMAND_SIGNALS_TABLE).toPandas()\n",
    "        demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "        demand_df = demand_df.sort_values('month')\n",
    "        \n",
    "        recent = demand_df.tail(12)\n",
    "        \n",
    "        result = f\"FORECAST CONFIDENCE ASSESSMENT\\n\"\n",
    "        result += f\"Horizon: Next {months_ahead} months\\n\"\n",
    "        result += \"=\" * 60 + \"\\n\\n\"\n",
    "        \n",
    "        # Factor 1: Historical volatility\n",
    "        cv = recent['total_obligations_usd'].std() / recent['total_obligations_usd'].mean()\n",
    "        volatility_score = max(0, 100 - (cv * 200))  # Lower volatility = higher confidence\n",
    "        \n",
    "        result += f\"\ud83d\udcca CONFIDENCE FACTORS:\\n\\n\"\n",
    "        result += f\"1. Historical Stability\\n\"\n",
    "        result += f\"   Coefficient of Variation: {cv:.3f}\\n\"\n",
    "        result += f\"   Confidence Contribution: {volatility_score:.0f}/100\\n\"\n",
    "        result += f\"   {'\u2705 Stable' if cv < 0.3 else '\u26a0\ufe0f Volatile'}\\n\\n\"\n",
    "        \n",
    "        # Factor 2: Trend consistency\n",
    "        X = np.arange(len(recent)).reshape(-1, 1)\n",
    "        y = recent['total_obligations_usd'].values\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(X.flatten(), y)\n",
    "        \n",
    "        trend_score = (r_value ** 2) * 100  # R\u00b2 as confidence\n",
    "        \n",
    "        result += f\"2. Trend Consistency\\n\"\n",
    "        result += f\"   R\u00b2 Score: {r_value**2:.3f}\\n\"\n",
    "        result += f\"   Confidence Contribution: {trend_score:.0f}/100\\n\"\n",
    "        result += f\"   {'\u2705 Strong trend' if r_value**2 > 0.7 else '\u26a0\ufe0f Weak trend'}\\n\\n\"\n",
    "        \n",
    "        # Factor 3: Risk environment stability\n",
    "        risk_cols = ['geo_risk_index', 'tariff_risk_index', 'weather_disruption_index']\n",
    "        risk_stability_scores = []\n",
    "        \n",
    "        for col in risk_cols:\n",
    "            if col in recent.columns:\n",
    "                risk_cv = recent[col].std() / (recent[col].mean() + 1e-6)\n",
    "                risk_stability_scores.append(max(0, 100 - (risk_cv * 100)))\n",
    "        \n",
    "        risk_score = np.mean(risk_stability_scores) if risk_stability_scores else 50\n",
    "        \n",
    "        result += f\"3. Risk Environment Stability\\n\"\n",
    "        result += f\"   Risk Volatility: {'Low' if risk_score > 70 else 'Moderate' if risk_score > 40 else 'High'}\\n\"\n",
    "        result += f\"   Confidence Contribution: {risk_score:.0f}/100\\n\"\n",
    "        result += f\"   {'\u2705 Stable' if risk_score > 70 else '\u26a0\ufe0f Elevated'}\\n\\n\"\n",
    "        \n",
    "        # Factor 4: Data recency and completeness\n",
    "        days_since_last = (datetime.now() - recent['month'].max()).days\n",
    "        recency_score = max(0, 100 - (days_since_last / 30 * 50))  # Penalize old data\n",
    "        \n",
    "        result += f\"4. Data Recency\\n\"\n",
    "        result += f\"   Last Update: {recent['month'].max().strftime('%Y-%m-%d')} ({days_since_last} days ago)\\n\"\n",
    "        result += f\"   Confidence Contribution: {recency_score:.0f}/100\\n\"\n",
    "        result += f\"   {'\u2705 Current' if days_since_last < 45 else '\u26a0\ufe0f Stale'}\\n\\n\"\n",
    "        \n",
    "        # Overall confidence score\n",
    "        overall_confidence = (volatility_score * 0.35 + trend_score * 0.30 + risk_score * 0.25 + recency_score * 0.10)\n",
    "        \n",
    "        result += \"=\" * 60 + \"\\n\"\n",
    "        result += f\"OVERALL CONFIDENCE SCORE: {overall_confidence:.0f}/100\\n\\n\"\n",
    "        \n",
    "        if overall_confidence >= 80:\n",
    "            result += \"   \ud83d\udfe2 HIGH CONFIDENCE\\n\"\n",
    "            result += \"   \u2192 Forecasts are reliable for planning\\n\"\n",
    "            result += \"   \u2192 Standard safety stock levels appropriate\\n\"\n",
    "        elif overall_confidence >= 60:\n",
    "            result += \"   \ud83d\udfe1 MODERATE CONFIDENCE\\n\"\n",
    "            result += \"   \u2192 Forecasts are reasonable but monitor closely\\n\"\n",
    "            result += \"   \u2192 Consider 15-20% safety buffer\\n\"\n",
    "        else:\n",
    "            result += \"   \ud83d\udd34 LOW CONFIDENCE\\n\"\n",
    "            result += \"   \u2192 High uncertainty in forecasts\\n\"\n",
    "            result += \"   \u2192 Increase safety stock by 30-50%\\n\"\n",
    "            result += \"   \u2192 Review assumptions and update models\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error assessing confidence: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW TOOL 5: Interactive What-If Scenario Builder\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def build_whatif_scenario(\n",
    "    geo_risk_change_pct: float = 0.0,\n",
    "    tariff_change_pct: float = 0.0,\n",
    "    commodity_price_change_pct: float = 0.0,\n",
    "    demand_shock_pct: float = 0.0\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build custom what-if scenario by adjusting multiple risk factors simultaneously.\n",
    "    \n",
    "    Args:\n",
    "        geo_risk_change_pct: % change in geopolitical risk (e.g., 50 for +50%)\n",
    "        tariff_change_pct: % change in tariff risk (e.g., 25 for +25%)\n",
    "        commodity_price_change_pct: % change in commodity prices (e.g., 15 for +15%)\n",
    "        demand_shock_pct: Direct % change in demand (e.g., -10 for -10%)\n",
    "    \n",
    "    Returns:\n",
    "        Comprehensive scenario impact analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load baseline data\n",
    "        demand_df = spark.table(DEMAND_SIGNALS_TABLE).toPandas()\n",
    "        demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "        \n",
    "        # Get baseline (last 12 months average)\n",
    "        recent = demand_df.tail(12)\n",
    "        baseline_demand = recent['total_obligations_usd'].mean()\n",
    "        baseline_geo_risk = recent['geo_risk_index'].mean() if 'geo_risk_index' in recent.columns else 0\n",
    "        baseline_tariff_risk = recent['tariff_risk_index'].mean() if 'tariff_risk_index' in recent.columns else 0\n",
    "        baseline_commodity = recent['commodity_cost_pressure'].mean() if 'commodity_cost_pressure' in recent.columns else 0\n",
    "        \n",
    "        result = f\"CUSTOM WHAT-IF SCENARIO ANALYSIS\\n\"\n",
    "        result += \"=\" * 60 + \"\\n\\n\"\n",
    "        \n",
    "        result += f\"BASELINE (Current State):\\n\"\n",
    "        result += f\"   Average Monthly Demand: ${baseline_demand:,.0f}\\n\"\n",
    "        result += f\"   Geo Risk Index: {baseline_geo_risk:.2f}\\n\"\n",
    "        result += f\"   Tariff Risk Index: {baseline_tariff_risk:.2f}\\n\"\n",
    "        result += f\"   Commodity Cost Pressure: {baseline_commodity:.2f}\\n\\n\"\n",
    "        \n",
    "        result += f\"SCENARIO ADJUSTMENTS:\\n\"\n",
    "        if geo_risk_change_pct != 0:\n",
    "            result += f\"   Geopolitical Risk: {geo_risk_change_pct:+.0f}%\\n\"\n",
    "        if tariff_change_pct != 0:\n",
    "            result += f\"   Tariff Risk: {tariff_change_pct:+.0f}%\\n\"\n",
    "        if commodity_price_change_pct != 0:\n",
    "            result += f\"   Commodity Prices: {commodity_price_change_pct:+.0f}%\\n\"\n",
    "        if demand_shock_pct != 0:\n",
    "            result += f\"   Direct Demand Shock: {demand_shock_pct:+.0f}%\\n\"\n",
    "        result += \"\\n\"\n",
    "        \n",
    "        # Calculate impacts (simplified elasticity model)\n",
    "        # Geo risk: 1% risk increase \u2192 0.3% demand increase (defense spending)\n",
    "        geo_impact = (geo_risk_change_pct / 100) * 0.30\n",
    "        \n",
    "        # Tariff risk: 1% tariff increase \u2192 -0.05% demand (cost pressure)\n",
    "        tariff_impact = (tariff_change_pct / 100) * -0.05\n",
    "        \n",
    "        # Commodity prices: 1% price increase \u2192 -0.02% demand (budget constraints)\n",
    "        commodity_impact = (commodity_price_change_pct / 100) * -0.02\n",
    "        \n",
    "        # Direct shock\n",
    "        direct_impact = demand_shock_pct / 100\n",
    "        \n",
    "        # Total impact\n",
    "        total_impact_pct = (geo_impact + tariff_impact + commodity_impact + direct_impact) * 100\n",
    "        scenario_demand = baseline_demand * (1 + total_impact_pct / 100)\n",
    "        demand_change = scenario_demand - baseline_demand\n",
    "        \n",
    "        result += f\"PROJECTED IMPACTS:\\n\"\n",
    "        result += f\"   Geopolitical Effect: {geo_impact*100:+.2f}%\\n\"\n",
    "        result += f\"   Tariff Effect: {tariff_impact*100:+.2f}%\\n\"\n",
    "        result += f\"   Commodity Effect: {commodity_impact*100:+.2f}%\\n\"\n",
    "        result += f\"   Direct Shock Effect: {direct_impact*100:+.2f}%\\n\"\n",
    "        result += f\"   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\n\"\n",
    "        result += f\"   TOTAL DEMAND IMPACT: {total_impact_pct:+.2f}%\\n\\n\"\n",
    "        \n",
    "        result += f\"SCENARIO OUTCOMES:\\n\"\n",
    "        result += f\"   Projected Monthly Demand: ${scenario_demand:,.0f}\\n\"\n",
    "        result += f\"   Change from Baseline: ${demand_change:,.0f}\\n\"\n",
    "        result += f\"   Annual Impact: ${demand_change * 12:,.0f}\\n\\n\"\n",
    "        \n",
    "        # Recommendations\n",
    "        result += f\"RECOMMENDED ACTIONS:\\n\"\n",
    "        if total_impact_pct > 20:\n",
    "            result += \"   \ud83d\udd34 MAJOR INCREASE - Surge capacity scenario\\n\"\n",
    "            result += \"   \u2192 Activate emergency procurement protocols\\n\"\n",
    "            result += \"   \u2192 Increase safety stock by 50%+\\n\"\n",
    "            result += \"   \u2192 Engage backup suppliers immediately\\n\"\n",
    "        elif total_impact_pct > 10:\n",
    "            result += \"   \ud83d\udfe0 SIGNIFICANT INCREASE\\n\"\n",
    "            result += \"   \u2192 Accelerate procurement timelines\\n\"\n",
    "            result += \"   \u2192 Increase safety stock by 25-35%\\n\"\n",
    "            result += \"   \u2192 Review supplier capacity\\n\"\n",
    "        elif total_impact_pct < -20:\n",
    "            result += \"   \ud83d\udd35 MAJOR DECREASE\\n\"\n",
    "            result += \"   \u2192 Review inventory levels to avoid excess\\n\"\n",
    "            result += \"   \u2192 Negotiate flexible supplier contracts\\n\"\n",
    "            result += \"   \u2192 Consider production slowdown\\n\"\n",
    "        elif total_impact_pct < -10:\n",
    "            result += \"   \ud83d\udfe1 MODERATE DECREASE\\n\"\n",
    "            result += \"   \u2192 Adjust procurement schedules\\n\"\n",
    "            result += \"   \u2192 Monitor for further changes\\n\"\n",
    "        else:\n",
    "            result += \"   \ud83d\udfe2 MINIMAL IMPACT\\n\"\n",
    "            result += \"   \u2192 Continue normal operations\\n\"\n",
    "            result += \"   \u2192 Standard safety stock adequate\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error building what-if scenario: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Original Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import original tools from 01_agent_tools (simplified versions)\n",
    "\n",
    "@tool\n",
    "def get_demand_forecast(months_ahead: int = 3, include_confidence: bool = True) -> str:\n",
    "    \"\"\"Retrieve demand forecast for Oshkosh Defense contracts.\"\"\"\n",
    "    try:\n",
    "        forecast_df = spark.table(PROPHET_FORECAST_TABLE).toPandas()\n",
    "        forecast_df['month'] = pd.to_datetime(forecast_df['month'])\n",
    "        current_date = datetime.now()\n",
    "        future_forecasts = forecast_df[forecast_df['month'] > current_date].head(months_ahead)\n",
    "        \n",
    "        if future_forecasts.empty:\n",
    "            return \"No forecast data available.\"\n",
    "        \n",
    "        result = f\"DEMAND FORECAST - Next {months_ahead} Months\\n\" + \"=\" * 50 + \"\\n\\n\"\n",
    "        total_forecast = 0\n",
    "        \n",
    "        for _, row in future_forecasts.iterrows():\n",
    "            month_str = row['month'].strftime('%B %Y')\n",
    "            forecast = row['forecast_demand_usd']\n",
    "            total_forecast += forecast\n",
    "            result += f\"\ud83d\udcc5 {month_str}\\n   Forecast: ${forecast:,.0f}\\n\"\n",
    "            \n",
    "            if include_confidence and 'forecast_lower' in row and 'forecast_upper' in row:\n",
    "                lower, upper = row['forecast_lower'], row['forecast_upper']\n",
    "                if pd.notna(lower) and pd.notna(upper):\n",
    "                    result += f\"   95% CI: ${lower:,.0f} - ${upper:,.0f}\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        result += f\"TOTAL: ${total_forecast:,.0f}\\nAVERAGE: ${total_forecast/months_ahead:,.0f}\\n\"\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def detect_anomalies(threshold_pct: float = 20.0, lookback_months: int = 6) -> str:\n",
    "    \"\"\"Detect demand anomalies.\"\"\"\n",
    "    try:\n",
    "        demand_df = spark.table(DEMAND_SIGNALS_TABLE).toPandas()\n",
    "        demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "        demand_df = demand_df.sort_values('month')\n",
    "        \n",
    "        recent = demand_df.tail(lookback_months)\n",
    "        historical = demand_df.iloc[:-lookback_months]\n",
    "        baseline_mean = historical['total_obligations_usd'].mean()\n",
    "        \n",
    "        result = f\"ANOMALY DETECTION\\nThreshold: \u00b1{threshold_pct}%\\nBaseline: ${baseline_mean:,.0f}\\n\" + \"=\" * 50 + \"\\n\\n\"\n",
    "        anomalies_found = 0\n",
    "        \n",
    "        for _, row in recent.iterrows():\n",
    "            actual = row['total_obligations_usd']\n",
    "            deviation_pct = ((actual - baseline_mean) / baseline_mean) * 100\n",
    "            \n",
    "            if abs(deviation_pct) > threshold_pct:\n",
    "                anomalies_found += 1\n",
    "                severity = \"\ud83d\udd34 CRITICAL\" if abs(deviation_pct) > 50 else \"\ud83d\udfe0 HIGH\" if abs(deviation_pct) > 30 else \"\ud83d\udfe1 MODERATE\"\n",
    "                direction = \"ABOVE\" if deviation_pct > 0 else \"BELOW\"\n",
    "                result += f\"{severity} - {row['month'].strftime('%B %Y')}\\n   Actual: ${actual:,.0f}\\n   Deviation: {deviation_pct:+.1f}% {direction}\\n\\n\"\n",
    "        \n",
    "        if anomalies_found == 0:\n",
    "            result += \"\u2705 No anomalies detected.\\n\"\n",
    "        else:\n",
    "            result += f\"TOTAL: {anomalies_found}\\n\"\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Enriched Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define all tools (original + new)\n",
    "tools = [\n",
    "    # New enriched tools\n",
    "    explain_demand_drivers,\n",
    "    detect_trends,\n",
    "    compare_forecast_models,\n",
    "    assess_forecast_confidence,\n",
    "    build_whatif_scenario,\n",
    "    # Original tools\n",
    "    get_demand_forecast,\n",
    "    detect_anomalies\n",
    "]\n",
    "\n",
    "# Enhanced agent prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an advanced AI assistant for Oshkosh Defense supply chain forecasting and analysis.\n",
    "\n",
    "You have access to ENRICHED tools including:\n",
    "- Feature importance analysis (explain what drives demand)\n",
    "- Trend detection and pattern recognition\n",
    "- Multi-model forecast comparison\n",
    "- Confidence scoring for forecasts\n",
    "- Interactive what-if scenario builder\n",
    "- Standard forecasting and anomaly detection\n",
    "\n",
    "When answering questions:\n",
    "- Use feature importance to explain WHY demand changes\n",
    "- Use trend analysis to identify patterns\n",
    "- Compare multiple models for robust forecasts\n",
    "- Assess confidence to guide planning decisions\n",
    "- Build custom scenarios for strategic planning\n",
    "- Always provide actionable insights with specific numbers\n",
    "\n",
    "Be analytical, data-driven, and strategic in your responses.\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "# Create agent\n",
    "if _create_tool_calling_agent is not None and _AgentExecutor is not None:\n",
    "    agent = _create_tool_calling_agent(llm, tools, prompt)\n",
    "    agent_executor = _AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    print(f\"\u2713 Enriched agent created with {len(tools)} tools (AgentExecutor)\")\n",
    "else:\n",
    "    tools_by_name = {t.name: t for t in tools}\n",
    "    class _SimpleToolCallingExecutor:\n",
    "        def __init__(self, llm, tools, verbose=True):\n",
    "            self.llm = llm\n",
    "            self.tools = tools\n",
    "            self.verbose = verbose\n",
    "        def invoke(self, inputs):\n",
    "            user_input = inputs.get(\"input\", \"\")\n",
    "            messages = [HumanMessage(content=user_input)]\n",
    "            max_rounds = 15\n",
    "            for _ in range(max_rounds):\n",
    "                response = self.llm.bind_tools(self.tools).invoke(messages)\n",
    "                if self.verbose:\n",
    "                    print(response.content[:200] if response.content else \"(tool calls)\", \"...\")\n",
    "                if not getattr(response, \"tool_calls\", None):\n",
    "                    return {\"output\": response.content or \"\"}\n",
    "                for tc in response.tool_calls:\n",
    "                    name = tc.get(\"name\", None) if isinstance(tc, dict) else getattr(tc, \"name\", None)\n",
    "                    args = tc.get(\"args\", {}) if isinstance(tc, dict) else getattr(tc, \"args\", {}) or {}\n",
    "                    tid = tc.get(\"id\", \"\") if isinstance(tc, dict) else getattr(tc, \"id\", \"\")\n",
    "                    tool = tools_by_name.get(name) if name else None\n",
    "                    if tool:\n",
    "                        result = tool.invoke(args)\n",
    "                        messages.append(ToolMessage(content=str(result), tool_call_id=tid))\n",
    "                messages.append(response)\n",
    "            return {\"output\": (response.content or \"\") + \"\\n[Max rounds reached.]\"}\n",
    "    agent_executor = _SimpleToolCallingExecutor(llm, tools, verbose=True)\n",
    "    print(f\"\u2713 Enriched agent created with {len(tools)} tools (bind_tools fallback)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Feature Importance Query\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE: What drives our demand?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What are the top factors that drive our demand forecasts? Explain the key drivers.\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Trend Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE: Trend analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Analyze demand trends over the last 12 months. Are we growing? Is there seasonality?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE: Compare forecasting models\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Compare the forecasts from Prophet, ARIMA, and Random Forest for the next quarter. Which should we trust?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Confidence Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE: Forecast confidence\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"How confident should we be in our demand forecasts for the next 3 months?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Custom What-If Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE: Custom scenario\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What if geopolitical risk increases by 50%, tariffs go up 25%, and commodity prices rise 15%? What's the combined impact?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Reference\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENRICHED AGENT TOOL REFERENCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tool_reference = [\n",
    "    (\"explain_demand_drivers\", \"Analyze feature importance\", \"What drives our demand?\"),\n",
    "    (\"detect_trends\", \"Detect patterns and trends\", \"Are we growing? Any seasonality?\"),\n",
    "    (\"compare_forecast_models\", \"Compare Prophet/ARIMA/RF\", \"Which model should we trust?\"),\n",
    "    (\"assess_forecast_confidence\", \"Assess forecast reliability\", \"How confident are the forecasts?\"),\n",
    "    (\"build_whatif_scenario\", \"Custom scenario builder\", \"What if risks increase by 50%?\"),\n",
    "    (\"get_demand_forecast\", \"Get demand forecasts\", \"What's next quarter's forecast?\"),\n",
    "    (\"detect_anomalies\", \"Find demand anomalies\", \"Any unusual patterns?\")\n",
    "]\n",
    "\n",
    "for tool_name, description, example in tool_reference:\n",
    "    print(f\"\\n{tool_name}\")\n",
    "    print(f\"  {description}\")\n",
    "    print(f\"  Example: \\\"{example}\\\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}