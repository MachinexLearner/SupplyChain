{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Tools for Supply Chain Forecasting\n",
    "\n",
    "**Executive summary:** Exposes tools (forecast, anomalies, scenarios, DoD metrics, commodity prices) via a LangChain agent backed by Databricks Foundation Models. Management: use for self-serve analytics and what-if scenarios; deploy as Model Serving or scheduled jobs.\n",
    "\n",
    "**Depends on:** Gold tables (demand signals, DoD metrics, geo/trade risk, commodity, weather) and `gold.prophet_forecasts`. Run transformation and at least one forecasting notebook first.\n",
    "\n",
    "This notebook implements AI agent tools for:\n",
    "- Demand forecasting queries\n",
    "- Anomaly detection\n",
    "- Scenario analysis (geopolitical, tariff, weather)\n",
    "- DoD metrics comparison\n",
    "- Commodity price monitoring\n",
    "\n",
    "**Framework**: LangChain with Databricks Foundation Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages. Use langchain>=0.2 so tool_calling_agent submodule exists (fixes ModuleNotFoundError).\n",
    "%pip install --upgrade \"typing_extensions>=4.1\" \"langchain>=0.2,<0.4\" \"langchain-core>=0.2\" langgraph databricks-langchain mlflow pandas numpy\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Restart Python so upgraded typing_extensions is loaded (fixes ImportError: cannot import name 'Sentinel').\n",
    "try:\n",
    "    from typing_extensions import Sentinel\n",
    "except ImportError:\n",
    "    dbutils.library.restartPython()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Do NOT use initialize_agent or AgentType from langchain.agents \u2014 they are deprecated/removed.\n",
    "from databricks_langchain import ChatDatabricks\n",
    "_create_tool_calling_agent = None\n",
    "_AgentExecutor = None\n",
    "try:\n",
    "    from langchain.agents import create_tool_calling_agent\n",
    "    _create_tool_calling_agent = create_tool_calling_agent\n",
    "except ImportError:\n",
    "    try:\n",
    "        from langchain.agents.tool_calling_agent.base import create_tool_calling_agent\n",
    "        _create_tool_calling_agent = create_tool_calling_agent\n",
    "    except (ModuleNotFoundError, ImportError):\n",
    "        try:\n",
    "            from langchain.agents import create_react_agent as create_tool_calling_agent\n",
    "            _create_tool_calling_agent = create_tool_calling_agent\n",
    "        except ImportError:\n",
    "            pass\n",
    "try:\n",
    "    from langchain_core.agents import AgentExecutor\n",
    "    _AgentExecutor = AgentExecutor\n",
    "except ImportError:\n",
    "    try:\n",
    "        from langchain.agents import AgentExecutor\n",
    "        _AgentExecutor = AgentExecutor\n",
    "    except ImportError:\n",
    "        pass\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import mlflow\n",
    "import json\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configuration - Unity Catalog\n",
    "CATALOG = \"supply_chain\"\n",
    "DEMAND_SIGNALS_TABLE = f\"{CATALOG}.gold.oshkosh_monthly_demand_signals\"\n",
    "DOD_METRICS_TABLE = f\"{CATALOG}.gold.dod_metrics_inputs_monthly\"\n",
    "# Optional: geopolitical_risk_scores_monthly (from GDELT ingestion\u2014removed; unified demand signals still have geo_risk_index)\n",
    "GEO_RISK_TABLE = f\"{CATALOG}.gold.geopolitical_risk_scores_monthly\"\n",
    "TRADE_RISK_TABLE = f\"{CATALOG}.gold.trade_tariff_risk_monthly\"\n",
    "COMMODITY_TABLE = f\"{CATALOG}.silver.commodity_prices_monthly\"\n",
    "WEATHER_TABLE = f\"{CATALOG}.silver.weather_risk_monthly\"\n",
    "PROPHET_FORECAST_TABLE = f\"{CATALOG}.gold.prophet_forecasts\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize Databricks Foundation Model (Llama 3.3 70B - pay-per-token)\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "# Enable MLflow tracing for agent interactions\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "print(\"LLM initialized: databricks-meta-llama-3-3-70b-instruct\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 1: Demand Forecast Query\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def get_demand_forecast(months_ahead: int = 3, include_confidence: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve demand forecast for Oshkosh Defense contracts.\n",
    "    \n",
    "    Args:\n",
    "        months_ahead: Number of months to forecast (1-12)\n",
    "        include_confidence: Whether to include confidence intervals\n",
    "    \n",
    "    Returns:\n",
    "        Forecast summary with predicted demand and confidence intervals\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load forecast data\n",
    "        forecast_df = spark.table(PROPHET_FORECAST_TABLE).toPandas()\n",
    "        \n",
    "        # Get future forecasts only\n",
    "        forecast_df['month'] = pd.to_datetime(forecast_df['month'])\n",
    "        current_date = datetime.now()\n",
    "        \n",
    "        future_forecasts = forecast_df[forecast_df['month'] > current_date].head(months_ahead)\n",
    "        \n",
    "        if future_forecasts.empty:\n",
    "            return \"No forecast data available. Please run the forecasting notebooks first.\"\n",
    "        \n",
    "        result = f\"DEMAND FORECAST - Next {months_ahead} Months\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\\n\"\n",
    "        \n",
    "        total_forecast = 0\n",
    "        for _, row in future_forecasts.iterrows():\n",
    "            month_str = row['month'].strftime('%B %Y')\n",
    "            forecast = row['forecast_demand_usd']\n",
    "            total_forecast += forecast\n",
    "            \n",
    "            result += f\"\ud83d\udcc5 {month_str}\\n\"\n",
    "            result += f\"   Forecast: ${forecast:,.0f}\\n\"\n",
    "            \n",
    "            if include_confidence and 'forecast_lower' in row and 'forecast_upper' in row:\n",
    "                lower = row['forecast_lower']\n",
    "                upper = row['forecast_upper']\n",
    "                if pd.notna(lower) and pd.notna(upper):\n",
    "                    result += f\"   95% CI: ${lower:,.0f} - ${upper:,.0f}\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        result += f\"TOTAL FORECAST: ${total_forecast:,.0f}\\n\"\n",
    "        result += f\"AVERAGE MONTHLY: ${total_forecast/months_ahead:,.0f}\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving forecast: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 2: Anomaly Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def detect_anomalies(threshold_pct: float = 20.0, lookback_months: int = 6) -> str:\n",
    "    \"\"\"\n",
    "    Detect demand anomalies by comparing recent actuals to historical patterns.\n",
    "    \n",
    "    Args:\n",
    "        threshold_pct: Percentage deviation to flag as anomaly (default 20%)\n",
    "        lookback_months: Number of months to analyze (default 6)\n",
    "    \n",
    "    Returns:\n",
    "        List of detected anomalies with severity levels\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load demand signals\n",
    "        demand_df = spark.table(DEMAND_SIGNALS_TABLE).toPandas()\n",
    "        demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "        demand_df = demand_df.sort_values('month')\n",
    "        \n",
    "        # Get recent months\n",
    "        recent = demand_df.tail(lookback_months)\n",
    "        \n",
    "        # Calculate historical baseline (excluding recent)\n",
    "        historical = demand_df.iloc[:-lookback_months]\n",
    "        baseline_mean = historical['total_obligations_usd'].mean()\n",
    "        baseline_std = historical['total_obligations_usd'].std()\n",
    "        \n",
    "        result = f\"ANOMALY DETECTION REPORT\\n\"\n",
    "        result += f\"Threshold: \u00b1{threshold_pct}% from baseline\\n\"\n",
    "        result += f\"Baseline Mean: ${baseline_mean:,.0f}\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\\n\"\n",
    "        \n",
    "        anomalies_found = 0\n",
    "        \n",
    "        for _, row in recent.iterrows():\n",
    "            month_str = row['month'].strftime('%B %Y')\n",
    "            actual = row['total_obligations_usd']\n",
    "            deviation_pct = ((actual - baseline_mean) / baseline_mean) * 100\n",
    "            \n",
    "            if abs(deviation_pct) > threshold_pct:\n",
    "                anomalies_found += 1\n",
    "                \n",
    "                # Determine severity\n",
    "                if abs(deviation_pct) > 50:\n",
    "                    severity = \"\ud83d\udd34 CRITICAL\"\n",
    "                elif abs(deviation_pct) > 30:\n",
    "                    severity = \"\ud83d\udfe0 HIGH\"\n",
    "                else:\n",
    "                    severity = \"\ud83d\udfe1 MODERATE\"\n",
    "                \n",
    "                direction = \"ABOVE\" if deviation_pct > 0 else \"BELOW\"\n",
    "                \n",
    "                result += f\"{severity} - {month_str}\\n\"\n",
    "                result += f\"   Actual: ${actual:,.0f}\\n\"\n",
    "                result += f\"   Deviation: {deviation_pct:+.1f}% {direction} baseline\\n\"\n",
    "                result += f\"   Risk Index: {row.get('combined_risk_index', 'N/A')}\\n\\n\"\n",
    "        \n",
    "        if anomalies_found == 0:\n",
    "            result += \"\u2705 No anomalies detected within the specified threshold.\\n\"\n",
    "        else:\n",
    "            result += f\"\\nTOTAL ANOMALIES: {anomalies_found}\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error detecting anomalies: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 3: Geopolitical Risk Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def scenario_geopolitical_risk(risk_level: str = \"HIGH\", region: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Analyze impact of geopolitical risk scenarios on demand.\n",
    "    \n",
    "    Args:\n",
    "        risk_level: Risk level to simulate (MODERATE, ELEVATED, HIGH, CRITICAL)\n",
    "        region: Region to analyze (EUROPE, MIDEAST, INDO_PACIFIC, AMERICAS, ALL)\n",
    "    \n",
    "    Returns:\n",
    "        Scenario analysis with demand impact projections\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load demand data (required)\n",
    "        demand_df = spark.table(DEMAND_SIGNALS_TABLE).toPandas()\n",
    "        # Geopolitical risk table is optional (GDELT ingestion was removed; unified signals still have geo_risk_index)\n",
    "        try:\n",
    "            geo_risk_df = spark.table(GEO_RISK_TABLE).toPandas()\n",
    "        except Exception:\n",
    "            geo_risk_df = None\n",
    "\n",
    "        # Define demand multipliers based on risk level\n",
    "        multipliers = {\n",
    "            \"MODERATE\": 1.0,\n",
    "            \"ELEVATED\": 1.15,\n",
    "            \"HIGH\": 1.35,\n",
    "            \"CRITICAL\": 1.75\n",
    "        }\n",
    "        \n",
    "        multiplier = multipliers.get(risk_level.upper(), 1.0)\n",
    "        \n",
    "        # Get baseline demand (last 12 months average)\n",
    "        demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "        recent_demand = demand_df.tail(12)['total_obligations_usd'].mean()\n",
    "        \n",
    "        # Calculate scenario impact\n",
    "        scenario_demand = recent_demand * multiplier\n",
    "        demand_increase = scenario_demand - recent_demand\n",
    "        \n",
    "        result = f\"GEOPOLITICAL RISK SCENARIO ANALYSIS\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\\n\"\n",
    "        result += f\"Scenario: {risk_level.upper()} geopolitical risk\\n\"\n",
    "        result += f\"Region: {region.upper()}\\n\\n\"\n",
    "        \n",
    "        result += f\"BASELINE (Current):\\n\"\n",
    "        result += f\"   Average Monthly Demand: ${recent_demand:,.0f}\\n\\n\"\n",
    "        \n",
    "        result += f\"SCENARIO PROJECTION:\\n\"\n",
    "        result += f\"   Demand Multiplier: {multiplier:.2f}x\\n\"\n",
    "        result += f\"   Projected Monthly Demand: ${scenario_demand:,.0f}\\n\"\n",
    "        result += f\"   Monthly Increase: ${demand_increase:,.0f} ({(multiplier-1)*100:.0f}%)\\n\"\n",
    "        result += f\"   Annual Impact: ${demand_increase * 12:,.0f}\\n\\n\"\n",
    "        \n",
    "        result += f\"RECOMMENDED ACTIONS:\\n\"\n",
    "        if risk_level.upper() == \"CRITICAL\":\n",
    "            result += \"   \ud83d\udd34 Activate surge capacity protocols\\n\"\n",
    "            result += \"   \ud83d\udd34 Increase safety stock by 75%\\n\"\n",
    "            result += \"   \ud83d\udd34 Expedite critical supplier orders\\n\"\n",
    "            result += \"   \ud83d\udd34 Review alternative supplier options\\n\"\n",
    "        elif risk_level.upper() == \"HIGH\":\n",
    "            result += \"   \ud83d\udfe0 Increase safety stock by 35%\\n\"\n",
    "            result += \"   \ud83d\udfe0 Accelerate procurement timelines\\n\"\n",
    "            result += \"   \ud83d\udfe0 Monitor supplier capacity closely\\n\"\n",
    "        elif risk_level.upper() == \"ELEVATED\":\n",
    "            result += \"   \ud83d\udfe1 Increase safety stock by 15%\\n\"\n",
    "            result += \"   \ud83d\udfe1 Review supplier contingency plans\\n\"\n",
    "        else:\n",
    "            result += \"   \ud83d\udfe2 Continue normal operations\\n\"\n",
    "            result += \"   \ud83d\udfe2 Maintain standard safety stock levels\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing geopolitical scenario: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 4: Tariff Risk Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def scenario_tariff_increase(tariff_increase_pct: float = 25.0, product_category: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Analyze impact of tariff increases on supply chain costs.\n",
    "    \n",
    "    Args:\n",
    "        tariff_increase_pct: Percentage increase in tariffs (default 25%)\n",
    "        product_category: Product category (VEHICLES, ELECTRONICS, STEEL, ALUMINUM, ALL)\n",
    "    \n",
    "    Returns:\n",
    "        Cost impact analysis with mitigation recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        demand_df = spark.table(DEMAND_SIGNALS_TABLE).toPandas()\n",
    "        trade_risk_df = spark.table(TRADE_RISK_TABLE).toPandas()\n",
    "        \n",
    "        # Get baseline spend\n",
    "        demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "        recent_demand = demand_df.tail(12)['total_obligations_usd'].mean()\n",
    "        \n",
    "        # Estimate import content (assumption: 30% of spend is imported materials)\n",
    "        import_content_pct = 0.30\n",
    "        imported_value = recent_demand * import_content_pct\n",
    "        \n",
    "        # Calculate tariff impact\n",
    "        tariff_cost_increase = imported_value * (tariff_increase_pct / 100)\n",
    "        total_cost_increase_pct = (tariff_cost_increase / recent_demand) * 100\n",
    "        \n",
    "        result = f\"TARIFF INCREASE SCENARIO ANALYSIS\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\\n\"\n",
    "        result += f\"Scenario: {tariff_increase_pct}% tariff increase\\n\"\n",
    "        result += f\"Product Category: {product_category.upper()}\\n\\n\"\n",
    "        \n",
    "        result += f\"BASELINE:\\n\"\n",
    "        result += f\"   Monthly Spend: ${recent_demand:,.0f}\\n\"\n",
    "        result += f\"   Estimated Import Content: {import_content_pct*100:.0f}%\\n\"\n",
    "        result += f\"   Imported Value: ${imported_value:,.0f}\\n\\n\"\n",
    "        \n",
    "        result += f\"TARIFF IMPACT:\\n\"\n",
    "        result += f\"   Additional Tariff Cost: ${tariff_cost_increase:,.0f}/month\\n\"\n",
    "        result += f\"   Total Cost Increase: {total_cost_increase_pct:.1f}%\\n\"\n",
    "        result += f\"   Annual Impact: ${tariff_cost_increase * 12:,.0f}\\n\\n\"\n",
    "        \n",
    "        result += f\"MITIGATION STRATEGIES:\\n\"\n",
    "        if tariff_increase_pct >= 50:\n",
    "            result += \"   \ud83d\udd34 Urgent: Evaluate domestic sourcing alternatives\\n\"\n",
    "            result += \"   \ud83d\udd34 Negotiate long-term contracts before increase\\n\"\n",
    "            result += \"   \ud83d\udd34 Consider tariff exclusion applications\\n\"\n",
    "        elif tariff_increase_pct >= 25:\n",
    "            result += \"   \ud83d\udfe0 Accelerate supplier diversification\\n\"\n",
    "            result += \"   \ud83d\udfe0 Review make-vs-buy decisions\\n\"\n",
    "            result += \"   \ud83d\udfe0 Explore bonded warehouse options\\n\"\n",
    "        else:\n",
    "            result += \"   \ud83d\udfe1 Monitor tariff developments\\n\"\n",
    "            result += \"   \ud83d\udfe1 Update cost models\\n\"\n",
    "            result += \"   \ud83d\udfe1 Review pricing strategies\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing tariff scenario: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 5: Weather Disruption Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def scenario_weather_disruption(disruption_type: str = \"SEVERE_WINTER\", affected_region: str = \"MIDWEST\") -> str:\n",
    "    \"\"\"\n",
    "    Analyze impact of weather disruptions on supply chain.\n",
    "    \n",
    "    Args:\n",
    "        disruption_type: Type of weather event (SEVERE_WINTER, HURRICANE, FLOODING, EXTREME_HEAT)\n",
    "        affected_region: Region affected (MIDWEST, SOUTHEAST, GULF_COAST, WEST_COAST)\n",
    "    \n",
    "    Returns:\n",
    "        Supply chain disruption analysis with contingency recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load weather risk data\n",
    "        weather_df = spark.table(WEATHER_TABLE).toPandas()\n",
    "        \n",
    "        # Define disruption impacts\n",
    "        disruption_impacts = {\n",
    "            \"SEVERE_WINTER\": {\n",
    "                \"transport_delay_days\": 7,\n",
    "                \"production_impact_pct\": 15,\n",
    "                \"affected_suppliers\": [\"POWERTRAIN\", \"SUSPENSION\", \"MATERIALS\"]\n",
    "            },\n",
    "            \"HURRICANE\": {\n",
    "                \"transport_delay_days\": 14,\n",
    "                \"production_impact_pct\": 25,\n",
    "                \"affected_suppliers\": [\"ELECTRONICS\", \"TIRES\", \"ARMOR\"]\n",
    "            },\n",
    "            \"FLOODING\": {\n",
    "                \"transport_delay_days\": 10,\n",
    "                \"production_impact_pct\": 20,\n",
    "                \"affected_suppliers\": [\"MATERIALS\", \"HYDRAULICS\", \"ELECTRICAL\"]\n",
    "            },\n",
    "            \"EXTREME_HEAT\": {\n",
    "                \"transport_delay_days\": 3,\n",
    "                \"production_impact_pct\": 10,\n",
    "                \"affected_suppliers\": [\"RUBBER\", \"ELECTRONICS\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        impact = disruption_impacts.get(disruption_type.upper(), disruption_impacts[\"SEVERE_WINTER\"])\n",
    "        \n",
    "        result = f\"WEATHER DISRUPTION SCENARIO ANALYSIS\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\\n\"\n",
    "        result += f\"Scenario: {disruption_type.replace('_', ' ')}\\n\"\n",
    "        result += f\"Affected Region: {affected_region.replace('_', ' ')}\\n\\n\"\n",
    "        \n",
    "        result += f\"ESTIMATED IMPACTS:\\n\"\n",
    "        result += f\"   Transportation Delays: {impact['transport_delay_days']} days\\n\"\n",
    "        result += f\"   Production Impact: {impact['production_impact_pct']}% reduction\\n\"\n",
    "        result += f\"   Affected Subsystems: {', '.join(impact['affected_suppliers'])}\\n\\n\"\n",
    "        \n",
    "        result += f\"SUPPLY CHAIN VULNERABILITIES:\\n\"\n",
    "        for subsystem in impact['affected_suppliers']:\n",
    "            result += f\"   \u26a0\ufe0f {subsystem}: Potential delays and shortages\\n\"\n",
    "        \n",
    "        result += f\"\\nCONTINGENCY ACTIONS:\\n\"\n",
    "        if impact['transport_delay_days'] >= 10:\n",
    "            result += \"   \ud83d\udd34 Activate emergency logistics protocols\\n\"\n",
    "            result += \"   \ud83d\udd34 Pre-position critical inventory\\n\"\n",
    "            result += \"   \ud83d\udd34 Engage backup transportation providers\\n\"\n",
    "        else:\n",
    "            result += \"   \ud83d\udfe1 Monitor weather forecasts closely\\n\"\n",
    "            result += \"   \ud83d\udfe1 Communicate with affected suppliers\\n\"\n",
    "            result += \"   \ud83d\udfe1 Review safety stock levels\\n\"\n",
    "        \n",
    "        result += f\"\\nRECOVERY TIMELINE:\\n\"\n",
    "        result += f\"   Expected normalization: {impact['transport_delay_days'] + 7} days\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing weather scenario: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 6: DoD Metrics Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def compare_dod_metrics(metric_type: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Compare current performance against DoD supply chain metrics objectives.\n",
    "    \n",
    "    Args:\n",
    "        metric_type: Metric to analyze (RO, AAO, DAYS_OF_SUPPLY, NMCS_RISK, ALL)\n",
    "    \n",
    "    Returns:\n",
    "        DoD metrics comparison with performance assessment\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load DoD metrics\n",
    "        dod_df = spark.table(DOD_METRICS_TABLE).toPandas()\n",
    "        dod_df['month'] = pd.to_datetime(dod_df['month'])\n",
    "        \n",
    "        # Get latest metrics\n",
    "        latest = dod_df.sort_values('month').iloc[-1]\n",
    "        \n",
    "        result = f\"DoD SUPPLY CHAIN METRICS ASSESSMENT\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\"\n",
    "        result += f\"As of: {latest['month'].strftime('%B %Y')}\\n\\n\"\n",
    "        \n",
    "        # Requirements Objective\n",
    "        if metric_type.upper() in [\"RO\", \"ALL\"]:\n",
    "            ro = latest['requirements_objective_proxy']\n",
    "            risk_adj_ro = latest['risk_adjusted_ro']\n",
    "            \n",
    "            result += f\"\ud83d\udcca REQUIREMENTS OBJECTIVE (RO)\\n\"\n",
    "            result += f\"   Current RO: ${ro:,.0f}\\n\"\n",
    "            result += f\"   Risk-Adjusted RO: ${risk_adj_ro:,.0f}\\n\"\n",
    "            result += f\"   Status: {'\u2705 Adequate' if ro > 0 else '\u26a0\ufe0f Review needed'}\\n\\n\"\n",
    "        \n",
    "        # Approved Acquisition Objective\n",
    "        if metric_type.upper() in [\"AAO\", \"ALL\"]:\n",
    "            aao = latest['approved_acquisition_objective_proxy']\n",
    "            \n",
    "            result += f\"\ud83d\udcca APPROVED ACQUISITION OBJECTIVE (AAO)\\n\"\n",
    "            result += f\"   Current AAO: ${aao:,.0f}\\n\"\n",
    "            result += f\"   (Includes 2-year forecast demand)\\n\\n\"\n",
    "        \n",
    "        # Days of Supply\n",
    "        if metric_type.upper() in [\"DAYS_OF_SUPPLY\", \"ALL\"]:\n",
    "            dos = latest['days_of_supply_proxy']\n",
    "            \n",
    "            status = \"\u2705 Healthy\" if dos >= 60 else \"\ud83d\udfe1 Monitor\" if dos >= 30 else \"\ud83d\udd34 Critical\"\n",
    "            \n",
    "            result += f\"\ud83d\udcca DAYS OF SUPPLY\\n\"\n",
    "            result += f\"   Current: {dos:.0f} days\\n\"\n",
    "            result += f\"   Target: 60+ days\\n\"\n",
    "            result += f\"   Status: {status}\\n\\n\"\n",
    "        \n",
    "        # NMCS Risk\n",
    "        if metric_type.upper() in [\"NMCS_RISK\", \"ALL\"]:\n",
    "            nmcs = latest['nmcs_risk_indicator']\n",
    "            \n",
    "            result += f\"\ud83d\udcca NOT MISSION CAPABLE - SUPPLY (NMCS) RISK\\n\"\n",
    "            result += f\"   Current Risk Level: {nmcs}\\n\"\n",
    "            if nmcs == \"HIGH_RISK\":\n",
    "                result += f\"   \u26a0\ufe0f Action Required: Increase safety stock immediately\\n\"\n",
    "            elif nmcs == \"ELEVATED_RISK\":\n",
    "                result += f\"   \ud83d\udfe1 Monitor closely and review inventory levels\\n\"\n",
    "            else:\n",
    "                result += f\"   \u2705 Within acceptable parameters\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        # Demand Volatility\n",
    "        if metric_type.upper() == \"ALL\":\n",
    "            volatility = latest['demand_volatility_category']\n",
    "            cv = latest['coefficient_of_variation']\n",
    "            \n",
    "            result += f\"\ud83d\udcca DEMAND VOLATILITY\\n\"\n",
    "            result += f\"   Category: {volatility}\\n\"\n",
    "            result += f\"   Coefficient of Variation: {cv:.2f}\\n\"\n",
    "            result += f\"   Recommended Forecast Method: {latest['forecast_method_recommendation']}\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving DoD metrics: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 7: Commodity Price Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def get_commodity_prices(category: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Get current prices for defense-critical commodities.\n",
    "    \n",
    "    Args:\n",
    "        category: Commodity category (ENERGY, PRECIOUS_METALS, INDUSTRIAL_METALS, BATTERY_MATERIALS, ALL)\n",
    "    \n",
    "    Returns:\n",
    "        Commodity price summary with supply chain impact analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load commodity prices\n",
    "        commodity_df = spark.table(COMMODITY_TABLE).toPandas()\n",
    "        commodity_df['month'] = pd.to_datetime(commodity_df['month'])\n",
    "        \n",
    "        # Get latest prices\n",
    "        latest_month = commodity_df['month'].max()\n",
    "        latest = commodity_df[commodity_df['month'] == latest_month]\n",
    "        \n",
    "        if category.upper() != \"ALL\":\n",
    "            latest = latest[latest['category'].str.upper() == category.upper()]\n",
    "        \n",
    "        result = f\"DEFENSE CRITICAL MATERIALS PRICE MONITOR\\n\"\n",
    "        result += \"=\" * 50 + \"\\n\"\n",
    "        result += f\"As of: {latest_month.strftime('%B %Y')}\\n\\n\"\n",
    "        \n",
    "        # Group by category\n",
    "        for cat in latest['category'].unique():\n",
    "            cat_data = latest[latest['category'] == cat]\n",
    "            \n",
    "            result += f\"\ud83d\udcca {cat.upper()}\\n\"\n",
    "            for _, row in cat_data.iterrows():\n",
    "                trend = \"\ud83d\udd3a\" if row['pct_change_1mo'] > 0 else \"\ud83d\udd3b\"\n",
    "                result += f\"   \u2022 {row['commodity_name']}: ${row['close_price']:,.2f}\\n\"\n",
    "                result += f\"     {trend} {row['pct_change_1mo']:+.1f}% (1mo) | {row['pct_change_3mo']:+.1f}% (3mo)\\n\"\n",
    "                result += f\"     Use: {row['defense_use']}\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        # Cost pressure summary\n",
    "        avg_pressure = latest['cost_pressure_score'].mean()\n",
    "        \n",
    "        result += f\"COST PRESSURE ASSESSMENT:\\n\"\n",
    "        if avg_pressure > 10:\n",
    "            result += f\"   \ud83d\udd34 HIGH PRESSURE: Average {avg_pressure:.1f} - Consider accelerating procurement\\n\"\n",
    "        elif avg_pressure > 0:\n",
    "            result += f\"   \ud83d\udfe1 MODERATE PRESSURE: Average {avg_pressure:.1f} - Monitor closely\\n\"\n",
    "        else:\n",
    "            result += f\"   \ud83d\udfe2 FAVORABLE: Average {avg_pressure:.1f} - Potential cost savings opportunity\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving commodity prices: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define all tools\n",
    "tools = [\n",
    "    get_demand_forecast,\n",
    "    detect_anomalies,\n",
    "    scenario_geopolitical_risk,\n",
    "    scenario_tariff_increase,\n",
    "    scenario_weather_disruption,\n",
    "    compare_dod_metrics,\n",
    "    get_commodity_prices\n",
    "]\n",
    "\n",
    "# Create agent prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI assistant for Oshkosh Defense supply chain forecasting and analysis.\n",
    "    \n",
    "You have access to tools that can:\n",
    "1. Retrieve demand forecasts\n",
    "2. Detect anomalies in demand patterns\n",
    "3. Analyze geopolitical risk scenarios\n",
    "4. Analyze tariff/trade risk scenarios\n",
    "5. Analyze weather disruption scenarios\n",
    "6. Compare against DoD supply chain metrics\n",
    "7. Monitor commodity prices\n",
    "\n",
    "When answering questions:\n",
    "- Use the appropriate tool to get data\n",
    "- Provide clear, actionable insights\n",
    "- Reference DoD metrics and terminology where applicable\n",
    "- Highlight risks and recommended actions\n",
    "\n",
    "Always be specific with numbers and dates when available.\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "# Create agent (use LangChain AgentExecutor if available; else simple bind_tools loop)\n",
    "if _create_tool_calling_agent is not None and _AgentExecutor is not None:\n",
    "    agent = _create_tool_calling_agent(llm, tools, prompt)\n",
    "    agent_executor = _AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    print(\"Agent created with 7 tools (LangChain AgentExecutor)\")\n",
    "else:\n",
    "    # Fallback when create_tool_calling_agent / create_react_agent / AgentExecutor not in langchain.agents\n",
    "    tools_by_name = {t.name: t for t in tools}\n",
    "    class _SimpleToolCallingExecutor:\n",
    "        def __init__(self, llm, tools, verbose=True):\n",
    "            self.llm = llm\n",
    "            self.tools = tools\n",
    "            self.verbose = verbose\n",
    "        def invoke(self, inputs):\n",
    "            user_input = inputs.get(\"input\", \"\")\n",
    "            messages = [HumanMessage(content=user_input)]\n",
    "            max_rounds = 15\n",
    "            for _ in range(max_rounds):\n",
    "                response = self.llm.bind_tools(self.tools).invoke(messages)\n",
    "                if self.verbose:\n",
    "                    print(response.content[:200] if response.content else \"(tool calls)\", \"...\")\n",
    "                if not getattr(response, \"tool_calls\", None):\n",
    "                    return {\"output\": response.content or \"\"}\n",
    "                for tc in response.tool_calls:\n",
    "                    name = tc.get(\"name\", None) if isinstance(tc, dict) else getattr(tc, \"name\", None)\n",
    "                    args = tc.get(\"args\", {}) if isinstance(tc, dict) else getattr(tc, \"args\", {}) or {}\n",
    "                    tid = tc.get(\"id\", \"\") if isinstance(tc, dict) else getattr(tc, \"id\", \"\")\n",
    "                    tool = tools_by_name.get(name) if name else None\n",
    "                    if tool:\n",
    "                        result = tool.invoke(args)\n",
    "                        messages.append(ToolMessage(content=str(result), tool_call_id=tid))\n",
    "                messages.append(response)\n",
    "            return {\"output\": (response.content or \"\") + \"\\n[Max rounds reached.]\"}\n",
    "    agent_executor = _SimpleToolCallingExecutor(llm, tools, verbose=True)\n",
    "    print(\"Agent created with 7 tools (bind_tools fallback)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Agent Interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 1: Forecast query\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE 1: Forecast Query\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What is the demand forecast for the next quarter?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 2: Anomaly detection\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE 2: Anomaly Detection\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Are there any demand anomalies in the last 6 months?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 3: Geopolitical scenario\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE 3: Geopolitical Risk Scenario\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What would happen to demand if geopolitical risk becomes CRITICAL in Europe?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 4: DoD metrics\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE 4: DoD Metrics Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"How do our current metrics compare to DoD objectives?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 5: Commodity prices\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE 5: Commodity Price Check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What are the current prices for industrial metals and how might they affect our costs?\"\n",
    "})\n",
    "print(response[\"output\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Agent Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save agent configuration for deployment\n",
    "agent_config = {\n",
    "    \"model\": \"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"tools\": [t.name for t in tools],\n",
    "    \"data_sources\": {\n",
    "        \"demand_signals\": DEMAND_SIGNALS_TABLE,\n",
    "        \"dod_metrics\": DOD_METRICS_TABLE,\n",
    "        \"geo_risk\": GEO_RISK_TABLE,\n",
    "        \"trade_risk\": TRADE_RISK_TABLE,\n",
    "        \"commodity\": COMMODITY_TABLE,\n",
    "        \"weather\": WEATHER_TABLE,\n",
    "        \"forecasts\": PROPHET_FORECAST_TABLE\n",
    "    },\n",
    "    \"created_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save agent config (local only; DBFS/workspace copy skipped when local filesystem access is forbidden)\n",
    "import json\n",
    "with open(\"/tmp/agent_config.json\", \"w\") as f:\n",
    "    json.dump(agent_config, f, indent=2)\n",
    "print(\"Agent configuration saved to /tmp/agent_config.json\")\n",
    "# Optional: copy to DBFS only when allowed (many clusters forbid WorkspaceLocalFileSystem/DBFS root)\n",
    "# try:\n",
    "#     dbutils.fs.cp(\"file:/tmp/agent_config.json\", \"dbfs:/models/agent_config.json\")\n",
    "#     print(\"Also copied to dbfs:/models/agent_config.json\")\n",
    "# except Exception as e:\n",
    "#     print(f\"DBFS copy skipped (restricted): {e}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Tool Reference\n",
    "\n",
    "| Tool | Description | Example Query |\n",
    "|------|-------------|---------------|\n",
    "| `get_demand_forecast` | Retrieve demand forecasts | \"What's the forecast for next quarter?\" |\n",
    "| `detect_anomalies` | Find demand anomalies | \"Are there any unusual demand patterns?\" |\n",
    "| `scenario_geopolitical_risk` | Analyze geo risk impact | \"What if geo risk becomes CRITICAL?\" |\n",
    "| `scenario_tariff_increase` | Analyze tariff impact | \"What's the impact of 25% tariff increase?\" |\n",
    "| `scenario_weather_disruption` | Analyze weather impact | \"How would a severe winter affect supply?\" |\n",
    "| `compare_dod_metrics` | Check DoD metrics | \"How do we compare to DoD objectives?\" |\n",
    "| `get_commodity_prices` | Monitor commodity costs | \"What are current steel prices?\" |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Deploy agent as a Databricks Model Serving endpoint\n",
    "2. Create Databricks Jobs for scheduled data refreshes\n",
    "3. Build dashboard for visualization\n"
   ]
  }
 ]
}