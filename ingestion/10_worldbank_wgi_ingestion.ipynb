{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Bank WGI Ingestion\n",
    "\n",
    "**Executive summary:** Ingests Worldwide Governance Indicators (political stability, government effectiveness, rule of law, etc.) from the World Bank API into raw and bronze. Used as structured governance/political risk indicators.\n",
    "\n",
    "**Data Source**: https://api.worldbank.org/v2 \u2014 World Bank Indicators API. WGI series use same endpoint: `country/all/indicator/{CODE}?format=json&date=...&per_page=10000`.\n",
    "\n",
    "**Target Tables** (Unity Catalog):\n",
    "- `supply_chain.raw.worldbank_wgi` - Raw WGI observations\n",
    "- `supply_chain.bronze.worldbank_wgi` - Cleaned WGI with typed columns\n",
    "\n",
    "**Idempotency:** Delta merge on (source, indicator_code, country_code, as_of_date).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, TimestampType, DateType,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CATALOG = \"supply_chain\"\n",
    "RAW_TABLE = f\"{CATALOG}.raw.worldbank_wgi\"\n",
    "BRONZE_TABLE = f\"{CATALOG}.bronze.worldbank_wgi\"\n",
    "\n",
    "# WGI: six governance dimensions (estimate series)\n",
    "WGI_INDICATORS = {\n",
    "    \"CC.EST\": \"Control of Corruption: Estimate\",\n",
    "    \"GE.EST\": \"Government Effectiveness: Estimate\",\n",
    "    \"PV.EST\": \"Political Stability and Absence of Violence/Terrorism: Estimate\",\n",
    "    \"RQ.EST\": \"Regulatory Quality: Estimate\",\n",
    "    \"RL.EST\": \"Rule of Law: Estimate\",\n",
    "    \"VA.EST\": \"Voice and Accountability: Estimate\",\n",
    "}\n",
    "\n",
    "WORLDBANK_BASE = \"https://api.worldbank.org/v2\"\n",
    "DATE_RANGE = \"2000:2025\"\n",
    "PER_PAGE = 10000\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared HTTP helper\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "for _p in [os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in dir() else \"\", os.getcwd(), \"/Workspace/Repos\", \".\"]:\n",
    "    if _p and _p not in sys.path:\n",
    "        sys.path.insert(0, _p)\n",
    "try:\n",
    "    from ingestion_utils import safe_get, parse_json, normalize_indicator_row\n",
    "except ImportError:\n",
    "    import requests\n",
    "    import time\n",
    "    def safe_get(url, *, timeout=60, retries=3, backoff=2.0, headers=None):\n",
    "        last = None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                r = requests.get(url, timeout=timeout, headers=headers or {})\n",
    "                r.raise_for_status()\n",
    "                return r\n",
    "            except Exception as e:\n",
    "                last = e\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(backoff ** attempt)\n",
    "        raise last\n",
    "    def parse_json(text):\n",
    "        return json.loads(text)\n",
    "    def normalize_indicator_row(*, source, ingested_at, as_of_date, country_code, indicator_code, indicator_name, value, unit, frequency, raw_payload=None):\n",
    "        return {\"source\": source, \"ingested_at\": ingested_at, \"as_of_date\": as_of_date, \"country_code\": country_code or \"\", \"indicator_code\": indicator_code, \"indicator_name\": indicator_name, \"value\": float(value) if value is not None else None, \"unit\": unit, \"frequency\": frequency, \"raw_payload\": raw_payload}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch WGI data from API\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fetch_wgi_indicator(indicator_code: str, indicator_name: str) -> list:\n",
    "    \"\"\"Fetch one WGI indicator for all countries; returns list of normalized row dicts.\"\"\"\n",
    "    url = f\"{WORLDBANK_BASE}/country/all/indicator/{indicator_code}?format=json&date={DATE_RANGE}&per_page={PER_PAGE}\"\n",
    "    try:\n",
    "        r = safe_get(url)\n",
    "        payload = parse_json(r.text)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"World Bank WGI API unavailable or invalid response for {indicator_code}: {e}\") from e\n",
    "    if not isinstance(payload, list) or len(payload) < 2:\n",
    "        return []\n",
    "    meta, data = payload[0], payload[1]\n",
    "    if not isinstance(data, list):\n",
    "        return []\n",
    "    ingested_at = datetime.utcnow().isoformat() + \"Z\"\n",
    "    rows = []\n",
    "    for rec in data:\n",
    "        if not isinstance(rec, dict):\n",
    "            continue\n",
    "        date_val = rec.get(\"date\")\n",
    "        if not date_val:\n",
    "            continue\n",
    "        try:\n",
    "            as_of_date = f\"{date_val}-01-01\"\n",
    "        except Exception:\n",
    "            continue\n",
    "        country = rec.get(\"country\") or {}\n",
    "        country_id = country.get(\"id\") or \"\"\n",
    "        country_iso = rec.get(\"countryiso3code\") or country_id\n",
    "        val = rec.get(\"value\")\n",
    "        if val is None:\n",
    "            continue\n",
    "        try:\n",
    "            value_float = float(val)\n",
    "        except (TypeError, ValueError):\n",
    "            continue\n",
    "        unit = (rec.get(\"unit\") or \"\").strip() or None\n",
    "        row = normalize_indicator_row(\n",
    "            source=\"worldbank_wgi\",\n",
    "            ingested_at=ingested_at,\n",
    "            as_of_date=as_of_date,\n",
    "            country_code=country_iso or country_id,\n",
    "            indicator_code=indicator_code,\n",
    "            indicator_name=indicator_name,\n",
    "            value=value_float,\n",
    "            unit=unit,\n",
    "            frequency=\"annual\",\n",
    "            raw_payload=json.dumps(rec),\n",
    "        )\n",
    "        rows.append(row)\n",
    "    return rows\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest all indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "all_rows = []\n",
    "for code, name in WGI_INDICATORS.items():\n",
    "    try:\n",
    "        rows = fetch_wgi_indicator(code, name)\n",
    "        all_rows.extend(rows)\n",
    "        print(f\"Fetched {code}: {len(rows)} records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Skip {code}: {e}\")\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"World Bank WGI API returned no data. Check connectivity and indicator codes.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Spark DataFrame and schema\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "INDICATOR_RAW_SCHEMA = StructType([\n",
    "    StructField(\"source\", StringType(), False),\n",
    "    StructField(\"ingested_at\", StringType(), False),\n",
    "    StructField(\"as_of_date\", StringType(), False),\n",
    "    StructField(\"country_code\", StringType(), False),\n",
    "    StructField(\"indicator_code\", StringType(), False),\n",
    "    StructField(\"indicator_name\", StringType(), False),\n",
    "    StructField(\"value\", DoubleType(), True),\n",
    "    StructField(\"unit\", StringType(), True),\n",
    "    StructField(\"frequency\", StringType(), False),\n",
    "    StructField(\"raw_payload\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_raw = spark.createDataFrame(all_rows, INDICATOR_RAW_SCHEMA)\n",
    "df_raw = df_raw.withColumn(\"ingested_at\", F.col(\"ingested_at\").cast(TimestampType()))\n",
    "df_raw = df_raw.withColumn(\"as_of_date\", F.to_date(F.col(\"as_of_date\")))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unity Catalog and idempotent merge (raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.raw\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.bronze\")\n",
    "print(f\"Catalog {CATALOG}, schemas raw/bronze ready.\")\n",
    "\n",
    "raw_create_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {RAW_TABLE} (\n",
    "  source STRING NOT NULL,\n",
    "  ingested_at TIMESTAMP NOT NULL,\n",
    "  as_of_date DATE NOT NULL,\n",
    "  country_code STRING NOT NULL,\n",
    "  indicator_code STRING NOT NULL,\n",
    "  indicator_name STRING NOT NULL,\n",
    "  value DOUBLE,\n",
    "  unit STRING,\n",
    "  frequency STRING NOT NULL,\n",
    "  raw_payload STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(raw_create_sql)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "dt_raw = DeltaTable.forName(spark, RAW_TABLE)\n",
    "dt_raw.alias(\"t\").merge(\n",
    "    df_raw.alias(\"s\"),\n",
    "    \"t.source = s.source AND t.indicator_code = s.indicator_code AND t.country_code = s.country_code AND t.as_of_date = s.as_of_date\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "raw_count = spark.table(RAW_TABLE).count()\n",
    "print(f\"Raw table row count after merge: {raw_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze: cleaned types\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bronze_df = spark.table(RAW_TABLE).select(\n",
    "    F.col(\"source\"),\n",
    "    F.col(\"ingested_at\"),\n",
    "    F.col(\"as_of_date\"),\n",
    "    F.col(\"country_code\"),\n",
    "    F.col(\"indicator_code\"),\n",
    "    F.col(\"indicator_name\"),\n",
    "    F.col(\"value\"),\n",
    "    F.col(\"unit\"),\n",
    "    F.col(\"frequency\"),\n",
    "    F.col(\"raw_payload\"),\n",
    ")\n",
    "\n",
    "bronze_create_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {BRONZE_TABLE} (\n",
    "  source STRING NOT NULL,\n",
    "  ingested_at TIMESTAMP NOT NULL,\n",
    "  as_of_date DATE NOT NULL,\n",
    "  country_code STRING NOT NULL,\n",
    "  indicator_code STRING NOT NULL,\n",
    "  indicator_name STRING NOT NULL,\n",
    "  value DOUBLE,\n",
    "  unit STRING,\n",
    "  frequency STRING NOT NULL,\n",
    "  raw_payload STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(bronze_create_sql)\n",
    "dt_bronze = DeltaTable.forName(spark, BRONZE_TABLE)\n",
    "dt_bronze.alias(\"t\").merge(\n",
    "    bronze_df.alias(\"s\"),\n",
    "    \"t.source = s.source AND t.indicator_code = s.indicator_code AND t.country_code = s.country_code AND t.as_of_date = s.as_of_date\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "bronze_count = spark.table(BRONZE_TABLE).count()\n",
    "print(f\"Bronze table row count after merge: {bronze_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log row counts and sample\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"=== World Bank WGI Ingestion ===\")\n",
    "print(f\"Raw {RAW_TABLE}: {raw_count} rows\")\n",
    "print(f\"Bronze {BRONZE_TABLE}: {bronze_count} rows\")\n",
    "print(\"Sample (raw):\")\n",
    "display(spark.table(RAW_TABLE).orderBy(F.desc(\"as_of_date\")).limit(10))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables: `supply_chain.raw.worldbank_wgi`, `supply_chain.bronze.worldbank_wgi`. Idempotent merge on (source, indicator_code, country_code, as_of_date).\n"
   ]
  }
 ]
}