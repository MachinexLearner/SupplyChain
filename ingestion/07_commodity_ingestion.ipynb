{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commodity Prices Ingestion\n",
    "\n",
    "**Executive summary:** Ingests defense-relevant commodity prices from Yahoo Finance (yfinance) and IMF Primary Commodity Prices (PCPS) into raw and bronze; builds silver with cost-pressure metrics from yfinance data. Single notebook, no redundant commodity tables.\n",
    "\n",
    "**Data Sources**: yfinance (Yahoo Finance, no API key); IMF PCPS (API/CSV, fails gracefully if unavailable).\n",
    "\n",
    "**Target Tables** (Unity Catalog):\n",
    "- `supply_chain.raw.commodity_prices` - Raw commodity observations (yfinance + IMF), standard indicator schema\n",
    "- `supply_chain.bronze.commodity_prices` - Cleaned with typed columns\n",
    "- `supply_chain.silver.commodity_prices_monthly` - Monthly prices with change metrics (from yfinance only)\n",
    "\n",
    "**Idempotency:** Delta merge on (source, indicator_code, country_code, as_of_date).\n",
    "\n",
    "**Requirements:** Cluster must have outbound internet access. Install yfinance via `%pip install yfinance`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install yfinance pandas requests\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import csv\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, TimestampType,\n",
    ")\n",
    "from pyspark.sql.window import Window\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CATALOG = \"supply_chain\"\n",
    "RAW_TABLE = f\"{CATALOG}.raw.commodity_prices\"\n",
    "BRONZE_TABLE = f\"{CATALOG}.bronze.commodity_prices\"\n",
    "SILVER_TABLE = f\"{CATALOG}.silver.commodity_prices_monthly\"\n",
    "\n",
    "# Defense-relevant commodity tickers (Yahoo Finance)\n",
    "DEFENSE_COMMODITIES = {\n",
    "    'CL=F': {'name': 'Crude Oil (WTI)', 'category': 'ENERGY', 'defense_use': 'Fuel, lubricants, plastics', 'unit': 'USD/barrel'},\n",
    "    'NG=F': {'name': 'Natural Gas', 'category': 'ENERGY', 'defense_use': 'Manufacturing energy, heating', 'unit': 'USD/MMBtu'},\n",
    "    'GC=F': {'name': 'Gold', 'category': 'PRECIOUS_METALS', 'defense_use': 'Electronics, connectors, plating', 'unit': 'USD/oz'},\n",
    "    'SI=F': {'name': 'Silver', 'category': 'PRECIOUS_METALS', 'defense_use': 'Electronics, soldering, contacts', 'unit': 'USD/oz'},\n",
    "    'PL=F': {'name': 'Platinum', 'category': 'PRECIOUS_METALS', 'defense_use': 'Catalytic converters, sensors', 'unit': 'USD/oz'},\n",
    "    'PA=F': {'name': 'Palladium', 'category': 'PRECIOUS_METALS', 'defense_use': 'Catalytic converters, electronics', 'unit': 'USD/oz'},\n",
    "    'HG=F': {'name': 'Copper', 'category': 'INDUSTRIAL_METALS', 'defense_use': 'Wiring, motors, electronics, radiators', 'unit': 'USD/lb'},\n",
    "    'ALI=F': {'name': 'Aluminum', 'category': 'INDUSTRIAL_METALS', 'defense_use': 'Vehicle frames, armor, components', 'unit': 'USD/lb'},\n",
    "    'SLX': {'name': 'Steel ETF (VanEck)', 'category': 'INDUSTRIAL_METALS', 'defense_use': 'Vehicle frames, armor, structural components', 'unit': 'USD/share'},\n",
    "    'LIT': {'name': 'Lithium & Battery Tech ETF', 'category': 'BATTERY_MATERIALS', 'defense_use': 'Batteries, hybrid vehicle systems', 'unit': 'USD/share'},\n",
    "    'RUBUUSD': {'name': 'Rubber', 'category': 'RUBBER', 'defense_use': 'Tires, seals, gaskets', 'unit': 'USD/kg'},\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared HTTP / schema helper\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for _p in [os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in dir() else \"\", os.getcwd(), \"/Workspace/Repos\", \".\"]:\n",
    "    if _p and _p not in sys.path:\n",
    "        sys.path.insert(0, _p)\n",
    "try:\n",
    "    from ingestion_utils import safe_get, parse_json, normalize_indicator_row\n",
    "except ImportError:\n",
    "    import requests\n",
    "    import time\n",
    "    def safe_get(url, *, timeout=60, retries=3, backoff=2.0, headers=None):\n",
    "        last = None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                r = requests.get(url, timeout=timeout, headers=headers or {})\n",
    "                r.raise_for_status()\n",
    "                return r\n",
    "            except Exception as e:\n",
    "                last = e\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(backoff ** attempt)\n",
    "        raise last\n",
    "    def parse_json(text):\n",
    "        return json.loads(text)\n",
    "    def normalize_indicator_row(*, source, ingested_at, as_of_date, country_code, indicator_code, indicator_name, value, unit, frequency, raw_payload=None):\n",
    "        return {\"source\": source, \"ingested_at\": ingested_at, \"as_of_date\": as_of_date, \"country_code\": country_code or \"\", \"indicator_code\": indicator_code, \"indicator_name\": indicator_name, \"value\": float(value) if value is not None else None, \"unit\": unit, \"frequency\": frequency, \"raw_payload\": raw_payload}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch yfinance (standard indicator rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def fetch_yfinance_commodity_rows(tickers: dict, years_back: int = 5) -> list:\n",
    "    \"\"\"Fetch yfinance commodity prices; return list of standard indicator row dicts.\"\"\"\n",
    "    ingested_at = datetime.utcnow().isoformat() + \"Z\"\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=years_back * 365)\n",
    "    rows = []\n",
    "    for ticker, info in tickers.items():\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "            if data.empty:\n",
    "                continue\n",
    "            close = data['Close']\n",
    "            if isinstance(close, pd.DataFrame):\n",
    "                close = close.squeeze()\n",
    "            monthly = close.resample('M').last()\n",
    "            for date, price in monthly.items():\n",
    "                price_val = float(price) if getattr(price, 'ndim', 0) == 0 else float(price.iloc[0])\n",
    "                as_of_date = date.strftime('%Y-%m-%d')\n",
    "                rows.append(normalize_indicator_row(\n",
    "                    source=\"yfinance_commodity\",\n",
    "                    ingested_at=ingested_at,\n",
    "                    as_of_date=as_of_date,\n",
    "                    country_code=\"\",\n",
    "                    indicator_code=ticker,\n",
    "                    indicator_name=info['name'],\n",
    "                    value=price_val,\n",
    "                    unit=info['unit'],\n",
    "                    frequency=\"monthly\",\n",
    "                    raw_payload=json.dumps({\"ticker\": ticker, \"close\": price_val, \"date\": as_of_date}),\n",
    "                ))\n",
    "        except Exception as e:\n",
    "            print(f\"  Skip {ticker}: {e}\")\n",
    "    return rows\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch IMF PCPS (standard indicator rows)\n",
    "\n",
    "Tries API/CSV; skips if unavailable (no duplicate commodity series\u2014yfinance is primary for silver).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fetch_imf_commodity_rows() -> list:\n",
    "    \"\"\"Fetch IMF Primary Commodity Price indices; return list of standard indicator row dicts. Returns [] if unavailable.\"\"\"\n",
    "    ingested_at = datetime.utcnow().isoformat() + \"Z\"\n",
    "    rows = []\n",
    "    urls = [\n",
    "        \"https://api.imf.org/data/PCPS?format=jsondata\",\n",
    "        \"https://data.imf.org/regular.aspx?key=60972224&format=csv\",\n",
    "    ]\n",
    "    for url in urls:\n",
    "        try:\n",
    "            r = safe_get(url, timeout=90)\n",
    "            text = r.text\n",
    "            if not text or len(text) < 50:\n",
    "                continue\n",
    "            if \"json\" in url or text.strip().startswith(\"[\"):\n",
    "                try:\n",
    "                    data = parse_json(text)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if isinstance(data, list):\n",
    "                    for rec in data:\n",
    "                        if not isinstance(rec, dict):\n",
    "                            continue\n",
    "                        period = rec.get(\"Period\") or rec.get(\"date\") or rec.get(\"Time Period\")\n",
    "                        val = rec.get(\"Value\") or rec.get(\"value\")\n",
    "                        code = rec.get(\"Commodity\") or rec.get(\"indicator\") or rec.get(\"Indicator\")\n",
    "                        name = rec.get(\"Commodity Name\") or rec.get(\"indicator_name\") or code or \"Commodity\"\n",
    "                        if period and val is not None:\n",
    "                            try:\n",
    "                                as_of = f\"{str(period)[:4]}-{str(period)[4:6].zfill(2)}-01\" if len(str(period)) >= 6 else f\"{period}-01-01\"\n",
    "                            except Exception:\n",
    "                                as_of = f\"{period}-01-01\"\n",
    "                            rows.append(normalize_indicator_row(\n",
    "                                source=\"imf_commodity_prices\",\n",
    "                                ingested_at=ingested_at,\n",
    "                                as_of_date=as_of,\n",
    "                                country_code=\"\",\n",
    "                                indicator_code=str(code) if code else \"UNKNOWN\",\n",
    "                                indicator_name=str(name),\n",
    "                                value=float(val),\n",
    "                                unit=rec.get(\"Unit\") or rec.get(\"unit\"),\n",
    "                                frequency=\"monthly\",\n",
    "                                raw_payload=json.dumps(rec),\n",
    "                            ))\n",
    "                    if rows:\n",
    "                        return rows\n",
    "            else:\n",
    "                reader = csv.DictReader(io.StringIO(text))\n",
    "                for rec in reader:\n",
    "                    period = rec.get(\"Period\") or rec.get(\"Date\") or rec.get(\"Time Period\") or \"\"\n",
    "                    val = rec.get(\"Value\") or rec.get(\"value\")\n",
    "                    code = rec.get(\"Commodity\") or rec.get(\"Indicator\") or rec.get(\"indicator\") or \"\"\n",
    "                    name = rec.get(\"Commodity Name\") or rec.get(\"Indicator Name\") or code or \"Commodity\"\n",
    "                    if not period or val is None or str(val).strip() == \"\":\n",
    "                        continue\n",
    "                    try:\n",
    "                        value_float = float(val)\n",
    "                        as_of = f\"{str(period)[:4]}-{str(period)[4:6].zfill(2)}-01\" if len(str(period)) >= 6 else f\"{period}-01-01\"\n",
    "                    except (TypeError, ValueError):\n",
    "                        continue\n",
    "                    rows.append(normalize_indicator_row(\n",
    "                        source=\"imf_commodity_prices\",\n",
    "                        ingested_at=ingested_at,\n",
    "                        as_of_date=as_of,\n",
    "                        country_code=\"\",\n",
    "                        indicator_code=str(code) if code else \"UNKNOWN\",\n",
    "                        indicator_name=str(name),\n",
    "                        value=value_float,\n",
    "                        unit=rec.get(\"Unit\") or rec.get(\"unit\"),\n",
    "                        frequency=\"monthly\",\n",
    "                        raw_payload=json.dumps(rec),\n",
    "                    ))\n",
    "                if rows:\n",
    "                    return rows\n",
    "        except Exception as e:\n",
    "            print(f\"IMF URL failed: {e}\")\n",
    "            continue\n",
    "    return rows\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest: yfinance + IMF\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "all_rows = []\n",
    "# yfinance (primary)\n",
    "print(\"Fetching commodity prices from yfinance...\")\n",
    "yf_rows = fetch_yfinance_commodity_rows(DEFENSE_COMMODITIES, years_back=5)\n",
    "if yf_rows:\n",
    "    all_rows.extend(yf_rows)\n",
    "    print(f\"Fetched {len(yf_rows)} yfinance commodity records\")\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        \"yfinance returned no data. Ensure the cluster has outbound internet access \"\n",
    "        \"and yfinance is installed (pip install yfinance).\"\n",
    "    )\n",
    "\n",
    "# IMF (additional; skip if unavailable)\n",
    "imf_rows = fetch_imf_commodity_rows()\n",
    "if imf_rows:\n",
    "    all_rows.extend(imf_rows)\n",
    "    print(f\"Fetched {len(imf_rows)} IMF commodity records\")\n",
    "else:\n",
    "    print(\"IMF PCPS unavailable; skipping (no redundant data).\")\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No commodity data (yfinance and IMF both failed).\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Spark DataFrame and merge into raw/bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "INDICATOR_SCHEMA = StructType([\n",
    "    StructField(\"source\", StringType(), False),\n",
    "    StructField(\"ingested_at\", StringType(), False),\n",
    "    StructField(\"as_of_date\", StringType(), False),\n",
    "    StructField(\"country_code\", StringType(), False),\n",
    "    StructField(\"indicator_code\", StringType(), False),\n",
    "    StructField(\"indicator_name\", StringType(), False),\n",
    "    StructField(\"value\", DoubleType(), True),\n",
    "    StructField(\"unit\", StringType(), True),\n",
    "    StructField(\"frequency\", StringType(), False),\n",
    "    StructField(\"raw_payload\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_raw = spark.createDataFrame(all_rows, INDICATOR_SCHEMA)\n",
    "df_raw = df_raw.withColumn(\"ingested_at\", F.col(\"ingested_at\").cast(TimestampType()))\n",
    "df_raw = df_raw.withColumn(\"as_of_date\", F.to_date(F.col(\"as_of_date\")))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.raw\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.bronze\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.silver\")\n",
    "\n",
    "raw_create_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {RAW_TABLE} (\n",
    "  source STRING NOT NULL,\n",
    "  ingested_at TIMESTAMP NOT NULL,\n",
    "  as_of_date DATE NOT NULL,\n",
    "  country_code STRING NOT NULL,\n",
    "  indicator_code STRING NOT NULL,\n",
    "  indicator_name STRING NOT NULL,\n",
    "  value DOUBLE,\n",
    "  unit STRING,\n",
    "  frequency STRING NOT NULL,\n",
    "  raw_payload STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(raw_create_sql)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "dt_raw = DeltaTable.forName(spark, RAW_TABLE)\n",
    "dt_raw.alias(\"t\").merge(\n",
    "    df_raw.alias(\"s\"),\n",
    "    \"t.source = s.source AND t.indicator_code = s.indicator_code AND t.country_code = s.country_code AND t.as_of_date = s.as_of_date\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "raw_count = spark.table(RAW_TABLE).count()\n",
    "print(f\"Raw row count after merge: {raw_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bronze_df = spark.table(RAW_TABLE)\n",
    "bronze_create_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {BRONZE_TABLE} (\n",
    "  source STRING NOT NULL,\n",
    "  ingested_at TIMESTAMP NOT NULL,\n",
    "  as_of_date DATE NOT NULL,\n",
    "  country_code STRING NOT NULL,\n",
    "  indicator_code STRING NOT NULL,\n",
    "  indicator_name STRING NOT NULL,\n",
    "  value DOUBLE,\n",
    "  unit STRING,\n",
    "  frequency STRING NOT NULL,\n",
    "  raw_payload STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(bronze_create_sql)\n",
    "dt_bronze = DeltaTable.forName(spark, BRONZE_TABLE)\n",
    "dt_bronze.alias(\"t\").merge(\n",
    "    bronze_df.alias(\"s\"),\n",
    "    \"t.source = s.source AND t.indicator_code = s.indicator_code AND t.country_code = s.country_code AND t.as_of_date = s.as_of_date\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "bronze_count = spark.table(BRONZE_TABLE).count()\n",
    "print(f\"Bronze row count after merge: {bronze_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver: cost-pressure metrics (yfinance only)\n",
    "\n",
    "Build `commodity_prices_monthly` from bronze where source = 'yfinance_commodity'; compute pct_change and cost_pressure_score in Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "yf_bronze = spark.table(BRONZE_TABLE).filter(F.col(\"source\") == \"yfinance_commodity\")\n",
    "window = Window.partitionBy(\"indicator_code\").orderBy(F.col(\"as_of_date\"))\n",
    "\n",
    "silver_base = yf_bronze \\\n",
    "    .withColumn(\"month\", F.col(\"as_of_date\").cast(\"string\")) \\\n",
    "    .withColumn(\"close_price\", F.col(\"value\")) \\\n",
    "    .withColumn(\"prev_1\", F.lag(\"value\", 1).over(window)) \\\n",
    "    .withColumn(\"prev_3\", F.lag(\"value\", 3).over(window)) \\\n",
    "    .withColumn(\"prev_12\", F.lag(\"value\", 12).over(window)) \\\n",
    "    .withColumn(\"pct_change_1mo\", F.when(F.col(\"prev_1\").isNotNull() & (F.col(\"prev_1\") != 0), (F.col(\"value\") - F.col(\"prev_1\")) / F.col(\"prev_1\") * 100).otherwise(None)) \\\n",
    "    .withColumn(\"pct_change_3mo\", F.when(F.col(\"prev_3\").isNotNull() & (F.col(\"prev_3\") != 0), (F.col(\"value\") - F.col(\"prev_3\")) / F.col(\"prev_3\") * 100).otherwise(None)) \\\n",
    "    .withColumn(\"pct_change_12mo\", F.when(F.col(\"prev_12\").isNotNull() & (F.col(\"prev_12\") != 0), (F.col(\"value\") - F.col(\"prev_12\")) / F.col(\"prev_12\") * 100).otherwise(None)) \\\n",
    "    .withColumn(\"ticker\", F.col(\"indicator_code\")) \\\n",
    "    .withColumn(\"commodity_name\", F.col(\"indicator_name\")) \\\n",
    "    .withColumn(\"month_date\", F.col(\"as_of_date\")) \\\n",
    "    .withColumn(\"price_direction\",\n",
    "        F.when(F.col(\"pct_change_1mo\") > 5, \"RISING_FAST\")\n",
    "         .when(F.col(\"pct_change_1mo\") > 0, \"RISING\")\n",
    "         .when(F.col(\"pct_change_1mo\") > -5, \"FALLING\")\n",
    "         .otherwise(\"FALLING_FAST\")) \\\n",
    "    .withColumn(\"volatility_flag\",\n",
    "        F.when(F.abs(F.col(\"pct_change_1mo\")) > 10, \"HIGH_VOLATILITY\")\n",
    "         .when(F.abs(F.col(\"pct_change_1mo\")) > 5, \"MODERATE_VOLATILITY\")\n",
    "         .otherwise(\"LOW_VOLATILITY\")) \\\n",
    "    .withColumn(\"cost_pressure_score\",\n",
    "        F.coalesce(F.col(\"pct_change_3mo\"), F.lit(0)) * 0.5 +\n",
    "        F.coalesce(F.col(\"pct_change_1mo\"), F.lit(0)) * 0.3 +\n",
    "        F.coalesce(F.col(\"pct_change_12mo\"), F.lit(0)) * 0.2) \\\n",
    "    .withColumn(\"ingestion_timestamp\", F.current_timestamp())\n",
    "\n",
    "meta_pd = pd.DataFrame([{\"ticker\": k, \"category\": v[\"category\"], \"defense_use\": v[\"defense_use\"]} for k, v in DEFENSE_COMMODITIES.items()])\n",
    "meta_spark = spark.createDataFrame(meta_pd)\n",
    "commodity_enriched = silver_base.join(meta_spark, silver_base.ticker == meta_spark.ticker, \"left\") \\\n",
    "    .select(\n",
    "        silver_base[\"month\"], silver_base[\"ticker\"], silver_base[\"commodity_name\"],\n",
    "        F.coalesce(meta_spark[\"category\"], F.lit(\"OTHER\")).alias(\"category\"),\n",
    "        F.coalesce(meta_spark[\"defense_use\"], F.lit(\"\")).alias(\"defense_use\"),\n",
    "        silver_base[\"unit\"], silver_base[\"close_price\"],\n",
    "        silver_base[\"pct_change_1mo\"], silver_base[\"pct_change_3mo\"], silver_base[\"pct_change_12mo\"],\n",
    "        silver_base[\"month_date\"], silver_base[\"price_direction\"], silver_base[\"volatility_flag\"],\n",
    "        silver_base[\"cost_pressure_score\"], silver_base[\"ingestion_timestamp\"]\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "commodity_enriched.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(SILVER_TABLE)\n",
    "\n",
    "silver_count = spark.table(SILVER_TABLE).count()\n",
    "print(f\"Saved {silver_count} records to {SILVER_TABLE}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log row counts and sample\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== Commodity Ingestion (yfinance + IMF) ===\")\n",
    "print(f\"Raw {RAW_TABLE}: {raw_count} rows\")\n",
    "print(f\"Bronze {BRONZE_TABLE}: {bronze_count} rows\")\n",
    "print(f\"Silver {SILVER_TABLE}: {silver_count} rows (yfinance only)\")\n",
    "display(spark.table(RAW_TABLE).orderBy(F.desc(\"as_of_date\")).limit(10))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display(commodity_enriched.filter(F.col(\"month\") >= \"2024-01-01\").orderBy(F.desc(\"month\"), \"category\").limit(15))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables: `supply_chain.raw.commodity_prices`, `supply_chain.bronze.commodity_prices`, `supply_chain.silver.commodity_prices_monthly`. Idempotent merge on (source, indicator_code, country_code, as_of_date). IMF data in raw/bronze only; silver is yfinance-only for cost-pressure metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run `08_weather_ingestion` for weather risk data\n",
    "2. Proceed to transformation notebooks for unified demand signals\n"
   ]
  }
 ]
}