{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NY Fed Global Supply Chain Pressure Index (GSCPI) Ingestion\n",
    "\n",
    "**Executive summary:** Ingests the NY Fed Global Supply Chain Pressure Index (monthly) into raw and bronze. Used as a structured supply chain risk indicator.\n",
    "\n",
    "**Data Source**: NY Fed GSCPI. Tries known CSV/JSON URLs; fails gracefully with clear message if unavailable. Data is at https://www.newyorkfed.org/research/policy/gscpi (download from page or API if exposed).\n",
    "\n",
    "**Target Tables** (Unity Catalog):\n",
    "- `supply_chain.raw.nyfed_gscpi` - Raw GSCPI observations\n",
    "- `supply_chain.bronze.nyfed_gscpi` - Cleaned with typed columns\n",
    "\n",
    "**Idempotency:** Delta merge on (source, indicator_code, country_code, as_of_date). country_code = \"\" (global index).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import csv\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, TimestampType, DateType,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CATALOG = \"supply_chain\"\n",
    "RAW_TABLE = f\"{CATALOG}.raw.nyfed_gscpi\"\n",
    "BRONZE_TABLE = f\"{CATALOG}.bronze.nyfed_gscpi\"\n",
    "\n",
    "# Possible GSCPI data URLs (NY Fed may change paths)\n",
    "GSCPI_URLS = [\n",
    "    \"https://www.newyorkfed.org/medialibrary/media/research/policy/gscpi/gscpi_data.csv\",\n",
    "    \"https://resources.newyorkfed.org/research/policy/gscpi/gscpi_data.csv\",\n",
    "    \"https://www.newyorkfed.org/research/policy/gscpi/data/gscpi_data.csv\",\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared HTTP helper\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "for _p in [os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in dir() else \"\", os.getcwd(), \"/Workspace/Repos\", \".\"]:\n",
    "    if _p and _p not in sys.path:\n",
    "        sys.path.insert(0, _p)\n",
    "try:\n",
    "    from ingestion_utils import safe_get, parse_json, normalize_indicator_row\n",
    "except ImportError:\n",
    "    import requests\n",
    "    import time\n",
    "    def safe_get(url, *, timeout=60, retries=3, backoff=2.0, headers=None):\n",
    "        last = None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                r = requests.get(url, timeout=timeout, headers=headers or {})\n",
    "                r.raise_for_status()\n",
    "                return r\n",
    "            except Exception as e:\n",
    "                last = e\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(backoff ** attempt)\n",
    "        raise last\n",
    "    def parse_json(text):\n",
    "        return json.loads(text)\n",
    "    def normalize_indicator_row(*, source, ingested_at, as_of_date, country_code, indicator_code, indicator_name, value, unit, frequency, raw_payload=None):\n",
    "        return {\"source\": source, \"ingested_at\": ingested_at, \"as_of_date\": as_of_date, \"country_code\": country_code or \"\", \"indicator_code\": indicator_code, \"indicator_name\": indicator_name, \"value\": float(value) if value is not None else None, \"unit\": unit, \"frequency\": frequency, \"raw_payload\": raw_payload}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch GSCPI data\n",
    "\n",
    "Tries each URL; parses CSV or JSON. Fails with clear message if none work.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fetch_nyfed_gscpi() -> list:\n",
    "    \"\"\"\n",
    "    Fetch NY Fed GSCPI (monthly). Tries configured URLs; returns list of normalized row dicts.\n",
    "    \"\"\"\n",
    "    ingested_at = datetime.utcnow().isoformat() + \"Z\"\n",
    "    rows = []\n",
    "    last_exc = None\n",
    "\n",
    "    for url in GSCPI_URLS:\n",
    "        try:\n",
    "            r = safe_get(url, timeout=60)\n",
    "            text = r.text.strip()\n",
    "            if not text or \"Page Not Found\" in text or \"does not exist\" in text:\n",
    "                continue\n",
    "            # CSV: expect Date, GSCPI or similar columns\n",
    "            if \"\\n\" in text and (\",\" in text or \"\\t\" in text):\n",
    "                sep = \"\\t\" if \"\\t\" in text.split(\"\\n\")[0] else \",\"\n",
    "                reader = csv.DictReader(io.StringIO(text), delimiter=sep)\n",
    "                for rec in reader:\n",
    "                    date_str = rec.get(\"Date\") or rec.get(\"date\") or rec.get(\"Month\") or \"\"\n",
    "                    val = rec.get(\"GSCPI\") or rec.get(\"gscpi\") or rec.get(\"Value\") or rec.get(\"value\")\n",
    "                    if not date_str or val is None or str(val).strip() == \"\":\n",
    "                        continue\n",
    "                    try:\n",
    "                        value_float = float(val)\n",
    "                    except (TypeError, ValueError):\n",
    "                        continue\n",
    "                    # Normalize date to YYYY-MM-01\n",
    "                    match = re.match(r\"(\\d{4})[-/]?(\\d{1,2})?\", str(date_str))\n",
    "                    if match:\n",
    "                        y, m = match.group(1), (match.group(2) or \"1\").zfill(2)\n",
    "                        as_of_date = f\"{y}-{m}-01\"\n",
    "                    else:\n",
    "                        as_of_date = str(date_str)[:10] if len(str(date_str)) >= 10 else f\"{date_str}-01-01\"\n",
    "                    row = normalize_indicator_row(\n",
    "                        source=\"nyfed_gscpi\",\n",
    "                        ingested_at=ingested_at,\n",
    "                        as_of_date=as_of_date,\n",
    "                        country_code=\"\",\n",
    "                        indicator_code=\"GSCPI\",\n",
    "                        indicator_name=\"Global Supply Chain Pressure Index\",\n",
    "                        value=value_float,\n",
    "                        unit=\"index\",\n",
    "                        frequency=\"monthly\",\n",
    "                        raw_payload=json.dumps(rec),\n",
    "                    )\n",
    "                    rows.append(row)\n",
    "                if rows:\n",
    "                    return rows\n",
    "            # JSON\n",
    "            if text.startswith(\"[\") or text.startswith(\"{\"):\n",
    "                try:\n",
    "                    data = parse_json(text)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if isinstance(data, list):\n",
    "                    for rec in data:\n",
    "                        if not isinstance(rec, dict):\n",
    "                            continue\n",
    "                        date_str = rec.get(\"Date\") or rec.get(\"date\") or rec.get(\"Month\")\n",
    "                        val = rec.get(\"GSCPI\") or rec.get(\"gscpi\") or rec.get(\"value\")\n",
    "                        if date_str is None or val is None:\n",
    "                            continue\n",
    "                        try:\n",
    "                            value_float = float(val)\n",
    "                        except (TypeError, ValueError):\n",
    "                            continue\n",
    "                        as_of_date = str(date_str)[:10] if len(str(date_str)) >= 10 else f\"{date_str}-01-01\"\n",
    "                        row = normalize_indicator_row(\n",
    "                            source=\"nyfed_gscpi\",\n",
    "                            ingested_at=ingested_at,\n",
    "                            as_of_date=as_of_date,\n",
    "                            country_code=\"\",\n",
    "                            indicator_code=\"GSCPI\",\n",
    "                            indicator_name=\"Global Supply Chain Pressure Index\",\n",
    "                            value=value_float,\n",
    "                            unit=\"index\",\n",
    "                            frequency=\"monthly\",\n",
    "                            raw_payload=json.dumps(rec),\n",
    "                        )\n",
    "                        rows.append(row)\n",
    "                    if rows:\n",
    "                        return rows\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            print(f\"GSCPI URL {url[:60]}... failed: {e}\")\n",
    "            continue\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"NY Fed GSCPI data unavailable: all configured URLs failed or returned no data. \"\n",
    "        \"Check https://www.newyorkfed.org/research/policy/gscpi for current download option and update GSCPI_URLS in this notebook.\"\n",
    "    ) from last_exc\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    all_rows = fetch_nyfed_gscpi()\n",
    "    print(f\"Fetched {len(all_rows)} GSCPI records\")\n",
    "except RuntimeError as e:\n",
    "    print(str(e))\n",
    "    raise\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Spark DataFrame and schema\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "INDICATOR_RAW_SCHEMA = StructType([\n",
    "    StructField(\"source\", StringType(), False),\n",
    "    StructField(\"ingested_at\", StringType(), False),\n",
    "    StructField(\"as_of_date\", StringType(), False),\n",
    "    StructField(\"country_code\", StringType(), False),\n",
    "    StructField(\"indicator_code\", StringType(), False),\n",
    "    StructField(\"indicator_name\", StringType(), False),\n",
    "    StructField(\"value\", DoubleType(), True),\n",
    "    StructField(\"unit\", StringType(), True),\n",
    "    StructField(\"frequency\", StringType(), False),\n",
    "    StructField(\"raw_payload\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_raw = spark.createDataFrame(all_rows, INDICATOR_RAW_SCHEMA)\n",
    "df_raw = df_raw.withColumn(\"ingested_at\", F.col(\"ingested_at\").cast(TimestampType()))\n",
    "df_raw = df_raw.withColumn(\"as_of_date\", F.to_date(F.col(\"as_of_date\")))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unity Catalog and idempotent merge (raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.raw\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.bronze\")\n",
    "print(f\"Catalog {CATALOG}, schemas raw/bronze ready.\")\n",
    "\n",
    "raw_create_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {RAW_TABLE} (\n",
    "  source STRING NOT NULL,\n",
    "  ingested_at TIMESTAMP NOT NULL,\n",
    "  as_of_date DATE NOT NULL,\n",
    "  country_code STRING NOT NULL,\n",
    "  indicator_code STRING NOT NULL,\n",
    "  indicator_name STRING NOT NULL,\n",
    "  value DOUBLE,\n",
    "  unit STRING,\n",
    "  frequency STRING NOT NULL,\n",
    "  raw_payload STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(raw_create_sql)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "dt_raw = DeltaTable.forName(spark, RAW_TABLE)\n",
    "dt_raw.alias(\"t\").merge(\n",
    "    df_raw.alias(\"s\"),\n",
    "    \"t.source = s.source AND t.indicator_code = s.indicator_code AND t.country_code = s.country_code AND t.as_of_date = s.as_of_date\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "raw_count = spark.table(RAW_TABLE).count()\n",
    "print(f\"Raw table row count after merge: {raw_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bronze_df = spark.table(RAW_TABLE).select(\n",
    "    F.col(\"source\"), F.col(\"ingested_at\"), F.col(\"as_of_date\"), F.col(\"country_code\"),\n",
    "    F.col(\"indicator_code\"), F.col(\"indicator_name\"), F.col(\"value\"), F.col(\"unit\"),\n",
    "    F.col(\"frequency\"), F.col(\"raw_payload\"),\n",
    ")\n",
    "bronze_create_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {BRONZE_TABLE} (\n",
    "  source STRING NOT NULL,\n",
    "  ingested_at TIMESTAMP NOT NULL,\n",
    "  as_of_date DATE NOT NULL,\n",
    "  country_code STRING NOT NULL,\n",
    "  indicator_code STRING NOT NULL,\n",
    "  indicator_name STRING NOT NULL,\n",
    "  value DOUBLE,\n",
    "  unit STRING,\n",
    "  frequency STRING NOT NULL,\n",
    "  raw_payload STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(bronze_create_sql)\n",
    "dt_bronze = DeltaTable.forName(spark, BRONZE_TABLE)\n",
    "dt_bronze.alias(\"t\").merge(\n",
    "    bronze_df.alias(\"s\"),\n",
    "    \"t.source = s.source AND t.indicator_code = s.indicator_code AND t.country_code = s.country_code AND t.as_of_date = s.as_of_date\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "\n",
    "bronze_count = spark.table(BRONZE_TABLE).count()\n",
    "print(f\"Bronze table row count after merge: {bronze_count}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log row counts and sample\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== NY Fed GSCPI Ingestion ===\")\n",
    "print(f\"Raw {RAW_TABLE}: {raw_count} rows\")\n",
    "print(f\"Bronze {BRONZE_TABLE}: {bronze_count} rows\")\n",
    "display(spark.table(RAW_TABLE).orderBy(F.desc(\"as_of_date\")).limit(10))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables: `supply_chain.raw.nyfed_gscpi`, `supply_chain.bronze.nyfed_gscpi`. Idempotent merge on (source, indicator_code, country_code, as_of_date).\n"
   ]
  }
 ]
}