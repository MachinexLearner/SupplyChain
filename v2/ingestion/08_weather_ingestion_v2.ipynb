{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Risk Data Ingestion\n",
    "\n",
    "**Executive summary:** Loads weather and climate risk for key supply chain locations into silver (monthly disruption index) using real Meteostat data. Management: feeds combined risk and weather scenario tools.\n",
    "\n",
    "**Data Sources**:\n",
    "- Meteostat (free Python library) - real historical weather observations\n",
    "- NOAA bulk climate data (no key required)\n",
    "\n",
    "**Target Tables** (Unity Catalog):\n",
    "- `supply_chain.silver.weather_risk_monthly` - Monthly weather risk indicators\n",
    "\n",
    "**Requirements:** Cluster must have outbound internet access. Install meteostat via `%pip install meteostat`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install meteostat\n",
    "%pip install meteostat pandas\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Meteostat v2 uses lowercase monthly(); v1 used Monthly class\n",
    "try:\n",
    "    from meteostat import Point, monthly\n",
    "    _METEO_MONTHLY_CALLABLE = monthly\n",
    "    _METEO_IS_V2 = True\n",
    "except ImportError:\n",
    "    from meteostat import Point, Monthly\n",
    "    _METEO_MONTHLY_CALLABLE = lambda point, start, end: Monthly(point, start, end).fetch()\n",
    "    _METEO_IS_V2 = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configuration - Unity Catalog\n",
    "CATALOG = \"supply_chain\"\n",
    "SILVER_TABLE = f\"{CATALOG}.silver.weather_risk_monthly\"\n",
    "\n",
    "# Key locations for Oshkosh Defense supply chain\n",
    "# Manufacturing facilities, major suppliers, and logistics hubs\n",
    "SUPPLY_CHAIN_LOCATIONS = {\n",
    "    # Oshkosh facilities\n",
    "    'oshkosh_hq': {\n",
    "        'name': 'Oshkosh HQ',\n",
    "        'city': 'Oshkosh',\n",
    "        'state': 'WI',\n",
    "        'lat': 44.0247,\n",
    "        'lon': -88.5426,\n",
    "        'type': 'MANUFACTURING'\n",
    "    },\n",
    "    'appleton': {\n",
    "        'name': 'Pierce Manufacturing',\n",
    "        'city': 'Appleton',\n",
    "        'state': 'WI',\n",
    "        'lat': 44.2619,\n",
    "        'lon': -88.4154,\n",
    "        'type': 'MANUFACTURING'\n",
    "    },\n",
    "    \n",
    "    # Major supplier locations\n",
    "    'detroit': {\n",
    "        'name': 'Detroit Metro (Powertrain)',\n",
    "        'city': 'Detroit',\n",
    "        'state': 'MI',\n",
    "        'lat': 42.3314,\n",
    "        'lon': -83.0458,\n",
    "        'type': 'SUPPLIER_HUB'\n",
    "    },\n",
    "    'indianapolis': {\n",
    "        'name': 'Indianapolis (Allison)',\n",
    "        'city': 'Indianapolis',\n",
    "        'state': 'IN',\n",
    "        'lat': 39.7684,\n",
    "        'lon': -86.1581,\n",
    "        'type': 'SUPPLIER'\n",
    "    },\n",
    "    'cleveland': {\n",
    "        'name': 'Cleveland (Parker/Eaton)',\n",
    "        'city': 'Cleveland',\n",
    "        'state': 'OH',\n",
    "        'lat': 41.4993,\n",
    "        'lon': -81.6944,\n",
    "        'type': 'SUPPLIER_HUB'\n",
    "    },\n",
    "    'pittsburgh': {\n",
    "        'name': 'Pittsburgh (Steel/Materials)',\n",
    "        'city': 'Pittsburgh',\n",
    "        'state': 'PA',\n",
    "        'lat': 40.4406,\n",
    "        'lon': -79.9959,\n",
    "        'type': 'SUPPLIER_HUB'\n",
    "    },\n",
    "    \n",
    "    # Logistics hubs\n",
    "    'chicago': {\n",
    "        'name': 'Chicago Logistics Hub',\n",
    "        'city': 'Chicago',\n",
    "        'state': 'IL',\n",
    "        'lat': 41.8781,\n",
    "        'lon': -87.6298,\n",
    "        'type': 'LOGISTICS'\n",
    "    },\n",
    "    'houston': {\n",
    "        'name': 'Houston Port',\n",
    "        'city': 'Houston',\n",
    "        'state': 'TX',\n",
    "        'lat': 29.7604,\n",
    "        'lon': -95.3698,\n",
    "        'type': 'PORT'\n",
    "    },\n",
    "    'los_angeles': {\n",
    "        'name': 'Los Angeles Port',\n",
    "        'city': 'Los Angeles',\n",
    "        'state': 'CA',\n",
    "        'lat': 33.9425,\n",
    "        'lon': -118.4081,\n",
    "        'type': 'PORT'\n",
    "    },\n",
    "    \n",
    "    # Military depot locations\n",
    "    'anniston': {\n",
    "        'name': 'Anniston Army Depot',\n",
    "        'city': 'Anniston',\n",
    "        'state': 'AL',\n",
    "        'lat': 33.6598,\n",
    "        'lon': -85.8316,\n",
    "        'type': 'DEPOT'\n",
    "    },\n",
    "    'red_river': {\n",
    "        'name': 'Red River Army Depot',\n",
    "        'city': 'Texarkana',\n",
    "        'state': 'TX',\n",
    "        'lat': 33.4418,\n",
    "        'lon': -94.0477,\n",
    "        'type': 'DEPOT'\n",
    "    },\n",
    "}\n",
    "\n",
    "# Weather thresholds for disruption risk\n",
    "WEATHER_THRESHOLDS = {\n",
    "    'extreme_heat_temp_c': 35,      # Above 35\u00b0C = extreme heat\n",
    "    'extreme_cold_temp_c': -15,     # Below -15\u00b0C = extreme cold\n",
    "    'heavy_precip_mm': 100,         # Above 100mm monthly = heavy precipitation\n",
    "    'drought_precip_mm': 10,        # Below 10mm monthly = drought conditions\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Weather Data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fetch_weather_data(locations: dict, years_back: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch historical weather data from Meteostat.\n",
    "    \n",
    "    Args:\n",
    "        locations: Dictionary of location metadata\n",
    "        years_back: Number of years of history to fetch\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with monthly weather data\n",
    "    \"\"\"\n",
    "    end_date = datetime.now()\n",
    "    start_date = datetime(end_date.year - years_back, 1, 1)\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for loc_id, loc_info in locations.items():\n",
    "        print(f\"Fetching weather for {loc_info['name']}...\")\n",
    "        try:\n",
    "            # Create point\n",
    "            point = Point(loc_info['lat'], loc_info['lon'])\n",
    "            \n",
    "            # Get monthly data (meteostat v2: monthly() returns DataFrame or None; v1: Monthly().fetch())\n",
    "            data = _METEO_MONTHLY_CALLABLE(point, start_date, end_date)\n",
    "            if data is None:\n",
    "                data = pd.DataFrame()\n",
    "            elif not isinstance(data, pd.DataFrame):\n",
    "                data = data.fetch() if hasattr(data, 'fetch') else pd.DataFrame(data)\n",
    "            if data is None:\n",
    "                data = pd.DataFrame()\n",
    "            \n",
    "            if data.empty:\n",
    "                print(f\"  No data available for {loc_info['name']}\")\n",
    "                continue\n",
    "            \n",
    "            # v2 uses 'time' column; v1 uses index as date\n",
    "            if 'time' in data.columns and not isinstance(data.index, pd.DatetimeIndex):\n",
    "                data = data.set_index('time')\n",
    "            \n",
    "            for date, row in data.iterrows():\n",
    "                all_data.append({\n",
    "                    'month': date.strftime('%Y-%m-%d'),\n",
    "                    'location_id': loc_id,\n",
    "                    'location_name': loc_info['name'],\n",
    "                    'city': loc_info['city'],\n",
    "                    'state': loc_info['state'],\n",
    "                    'lat': loc_info['lat'],\n",
    "                    'lon': loc_info['lon'],\n",
    "                    'location_type': loc_info['type'],\n",
    "                    'tavg': row.get('tavg'),      # Average temperature\n",
    "                    'tmin': row.get('tmin'),      # Minimum temperature\n",
    "                    'tmax': row.get('tmax'),      # Maximum temperature\n",
    "                    'prcp': row.get('prcp'),      # Precipitation\n",
    "                    'snow': row.get('snow'),      # Snowfall\n",
    "                    'wdir': row.get('wdir'),      # Wind direction\n",
    "                    'wspd': row.get('wspd'),      # Wind speed\n",
    "                    'pres': row.get('pres'),      # Pressure\n",
    "                })\n",
    "            \n",
    "            print(f\"  Retrieved {len(data)} months of data\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error fetching {loc_info['name']}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Fetching weather data from Meteostat...\")\n",
    "weather_df = fetch_weather_data(SUPPLY_CHAIN_LOCATIONS, years_back=5)\n",
    "if weather_df.empty:\n",
    "    raise RuntimeError(\n",
    "        \"Meteostat returned no data. Ensure the cluster has outbound internet access \"\n",
    "        \"and meteostat is installed (pip install meteostat). Check that Meteostat's \"\n",
    "        \"data servers are reachable.\"\n",
    "    )\n",
    "print(f\"Successfully fetched {len(weather_df)} records from Meteostat\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert to Spark DataFrame\n",
    "spark_weather = spark.createDataFrame(weather_df)\n",
    "\n",
    "# Display schema\n",
    "print(\"Weather Data Schema:\")\n",
    "spark_weather.printSchema()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display sample\n",
    "display(spark_weather.filter(F.col(\"month\") >= \"2024-01-01\").orderBy(\"month\", \"location_id\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Weather Risk Indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Add weather risk indicators\n",
    "weather_risk = spark_weather \\\n",
    "    .withColumn(\"month_date\", F.to_date(F.col(\"month\"))) \\\n",
    "    .withColumn(\"extreme_heat_days\",\n",
    "        F.when(F.col(\"tmax\") > WEATHER_THRESHOLDS['extreme_heat_temp_c'], \n",
    "               F.lit(15)).otherwise(F.lit(0))  # Estimate days based on monthly max\n",
    "    ) \\\n",
    "    .withColumn(\"extreme_cold_days\",\n",
    "        F.when(F.col(\"tmin\") < WEATHER_THRESHOLDS['extreme_cold_temp_c'], \n",
    "               F.lit(15)).otherwise(F.lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\"precipitation_anomaly\",\n",
    "        F.when(F.col(\"prcp\") > WEATHER_THRESHOLDS['heavy_precip_mm'], \"HEAVY\")\n",
    "         .when(F.col(\"prcp\") < WEATHER_THRESHOLDS['drought_precip_mm'], \"DROUGHT\")\n",
    "         .otherwise(\"NORMAL\")\n",
    "    ) \\\n",
    "    .withColumn(\"storm_event_count\",\n",
    "        # Estimate based on precipitation and wind\n",
    "        F.when((F.col(\"prcp\") > 80) & (F.col(\"wspd\") > 15), F.lit(3))\n",
    "         .when((F.col(\"prcp\") > 50) | (F.col(\"wspd\") > 20), F.lit(1))\n",
    "         .otherwise(F.lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\"snow_disruption_risk\",\n",
    "        F.when(F.col(\"snow\") > 50, \"HIGH\")\n",
    "         .when(F.col(\"snow\") > 20, \"MODERATE\")\n",
    "         .when(F.col(\"snow\") > 0, \"LOW\")\n",
    "         .otherwise(\"NONE\")\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate weather disruption index (0-100 scale)\n",
    "weather_risk_final = weather_risk \\\n",
    "    .withColumn(\"heat_score\",\n",
    "        F.col(\"extreme_heat_days\") / 30 * 25\n",
    "    ) \\\n",
    "    .withColumn(\"cold_score\",\n",
    "        F.col(\"extreme_cold_days\") / 30 * 25\n",
    "    ) \\\n",
    "    .withColumn(\"precip_score\",\n",
    "        F.when(F.col(\"precipitation_anomaly\") == \"HEAVY\", F.lit(20))\n",
    "         .when(F.col(\"precipitation_anomaly\") == \"DROUGHT\", F.lit(15))\n",
    "         .otherwise(F.lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\"storm_score\",\n",
    "        F.col(\"storm_event_count\") * 10\n",
    "    ) \\\n",
    "    .withColumn(\"snow_score\",\n",
    "        F.when(F.col(\"snow_disruption_risk\") == \"HIGH\", F.lit(20))\n",
    "         .when(F.col(\"snow_disruption_risk\") == \"MODERATE\", F.lit(10))\n",
    "         .when(F.col(\"snow_disruption_risk\") == \"LOW\", F.lit(5))\n",
    "         .otherwise(F.lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\"weather_disruption_index\",\n",
    "        F.least(\n",
    "            F.col(\"heat_score\") + F.col(\"cold_score\") + F.col(\"precip_score\") + \n",
    "            F.col(\"storm_score\") + F.col(\"snow_score\"),\n",
    "            F.lit(100)\n",
    "        )\n",
    "    ) \\\n",
    "    .withColumn(\"disruption_risk_level\",\n",
    "        F.when(F.col(\"weather_disruption_index\") >= 50, \"HIGH\")\n",
    "         .when(F.col(\"weather_disruption_index\") >= 25, \"MODERATE\")\n",
    "         .otherwise(\"LOW\")\n",
    "    ) \\\n",
    "    .select(\n",
    "        \"month\",\n",
    "        \"month_date\",\n",
    "        \"location_id\",\n",
    "        \"location_name\",\n",
    "        \"city\",\n",
    "        \"state\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"location_type\",\n",
    "        \"tavg\",\n",
    "        \"tmin\",\n",
    "        \"tmax\",\n",
    "        \"prcp\",\n",
    "        \"snow\",\n",
    "        \"wspd\",\n",
    "        \"extreme_heat_days\",\n",
    "        \"extreme_cold_days\",\n",
    "        \"precipitation_anomaly\",\n",
    "        \"storm_event_count\",\n",
    "        \"snow_disruption_risk\",\n",
    "        \"weather_disruption_index\",\n",
    "        \"disruption_risk_level\"\n",
    "    ) \\\n",
    "    .withColumn(\"ingestion_timestamp\", F.current_timestamp())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display enriched data\n",
    "display(weather_risk_final.filter(F.col(\"month\") >= \"2024-01-01\").orderBy(F.desc(\"weather_disruption_index\")).limit(20))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unity Catalog setup and Save to Silver Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.silver\")\n",
    "print(f\"Catalog {CATALOG} and schema silver ready.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save to silver layer (Unity Catalog)\n",
    "weather_risk_final.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(SILVER_TABLE)\n",
    "\n",
    "print(f\"Saved {weather_risk_final.count()} records to {SILVER_TABLE}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Risk Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Current weather risk by location\n",
    "print(\"=== Current Weather Risk by Location ===\")\n",
    "latest_month = weather_risk_final.agg(F.max(\"month\")).collect()[0][0]\n",
    "\n",
    "display(weather_risk_final.filter(F.col(\"month\") == latest_month) \\\n",
    "    .select(\"location_name\", \"state\", \"location_type\", \"tavg\", \"prcp\", \"snow\", \n",
    "            \"weather_disruption_index\", \"disruption_risk_level\") \\\n",
    "    .orderBy(F.desc(\"weather_disruption_index\")))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Weather risk by location type\n",
    "print(\"\\n=== Average Weather Risk by Location Type ===\")\n",
    "display(weather_risk_final \\\n",
    "    .filter(F.col(\"month\") >= F.add_months(F.current_date(), -12)) \\\n",
    "    .groupBy(\"location_type\") \\\n",
    "    .agg(\n",
    "        F.avg(\"weather_disruption_index\").alias(\"avg_disruption_index\"),\n",
    "        F.sum(\"storm_event_count\").alias(\"total_storm_events\"),\n",
    "        F.avg(\"extreme_heat_days\").alias(\"avg_heat_days\"),\n",
    "        F.avg(\"extreme_cold_days\").alias(\"avg_cold_days\")\n",
    "    ) \\\n",
    "    .orderBy(F.desc(\"avg_disruption_index\")))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Seasonal weather patterns\n",
    "print(\"\\n=== Seasonal Weather Patterns (Last 12 Months) ===\")\n",
    "display(weather_risk_final \\\n",
    "    .filter(F.col(\"month\") >= F.add_months(F.current_date(), -12)) \\\n",
    "    .groupBy(\"month_date\") \\\n",
    "    .agg(\n",
    "        F.avg(\"weather_disruption_index\").alias(\"avg_disruption_index\"),\n",
    "        F.avg(\"tavg\").alias(\"avg_temp\"),\n",
    "        F.sum(\"prcp\").alias(\"total_precip\"),\n",
    "        F.sum(\"snow\").alias(\"total_snow\")\n",
    "    ) \\\n",
    "    .orderBy(\"month_date\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# High-risk weather events\n",
    "print(\"\\n=== High Weather Risk Events ===\")\n",
    "display(weather_risk_final \\\n",
    "    .filter(F.col(\"disruption_risk_level\") == \"HIGH\") \\\n",
    "    .select(\"month\", \"location_name\", \"state\", \"weather_disruption_index\", \n",
    "            \"extreme_heat_days\", \"extreme_cold_days\", \"storm_event_count\", \"snow\") \\\n",
    "    .orderBy(F.desc(\"month\"), F.desc(\"weather_disruption_index\")) \\\n",
    "    .limit(20))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table is in Unity Catalog: `supply_chain.silver.weather_risk_monthly`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Proceed to transformation notebooks to build unified demand signals\n",
    "2. Run `01_unified_demand_signals_v2` to combine all data sources\n",
    "3. Run `02_dod_metrics_inputs_v2` to calculate DoD metric inputs\n"
   ]
  }
 ]
}