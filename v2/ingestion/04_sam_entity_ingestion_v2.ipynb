{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM.gov Entity Data Ingestion (Live API)\n",
    "\n",
    "**Executive summary:** Fetches supplier entity and location data from the **SAM.gov Entity Management API v3** into raw and silver (supplier geolocations, distance to facilities). Searches by defense-relevant NAICS codes to find active registrants.\n",
    "\n",
    "**Data Source**: SAM.gov Entity Management API v3 \u2014 https://open.gsa.gov/api/entity-api/\n",
    "\n",
    "**Target Tables** (Unity Catalog):\n",
    "- `supply_chain.raw.sam_entity_export` \u2014 Raw SAM entity data\n",
    "- `supply_chain.silver.supplier_geolocations` \u2014 Geocoded supplier locations\n",
    "\n",
    "**API Key:** Obtain a free API key at https://sam.gov/content/entity-information \u2014 set via widget, env var `SAM_API_KEY`, or Databricks secret scope `supply_chain/sam_api_key`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# MAGIC %pip install requests pandas pyarrow\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Widget for API key (can also be set via env var or Databricks secrets)\n",
    "dbutils.widgets.text(\"sam_api_key\", \"SAM-45654ff9-9605-4e0a-bfe8-fb30e0d939e3\", \"SAM.gov API key (or set SAM_API_KEY env var)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configuration - Unity Catalog\n",
    "CATALOG = \"supply_chain\"\n",
    "RAW_TABLE = f\"{CATALOG}.raw.sam_entity_export\"\n",
    "SILVER_TABLE = f\"{CATALOG}.silver.supplier_geolocations\"\n",
    "\n",
    "# Oshkosh Defense facility locations for distance calculations\n",
    "OSHKOSH_FACILITIES = [\n",
    "    {'name': 'Oshkosh HQ', 'city': 'Oshkosh', 'state': 'WI', 'lat': 44.0247, 'lon': -88.5426},\n",
    "    {'name': 'Oshkosh Defense', 'city': 'Oshkosh', 'state': 'WI', 'lat': 44.0247, 'lon': -88.5426},\n",
    "    {'name': 'JLG Industries', 'city': 'McConnellsburg', 'state': 'PA', 'lat': 39.9326, 'lon': -77.9967},\n",
    "    {'name': 'Pierce Manufacturing', 'city': 'Appleton', 'state': 'WI', 'lat': 44.2619, 'lon': -88.4154},\n",
    "]\n",
    "\n",
    "# Region mapping for geopolitical analysis\n",
    "REGION_MAPPING = {\n",
    "    # Americas\n",
    "    'USA': 'AMERICAS', 'CAN': 'AMERICAS', 'MEX': 'AMERICAS', 'BRA': 'AMERICAS',\n",
    "    # Europe\n",
    "    'GBR': 'EUROPE', 'DEU': 'EUROPE', 'FRA': 'EUROPE', 'ITA': 'EUROPE', 'POL': 'EUROPE',\n",
    "    'ESP': 'EUROPE', 'NLD': 'EUROPE', 'BEL': 'EUROPE', 'AUT': 'EUROPE', 'CHE': 'EUROPE',\n",
    "    'SWE': 'EUROPE', 'NOR': 'EUROPE', 'DNK': 'EUROPE', 'FIN': 'EUROPE', 'CZE': 'EUROPE',\n",
    "    # Middle East\n",
    "    'ISR': 'MIDEAST', 'SAU': 'MIDEAST', 'ARE': 'MIDEAST', 'KWT': 'MIDEAST', 'QAT': 'MIDEAST',\n",
    "    'JOR': 'MIDEAST', 'IRQ': 'MIDEAST', 'TUR': 'MIDEAST',\n",
    "    # Indo-Pacific\n",
    "    'JPN': 'INDO_PACIFIC', 'KOR': 'INDO_PACIFIC', 'AUS': 'INDO_PACIFIC', 'TWN': 'INDO_PACIFIC',\n",
    "    'SGP': 'INDO_PACIFIC', 'THA': 'INDO_PACIFIC', 'PHL': 'INDO_PACIFIC', 'IND': 'INDO_PACIFIC',\n",
    "    'NZL': 'INDO_PACIFIC', 'MYS': 'INDO_PACIFIC', 'IDN': 'INDO_PACIFIC',\n",
    "    # Africa\n",
    "    'ZAF': 'AFRICA', 'EGY': 'AFRICA', 'MAR': 'AFRICA', 'NGA': 'AFRICA', 'KEN': 'AFRICA',\n",
    "    # China (separate for risk analysis)\n",
    "    'CHN': 'CHINA',\n",
    "}\n",
    "\n",
    "# Defense-relevant NAICS codes\n",
    "DEFENSE_NAICS_CODES = {\n",
    "    '336120': 'Heavy Duty Truck Manufacturing',\n",
    "    '336211': 'Motor Vehicle Body Manufacturing',\n",
    "    '336992': 'Military Armored Vehicle Manufacturing',\n",
    "    '336999': 'Other Transportation Equipment Manufacturing',\n",
    "    '332994': 'Small Arms, Ordnance, and Ordnance Accessories Manufacturing',\n",
    "}\n",
    "\n",
    "# Subsystem category classification based on NAICS/PSC\n",
    "NAICS_TO_SUBSYSTEM = {\n",
    "    '336120': 'POWERTRAIN',\n",
    "    '336211': 'ARMOR',\n",
    "    '336992': 'ARMOR',\n",
    "    '336999': 'ELECTRONICS',\n",
    "    '332994': 'ARMOR',\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM.gov Entity API Fetch\n",
    "\n",
    "Queries the SAM.gov Entity Management API v3 for active defense-related registrants\n",
    "by NAICS code with `purposeOfRegistrationCode=Z2` (Federal Assistance awards + contracts).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def _get_sam_api_key() -> str:\n",
    "    \"\"\"\n",
    "    Resolve SAM.gov API key from (in priority order):\n",
    "      1. Databricks widget\n",
    "      2. Environment variable SAM_API_KEY\n",
    "      3. Databricks secret scope supply_chain/sam_api_key\n",
    "    Raises ValueError with instructions if none found.\n",
    "    \"\"\"\n",
    "    # 1. Widget value\n",
    "    try:\n",
    "        key = dbutils.widgets.get(\"sam_api_key\").strip()\n",
    "        if key:\n",
    "            return key\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2. Environment variable\n",
    "    key = os.environ.get(\"SAM_API_KEY\", \"\").strip()\n",
    "    if key:\n",
    "        return key\n",
    "\n",
    "    # 3. Databricks secrets\n",
    "    try:\n",
    "        key = dbutils.secrets.get(scope=\"supply_chain\", key=\"sam_api_key\").strip()\n",
    "        if key:\n",
    "            return key\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    raise ValueError(\n",
    "        \"No SAM.gov API key found. Provide one via:\\n\"\n",
    "        \"  1. The 'sam_api_key' widget at the top of this notebook\\n\"\n",
    "        \"  2. Environment variable SAM_API_KEY\\n\"\n",
    "        \"  3. Databricks secret scope 'supply_chain' key 'sam_api_key'\\n\\n\"\n",
    "        \"Get a free API key at: https://sam.gov/content/entity-information\"\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fetch_sam_entities() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch active entity registrations from SAM.gov Entity Management API v3\n",
    "    for defense-relevant NAICS codes.\n",
    "\n",
    "    Returns a pandas DataFrame with one row per entity, mapped to the\n",
    "    sam_entity_export schema.\n",
    "    \"\"\"\n",
    "    api_key = _get_sam_api_key()\n",
    "    base_url = \"https://api.sam.gov/entity-information/v3/entities\"\n",
    "\n",
    "    all_entities = []\n",
    "    seen_ueis = set()  # deduplicate across NAICS queries\n",
    "\n",
    "    for naics_code, naics_desc in DEFENSE_NAICS_CODES.items():\n",
    "        print(f\"Fetching entities for NAICS {naics_code} ({naics_desc}) ...\")\n",
    "        page = 0\n",
    "        total_fetched_for_naics = 0\n",
    "\n",
    "        while True:\n",
    "            params = {\n",
    "                \"api_key\": api_key,\n",
    "                \"registrationStatus\": \"A\",\n",
    "                \"naicsCode\": naics_code,\n",
    "                \"purposeOfRegistrationCode\": \"Z2\",\n",
    "                \"includeSections\": \"entityRegistration,coreData\",\n",
    "                \"page\": page,\n",
    "                \"size\": 100,\n",
    "            }\n",
    "\n",
    "            # Retry logic \u2014 3 attempts with exponential backoff\n",
    "            response = None\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    response = requests.get(base_url, params=params, timeout=30)\n",
    "                    if response.status_code == 200:\n",
    "                        break\n",
    "                    elif response.status_code == 429:\n",
    "                        wait = 2 ** (attempt + 1)\n",
    "                        print(f\"  Rate limited, waiting {wait}s ...\")\n",
    "                        time.sleep(wait)\n",
    "                    else:\n",
    "                        print(f\"  HTTP {response.status_code}: {response.text[:200]}\")\n",
    "                        time.sleep(2 ** attempt)\n",
    "                except requests.exceptions.RequestException as exc:\n",
    "                    print(f\"  Request error (attempt {attempt+1}/3): {exc}\")\n",
    "                    time.sleep(2 ** attempt)\n",
    "\n",
    "            if response is None or response.status_code != 200:\n",
    "                print(f\"  Skipping NAICS {naics_code} after retries (last status: {getattr(response, 'status_code', 'N/A')})\")\n",
    "                break\n",
    "\n",
    "            data = response.json()\n",
    "            entities = data.get(\"entityData\", [])\n",
    "            total_records = data.get(\"totalRecords\", 0)\n",
    "\n",
    "            if not entities:\n",
    "                break\n",
    "\n",
    "            for entity in entities:\n",
    "                reg = entity.get(\"entityRegistration\", {})\n",
    "                core = entity.get(\"coreData\", {})\n",
    "                phys_addr = core.get(\"physicalAddress\", {})\n",
    "                entity_info = core.get(\"entityInformation\", {})\n",
    "\n",
    "                uei = reg.get(\"ueiSAM\")\n",
    "                if not uei or uei in seen_ueis:\n",
    "                    continue\n",
    "                seen_ueis.add(uei)\n",
    "\n",
    "                # Map business types list to string\n",
    "                biz_types = reg.get(\"businessTypes\", [])\n",
    "                biz_type_str = \", \".join(biz_types) if isinstance(biz_types, list) else str(biz_types) if biz_types else None\n",
    "\n",
    "                # Classify subsystem from NAICS\n",
    "                primary_naics = entity_info.get(\"primaryNaics\", naics_code)\n",
    "                subsystem = NAICS_TO_SUBSYSTEM.get(str(primary_naics), \"OTHER\")\n",
    "\n",
    "                # Classify company size from SAM business type flags\n",
    "                company_size = None\n",
    "                if biz_type_str:\n",
    "                    bt_lower = biz_type_str.lower()\n",
    "                    if \"small\" in bt_lower:\n",
    "                        company_size = \"SMALL\"\n",
    "                    elif \"large\" in bt_lower:\n",
    "                        company_size = \"LARGE\"\n",
    "                    else:\n",
    "                        company_size = \"MEDIUM\"\n",
    "\n",
    "                all_entities.append({\n",
    "                    \"uei\": uei,\n",
    "                    \"cage_code\": reg.get(\"cageCode\"),\n",
    "                    \"legal_business_name\": reg.get(\"legalBusinessName\"),\n",
    "                    \"dba_name\": reg.get(\"dbaName\"),\n",
    "                    \"physical_address_line_1\": phys_addr.get(\"addressLine1\"),\n",
    "                    \"physical_address_city\": phys_addr.get(\"city\"),\n",
    "                    \"physical_address_state_or_province\": phys_addr.get(\"stateOrProvinceCode\"),\n",
    "                    \"physical_address_zip_postal_code\": phys_addr.get(\"zipCode\"),\n",
    "                    \"physical_address_country_code\": phys_addr.get(\"countryCode\"),\n",
    "                    \"entity_start_date\": reg.get(\"registrationDate\"),\n",
    "                    \"entity_expiration_date\": reg.get(\"registrationExpirationDate\"),\n",
    "                    \"activation_date\": reg.get(\"activationDate\"),\n",
    "                    \"business_type\": biz_type_str,\n",
    "                    \"entity_structure\": entity_info.get(\"entityStructureDesc\"),\n",
    "                    \"organization_type\": entity_info.get(\"organizationStructureDesc\"),\n",
    "                    \"naics_code_primary\": str(primary_naics) if primary_naics else naics_code,\n",
    "                    \"subsystem_category\": subsystem,\n",
    "                    \"company_size\": company_size,\n",
    "                    \"sam_extract_code\": \"A\",\n",
    "                })\n",
    "                total_fetched_for_naics += 1\n",
    "\n",
    "            print(f\"  Page {page}: got {len(entities)} entities (total so far: {total_fetched_for_naics}, API reports {total_records} total)\")\n",
    "\n",
    "            # Next page or done\n",
    "            if total_fetched_for_naics >= total_records or len(entities) < 100:\n",
    "                break\n",
    "            page += 1\n",
    "            time.sleep(0.5)  # polite pacing between pages\n",
    "\n",
    "    print(f\"\\nTotal unique entities fetched: {len(all_entities)}\")\n",
    "    return pd.DataFrame(all_entities)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding\n",
    "\n",
    "Use OpenStreetMap Nominatim to geocode entity addresses.\n",
    "Rate-limited to 1 request/second per Nominatim usage policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def geocode_with_nominatim(address: str, city: str, state: str, country: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Geocode an address using OpenStreetMap Nominatim (free, no API key).\n",
    "    \n",
    "    Note: In production, respect Nominatim usage policy (1 request/second).\n",
    "    \n",
    "    Args:\n",
    "        address: Street address\n",
    "        city: City name\n",
    "        state: State/province\n",
    "        country: Country code\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (latitude, longitude) or (None, None) if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = f\"{city}, {state}, {country}\"\n",
    "        url = f\"https://nominatim.openstreetmap.org/search\"\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'format': 'json',\n",
    "            'limit': 1\n",
    "        }\n",
    "        headers = {'User-Agent': 'DatabricksSupplyChainPlatform/1.0'}\n",
    "        \n",
    "        response = requests.get(url, params=params, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                return float(data[0]['lat']), float(data[0]['lon'])\n",
    "        \n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Geocoding error: {e}\")\n",
    "        return None, None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def geocode_entities(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add latitude/longitude columns to entity DataFrame using Nominatim.\n",
    "    Respects 1 request/second rate limit.\n",
    "    \"\"\"\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    total = len(df)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        city = row.get(\"physical_address_city\", \"\")\n",
    "        state = row.get(\"physical_address_state_or_province\", \"\")\n",
    "        country = row.get(\"physical_address_country_code\", \"\")\n",
    "\n",
    "        if city and state:\n",
    "            lat, lon = geocode_with_nominatim(\n",
    "                row.get(\"physical_address_line_1\", \"\"),\n",
    "                city, state, country\n",
    "            )\n",
    "            latitudes.append(lat)\n",
    "            longitudes.append(lon)\n",
    "            if (idx + 1) % 25 == 0:\n",
    "                print(f\"  Geocoded {idx + 1}/{total} ...\")\n",
    "            # Nominatim policy: max 1 request per second\n",
    "            time.sleep(1.0)\n",
    "        else:\n",
    "            latitudes.append(None)\n",
    "            longitudes.append(None)\n",
    "\n",
    "    df[\"latitude\"] = latitudes\n",
    "    df[\"longitude\"] = longitudes\n",
    "    geocoded = sum(1 for lat in latitudes if lat is not None)\n",
    "    print(f\"Geocoding complete: {geocoded}/{total} entities resolved\")\n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fetch entities from SAM.gov API\n",
    "print(\"Fetching entity data from SAM.gov Entity Management API v3 ...\")\n",
    "sam_df = fetch_sam_entities()\n",
    "print(f\"Fetched {len(sam_df)} entity records\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Geocode entity addresses\n",
    "print(\"Geocoding entity addresses via Nominatim (1 req/sec) ...\")\n",
    "sam_df = geocode_entities(sam_df)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert to Spark DataFrame\n",
    "spark_sam = spark.createDataFrame(sam_df)\n",
    "\n",
    "# Display schema\n",
    "print(\"SAM Entity Schema:\")\n",
    "spark_sam.printSchema()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display sample\n",
    "display(spark_sam.limit(10))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Raw Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Unity Catalog setup\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.raw\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.silver\")\n",
    "\n",
    "# Save to raw layer (Unity Catalog)\n",
    "spark_sam.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(RAW_TABLE)\n",
    "\n",
    "print(f\"Saved {spark_sam.count()} records to {RAW_TABLE}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding and Distance Calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points on Earth (in km).\n",
    "    \n",
    "    Args:\n",
    "        lat1, lon1: Coordinates of first point\n",
    "        lat2, lon2: Coordinates of second point\n",
    "    \n",
    "    Returns:\n",
    "        Distance in kilometers\n",
    "    \"\"\"\n",
    "    from math import radians, cos, sin, asin, sqrt\n",
    "    \n",
    "    # Convert to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    \n",
    "    # Earth radius in km\n",
    "    r = 6371\n",
    "    \n",
    "    return c * r\n",
    "\n",
    "# Register as UDF\n",
    "haversine_udf = F.udf(haversine_distance, DoubleType())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Silver Layer - Supplier Geolocations\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Read raw SAM data (Unity Catalog)\n",
    "sam_raw = spark.table(RAW_TABLE)\n",
    "\n",
    "# Add region group based on country\n",
    "def get_region_group(country_code):\n",
    "    return REGION_MAPPING.get(country_code, 'OTHER')\n",
    "\n",
    "region_udf = F.udf(get_region_group, StringType())\n",
    "\n",
    "# Calculate distance to nearest Oshkosh facility\n",
    "# Using Oshkosh HQ as primary reference point\n",
    "oshkosh_hq_lat = 44.0247\n",
    "oshkosh_hq_lon = -88.5426\n",
    "\n",
    "# Build silver layer\n",
    "supplier_geolocations = sam_raw \\\n",
    "    .withColumnRenamed(\"legal_business_name\", \"supplier_name\") \\\n",
    "    .withColumnRenamed(\"physical_address_city\", \"city\") \\\n",
    "    .withColumnRenamed(\"physical_address_state_or_province\", \"state\") \\\n",
    "    .withColumnRenamed(\"physical_address_country_code\", \"country\") \\\n",
    "    .withColumnRenamed(\"latitude\", \"lat\") \\\n",
    "    .withColumnRenamed(\"longitude\", \"lon\") \\\n",
    "    .withColumn(\"region_group\", region_udf(F.col(\"country\"))) \\\n",
    "    .withColumn(\n",
    "        \"distance_to_nearest_oshkosh_facility_km\",\n",
    "        haversine_udf(\n",
    "            F.col(\"lat\"),\n",
    "            F.col(\"lon\"),\n",
    "            F.lit(oshkosh_hq_lat),\n",
    "            F.lit(oshkosh_hq_lon)\n",
    "        )\n",
    "    ) \\\n",
    "    .select(\n",
    "        \"supplier_name\",\n",
    "        \"uei\",\n",
    "        \"cage_code\",\n",
    "        \"city\",\n",
    "        \"state\",\n",
    "        \"country\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"region_group\",\n",
    "        \"distance_to_nearest_oshkosh_facility_km\",\n",
    "        \"subsystem_category\",\n",
    "        \"company_size\",\n",
    "        \"naics_code_primary\",\n",
    "    ) \\\n",
    "    .withColumn(\"ingestion_timestamp\", F.current_timestamp()) \\\n",
    "    .withColumn(\"source_system\", F.lit(\"sam_gov_api_v3\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display sample\n",
    "display(supplier_geolocations.limit(15))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save to silver layer (Unity Catalog)\n",
    "supplier_geolocations.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(SILVER_TABLE)\n",
    "\n",
    "print(f\"Saved {supplier_geolocations.count()} records to {SILVER_TABLE}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplier Geography Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Suppliers by region\n",
    "print(\"=== Suppliers by Region ===\")\n",
    "display(supplier_geolocations.groupBy(\"region_group\").agg(\n",
    "    F.count(\"*\").alias(\"supplier_count\"),\n",
    "    F.avg(\"distance_to_nearest_oshkosh_facility_km\").alias(\"avg_distance_km\")\n",
    ").orderBy(F.desc(\"supplier_count\")))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Suppliers by subsystem and region\n",
    "print(\"\\n=== Suppliers by Subsystem and Region ===\")\n",
    "display(supplier_geolocations.groupBy(\"subsystem_category\", \"region_group\").agg(\n",
    "    F.count(\"*\").alias(\"supplier_count\")\n",
    ").orderBy(\"subsystem_category\", \"region_group\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Distance distribution\n",
    "print(\"\\n=== Supplier Distance Distribution ===\")\n",
    "display(supplier_geolocations.select(\n",
    "    \"supplier_name\",\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"country\",\n",
    "    \"region_group\",\n",
    "    \"distance_to_nearest_oshkosh_facility_km\",\n",
    "    \"subsystem_category\"\n",
    ").orderBy(F.desc(\"distance_to_nearest_oshkosh_facility_km\")))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply Chain Risk by Geography\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate geographic risk scores\n",
    "geo_risk = supplier_geolocations.groupBy(\"region_group\").agg(\n",
    "    F.count(\"*\").alias(\"supplier_count\"),\n",
    "    F.avg(\"distance_to_nearest_oshkosh_facility_km\").alias(\"avg_distance_km\"),\n",
    "    F.max(\"distance_to_nearest_oshkosh_facility_km\").alias(\"max_distance_km\")\n",
    ").withColumn(\n",
    "    \"geographic_risk_level\",\n",
    "    F.when(F.col(\"region_group\") == \"CHINA\", \"CRITICAL\")\n",
    "     .when(F.col(\"region_group\").isin([\"MIDEAST\", \"AFRICA\"]), \"HIGH\")\n",
    "     .when(F.col(\"region_group\").isin([\"INDO_PACIFIC\", \"EUROPE\"]), \"MODERATE\")\n",
    "     .when(F.col(\"region_group\") == \"AMERICAS\", \"LOW\")\n",
    "     .otherwise(\"UNKNOWN\")\n",
    ")\n",
    "\n",
    "print(\"=== Geographic Supply Chain Risk ===\")\n",
    "display(geo_risk.orderBy(\"supplier_count\", ascending=False))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables written to Unity Catalog: `supply_chain.raw.sam_entity_export`, `supply_chain.silver.supplier_geolocations`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run `06_tariff_trade_ingestion_v2` for trade risk data\n",
    "2. Run `07_commodity_ingestion_v2` for commodity price data\n",
    "3. Run `08_weather_ingestion_v2` for weather risk data\n"
   ]
  }
 ]
}