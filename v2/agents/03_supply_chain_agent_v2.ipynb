{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Chain Intelligence Agent (v2)\n",
    "\n",
    "**Executive summary:** Production-grade conversational AI agent with 17 tools spanning\n",
    "forecasting, risk analysis, supplier intelligence, contract search, macroeconomic\n",
    "context, and executive briefing. Backed by Databricks Foundation Models with\n",
    "conversation memory and MLflow tracing.\n",
    "\n",
    "**Depends on:** All gold/silver/bronze tables from the v2 pipeline. Run ingestion,\n",
    "transformation, and at least one forecasting notebook first.\n",
    "\n",
    "### Capabilities\n",
    "| Category | Tools | Data Sources |\n",
    "|----------|-------|--------------|\n",
    "| **Forecasting** | Demand forecast, model comparison, confidence scoring | Prophet, ARIMA, RF forecasts |\n",
    "| **Analysis** | Anomaly detection, trend analysis, demand drivers | Demand signals, feature importance |\n",
    "| **Scenarios** | Geopolitical, tariff, weather, custom what-if | Risk indices, commodity prices |\n",
    "| **Intelligence** | Supplier lookup, contract search, DoD metrics, commodity prices | SAM entities, FPDS contracts |\n",
    "| **Macro Context** | Economic indicators, trade barometer, supply chain pressure | World Bank, NY Fed, WTO |\n",
    "| **Executive** | Supply chain health dashboard, executive briefing | All tables |\n",
    "\n",
    "### Enhancements over notebooks 01 & 02\n",
    "- All 17 tools consolidated (no duplication)\n",
    "- **5 new tools**: supplier intelligence, contract search, macro context, supply chain health, executive briefing\n",
    "- **Conversation memory**: multi-turn dialogue with context retention\n",
    "- **Rich system prompt**: defense supply chain domain expertise\n",
    "- **Graceful degradation**: missing tables handled without crashing\n",
    "- **Interactive chat loop**: run as a conversational session in Databricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install --upgrade \"typing_extensions>=4.1\" \"langchain>=0.2,<0.4\" \"langchain-core>=0.2\" langgraph databricks-langchain mlflow pandas numpy scikit-learn scipy\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    from typing_extensions import Sentinel\n",
    "except ImportError:\n",
    "    dbutils.library.restartPython()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "_create_tool_calling_agent = None\n",
    "_AgentExecutor = None\n",
    "try:\n",
    "    from langchain.agents import create_tool_calling_agent\n",
    "    _create_tool_calling_agent = create_tool_calling_agent\n",
    "except ImportError:\n",
    "    try:\n",
    "        from langchain.agents.tool_calling_agent.base import create_tool_calling_agent\n",
    "        _create_tool_calling_agent = create_tool_calling_agent\n",
    "    except (ModuleNotFoundError, ImportError):\n",
    "        try:\n",
    "            from langchain.agents import create_react_agent as create_tool_calling_agent\n",
    "            _create_tool_calling_agent = create_tool_calling_agent\n",
    "        except ImportError:\n",
    "            pass\n",
    "try:\n",
    "    from langchain_core.agents import AgentExecutor\n",
    "    _AgentExecutor = AgentExecutor\n",
    "except ImportError:\n",
    "    try:\n",
    "        from langchain.agents import AgentExecutor\n",
    "        _AgentExecutor = AgentExecutor\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "from pyspark.sql import functions as F\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import mlflow\n",
    "import json\n",
    "import textwrap\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CATALOG = \"supply_chain\"\n",
    "\n",
    "# \u2500\u2500 Table registry \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "TABLES = {\n",
    "    # Gold\n",
    "    \"demand_signals\":       f\"{CATALOG}.gold.oshkosh_monthly_demand_signals\",\n",
    "    \"dod_metrics\":          f\"{CATALOG}.gold.dod_metrics_inputs_monthly\",\n",
    "    \"trade_risk\":           f\"{CATALOG}.gold.trade_tariff_risk_monthly\",\n",
    "    \"prophet_forecasts\":    f\"{CATALOG}.gold.prophet_forecasts\",\n",
    "    \"arima_forecasts\":      f\"{CATALOG}.gold.arima_forecasts\",\n",
    "    \"rf_forecasts\":         f\"{CATALOG}.gold.random_forest_forecasts\",\n",
    "    \"rf_feature_importance\": f\"{CATALOG}.gold.random_forest_feature_importance\",\n",
    "    # Silver\n",
    "    \"suppliers\":            f\"{CATALOG}.silver.supplier_geolocations\",\n",
    "    \"commodity\":            f\"{CATALOG}.silver.commodity_prices_monthly\",\n",
    "    \"weather\":              f\"{CATALOG}.silver.weather_risk_monthly\",\n",
    "    \"tariff_events\":        f\"{CATALOG}.silver.trade_tariff_risk_events\",\n",
    "    # Bronze\n",
    "    \"fpds_contracts\":       f\"{CATALOG}.bronze.fpds_contracts\",\n",
    "    \"prime_awards\":         f\"{CATALOG}.bronze.oshkosh_prime_award_actions\",\n",
    "    \"subawards\":            f\"{CATALOG}.bronze.oshkosh_subawards\",\n",
    "    \"wdi\":                  f\"{CATALOG}.bronze.worldbank_wdi\",\n",
    "    \"wgi\":                  f\"{CATALOG}.bronze.worldbank_wgi\",\n",
    "    \"gscpi\":                f\"{CATALOG}.bronze.nyfed_gscpi\",\n",
    "    \"wto\":                  f\"{CATALOG}.bronze.wto_trade_barometer\",\n",
    "}\n",
    "\n",
    "\n",
    "def _safe_load(table_key: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a table by key, returning empty DataFrame if it doesn't exist.\"\"\"\n",
    "    table_name = TABLES.get(table_key, table_key)\n",
    "    try:\n",
    "        return spark.table(table_name).toPandas()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "print(f\"Table registry: {len(TABLES)} tables configured\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm = ChatDatabricks(\n",
    "    endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=2000,\n",
    ")\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "print(\"LLM initialized: databricks-meta-llama-3-3-70b-instruct\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tools: Forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def get_demand_forecast(months_ahead: int = 3, include_confidence: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve demand forecast for Oshkosh Defense contracts.\n",
    "\n",
    "    Args:\n",
    "        months_ahead: Number of months to forecast (1-12)\n",
    "        include_confidence: Whether to include confidence intervals\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"prophet_forecasts\")\n",
    "        if df.empty:\n",
    "            return \"No forecast data available. Run the forecasting notebooks first.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        future = df[df['month'] > datetime.now()].head(months_ahead)\n",
    "        if future.empty:\n",
    "            return \"No future forecast rows found. The forecast horizon may need extending.\"\n",
    "\n",
    "        lines = [f\"DEMAND FORECAST - Next {months_ahead} Months\", \"=\" * 50, \"\"]\n",
    "        total = 0.0\n",
    "        for _, r in future.iterrows():\n",
    "            m = r['month'].strftime('%B %Y')\n",
    "            f_val = r['forecast_demand_usd']\n",
    "            total += f_val\n",
    "            lines.append(f\"  {m}\")\n",
    "            lines.append(f\"    Forecast: ${f_val:,.0f}\")\n",
    "            if include_confidence:\n",
    "                lo = r.get('forecast_lower')\n",
    "                hi = r.get('forecast_upper')\n",
    "                if pd.notna(lo) and pd.notna(hi):\n",
    "                    lines.append(f\"    95% CI:   ${lo:,.0f} - ${hi:,.0f}\")\n",
    "            lines.append(\"\")\n",
    "        lines.append(f\"TOTAL FORECAST:   ${total:,.0f}\")\n",
    "        lines.append(f\"MONTHLY AVERAGE:  ${total / len(future):,.0f}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving forecast: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def compare_forecast_models(months_ahead: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Compare forecasts from Prophet, ARIMA, and Random Forest models side-by-side.\n",
    "\n",
    "    Args:\n",
    "        months_ahead: Number of months to compare (default 3)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        now = datetime.now()\n",
    "        models_data = {}\n",
    "        for key, label in [(\"prophet_forecasts\", \"Prophet\"), (\"arima_forecasts\", \"ARIMA\"), (\"rf_forecasts\", \"Random Forest\")]:\n",
    "            df = _safe_load(key)\n",
    "            if not df.empty:\n",
    "                df['month'] = pd.to_datetime(df['month'])\n",
    "                models_data[label] = df[df['month'] > now].head(months_ahead)\n",
    "\n",
    "        if not models_data:\n",
    "            return \"No forecast tables found. Run at least one forecasting notebook first.\"\n",
    "\n",
    "        lines = [f\"MULTI-MODEL FORECAST COMPARISON (next {months_ahead} months)\", \"=\" * 60, \"\"]\n",
    "\n",
    "        # Get months from first available model\n",
    "        ref = list(models_data.values())[0]\n",
    "        for i in range(min(months_ahead, len(ref))):\n",
    "            month_str = ref.iloc[i]['month'].strftime('%B %Y')\n",
    "            lines.append(f\"  {month_str}\")\n",
    "            vals = []\n",
    "            for label, mdf in models_data.items():\n",
    "                if i < len(mdf):\n",
    "                    v = mdf.iloc[i]['forecast_demand_usd']\n",
    "                    vals.append(v)\n",
    "                    lines.append(f\"    {label:<15s} ${v:>12,.0f}\")\n",
    "            if len(vals) > 1:\n",
    "                avg = np.mean(vals)\n",
    "                spread = np.std(vals)\n",
    "                lines.append(f\"    {'Ensemble Avg':<15s} ${avg:>12,.0f}  (spread: {spread/avg*100:.1f}%)\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        # Agreement summary\n",
    "        if len(models_data) > 1:\n",
    "            spreads = []\n",
    "            for i in range(min(months_ahead, len(ref))):\n",
    "                vals = [mdf.iloc[i]['forecast_demand_usd'] for mdf in models_data.values() if i < len(mdf)]\n",
    "                if len(vals) > 1:\n",
    "                    spreads.append(np.std(vals) / np.mean(vals) * 100)\n",
    "            if spreads:\n",
    "                avg_sp = np.mean(spreads)\n",
    "                level = \"HIGH\" if avg_sp < 5 else \"MODERATE\" if avg_sp < 15 else \"LOW\"\n",
    "                lines.append(f\"Model agreement: {level} (avg spread {avg_sp:.1f}%)\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error comparing models: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def assess_forecast_confidence(months_ahead: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Score forecast confidence based on volatility, trend strength, risk stability, and data recency.\n",
    "\n",
    "    Args:\n",
    "        months_ahead: Forecast horizon to assess (default 3)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"demand_signals\")\n",
    "        if df.empty:\n",
    "            return \"Demand signals table not available.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df = df.sort_values('month')\n",
    "        recent = df.tail(12)\n",
    "        y = recent['total_obligations_usd'].values\n",
    "\n",
    "        # Factor 1 - Volatility\n",
    "        cv = y.std() / y.mean()\n",
    "        vol_score = max(0, 100 - cv * 200)\n",
    "\n",
    "        # Factor 2 - Trend consistency\n",
    "        slope, _, r_value, p_value, _ = stats.linregress(np.arange(len(y)), y)\n",
    "        trend_score = (r_value ** 2) * 100\n",
    "\n",
    "        # Factor 3 - Risk environment stability\n",
    "        risk_scores = []\n",
    "        for col in ['geo_risk_index', 'tariff_risk_index', 'weather_disruption_index']:\n",
    "            if col in recent.columns and recent[col].mean() > 0:\n",
    "                risk_scores.append(max(0, 100 - (recent[col].std() / (recent[col].mean() + 1e-9)) * 100))\n",
    "        risk_score = np.mean(risk_scores) if risk_scores else 50\n",
    "\n",
    "        # Factor 4 - Data recency\n",
    "        days_since = (datetime.now() - recent['month'].max()).days\n",
    "        recency_score = max(0, 100 - days_since / 30 * 50)\n",
    "\n",
    "        overall = vol_score * 0.35 + trend_score * 0.30 + risk_score * 0.25 + recency_score * 0.10\n",
    "\n",
    "        label = \"HIGH\" if overall >= 80 else \"MODERATE\" if overall >= 60 else \"LOW\"\n",
    "\n",
    "        lines = [\n",
    "            f\"FORECAST CONFIDENCE ASSESSMENT (next {months_ahead} months)\",\n",
    "            \"=\" * 60, \"\",\n",
    "            f\"  1. Historical Stability   {vol_score:5.0f}/100  (CV={cv:.3f})\",\n",
    "            f\"  2. Trend Consistency       {trend_score:5.0f}/100  (R\u00b2={r_value**2:.3f}, p={p_value:.4f})\",\n",
    "            f\"  3. Risk Env. Stability     {risk_score:5.0f}/100\",\n",
    "            f\"  4. Data Recency            {recency_score:5.0f}/100  ({days_since} days since last)\",\n",
    "            \"\", \"=\" * 60,\n",
    "            f\"  OVERALL CONFIDENCE: {overall:.0f}/100 ({label})\", \"\",\n",
    "        ]\n",
    "        if overall >= 80:\n",
    "            lines.append(\"  Forecasts are reliable for planning. Standard safety stock appropriate.\")\n",
    "        elif overall >= 60:\n",
    "            lines.append(\"  Forecasts are reasonable. Consider 15-20% safety buffer.\")\n",
    "        else:\n",
    "            lines.append(\"  High uncertainty. Increase safety stock 30-50% and review model inputs.\")\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error assessing confidence: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tools: Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def detect_anomalies(threshold_pct: float = 20.0, lookback_months: int = 6) -> str:\n",
    "    \"\"\"\n",
    "    Detect demand anomalies by comparing recent months to the historical baseline.\n",
    "\n",
    "    Args:\n",
    "        threshold_pct: Percentage deviation to flag as anomaly (default 20%)\n",
    "        lookback_months: Months to analyze (default 6)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"demand_signals\")\n",
    "        if df.empty:\n",
    "            return \"Demand signals table not available.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df = df.sort_values('month')\n",
    "        recent = df.tail(lookback_months)\n",
    "        historical = df.iloc[:-lookback_months]\n",
    "        if historical.empty:\n",
    "            return \"Not enough history for anomaly detection.\"\n",
    "        baseline = historical['total_obligations_usd'].mean()\n",
    "\n",
    "        lines = [\n",
    "            \"ANOMALY DETECTION REPORT\",\n",
    "            f\"  Threshold: +/-{threshold_pct}%  |  Baseline: ${baseline:,.0f}\",\n",
    "            \"=\" * 50, \"\",\n",
    "        ]\n",
    "        count = 0\n",
    "        for _, r in recent.iterrows():\n",
    "            actual = r['total_obligations_usd']\n",
    "            dev = (actual - baseline) / baseline * 100\n",
    "            if abs(dev) > threshold_pct:\n",
    "                count += 1\n",
    "                sev = \"CRITICAL\" if abs(dev) > 50 else \"HIGH\" if abs(dev) > 30 else \"MODERATE\"\n",
    "                lines.append(f\"  [{sev}] {r['month'].strftime('%B %Y')}\")\n",
    "                lines.append(f\"    Actual: ${actual:,.0f}  ({dev:+.1f}% vs baseline)\")\n",
    "                risk = r.get('combined_risk_index', 'N/A')\n",
    "                lines.append(f\"    Combined Risk Index: {risk}\")\n",
    "                lines.append(\"\")\n",
    "\n",
    "        if count == 0:\n",
    "            lines.append(\"  No anomalies detected within the threshold.\")\n",
    "        else:\n",
    "            lines.append(f\"  TOTAL ANOMALIES: {count}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error detecting anomalies: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def detect_trends(lookback_months: int = 12, trend_type: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Detect growth trends, seasonality, volatility, and risk correlations in demand.\n",
    "\n",
    "    Args:\n",
    "        lookback_months: Months to analyze (default 12)\n",
    "        trend_type: GROWTH, SEASONAL, VOLATILITY, CORRELATION, or ALL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"demand_signals\")\n",
    "        if df.empty:\n",
    "            return \"Demand signals table not available.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df = df.sort_values('month')\n",
    "        recent = df.tail(lookback_months)\n",
    "        y = recent['total_obligations_usd'].values\n",
    "        tt = trend_type.upper()\n",
    "\n",
    "        lines = [f\"TREND ANALYSIS (last {lookback_months} months)\", \"=\" * 60, \"\"]\n",
    "\n",
    "        if tt in (\"GROWTH\", \"ALL\"):\n",
    "            slope, _, r_val, p_val, _ = stats.linregress(np.arange(len(y)), y)\n",
    "            mg = slope / y.mean() * 100\n",
    "            lines += [\n",
    "                \"GROWTH TREND\",\n",
    "                f\"  Direction: {'Increasing' if slope > 0 else 'Decreasing'}\",\n",
    "                f\"  Monthly growth: {mg:+.2f}%  |  Annualized: {mg*12:+.1f}%\",\n",
    "                f\"  R\u00b2={r_val**2:.3f}, p={p_val:.4f} ({'significant' if p_val < 0.05 else 'not significant'})\",\n",
    "                \"\",\n",
    "            ]\n",
    "\n",
    "        if tt in (\"SEASONAL\", \"ALL\"):\n",
    "            recent_copy = recent.copy()\n",
    "            recent_copy['moy'] = recent_copy['month'].dt.month\n",
    "            mavg = recent_copy.groupby('moy')['total_obligations_usd'].mean()\n",
    "            amp = (mavg.max() - mavg.min()) / mavg.mean() * 100\n",
    "            mn = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "            lines += [\n",
    "                \"SEASONALITY\",\n",
    "                f\"  Peak: {mn[mavg.idxmax()-1]} (${mavg.max():,.0f})\",\n",
    "                f\"  Trough: {mn[mavg.idxmin()-1]} (${mavg.min():,.0f})\",\n",
    "                f\"  Amplitude: {amp:.1f}%  ({'HIGH' if amp > 30 else 'MODERATE' if amp > 15 else 'LOW'})\",\n",
    "                \"\",\n",
    "            ]\n",
    "\n",
    "        if tt in (\"VOLATILITY\", \"ALL\"):\n",
    "            cv = y.std() / y.mean()\n",
    "            swings = (np.abs(np.diff(y) / y[:-1]) > 0.20).sum()\n",
    "            lines += [\n",
    "                \"VOLATILITY\",\n",
    "                f\"  Std Dev: ${y.std():,.0f}  |  CV: {cv:.3f}\",\n",
    "                f\"  Large swings (>20%): {swings}\",\n",
    "                f\"  Assessment: {'HIGH' if cv > 0.5 else 'MODERATE' if cv > 0.3 else 'LOW'}\",\n",
    "                \"\",\n",
    "            ]\n",
    "\n",
    "        if tt in (\"CORRELATION\", \"ALL\"):\n",
    "            lines.append(\"RISK CORRELATIONS\")\n",
    "            for col, label in [('geo_risk_index','Geopolitical'), ('tariff_risk_index','Tariff'), ('commodity_cost_pressure','Commodity')]:\n",
    "                if col in recent.columns:\n",
    "                    corr = recent['total_obligations_usd'].corr(recent[col])\n",
    "                    if pd.notna(corr):\n",
    "                        strength = \"Strong\" if abs(corr) > 0.7 else \"Moderate\" if abs(corr) > 0.4 else \"Weak\"\n",
    "                        lines.append(f\"  {label}: {corr:+.3f} ({strength})\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error detecting trends: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def explain_demand_drivers(top_n: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Explain which features drive demand using Random Forest feature importance.\n",
    "\n",
    "    Args:\n",
    "        top_n: Number of top features to show (default 10)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"rf_feature_importance\")\n",
    "        if df.empty:\n",
    "            return \"Feature importance table not available. Run the Random Forest forecasting notebook first.\"\n",
    "        df = df.sort_values('importance', ascending=False).head(top_n)\n",
    "\n",
    "        interp = {\n",
    "            'demand_lag_1m': 'Previous month demand (momentum)',\n",
    "            'demand_rolling_mean_12m': 'Annual average demand (baseline)',\n",
    "            'demand_rolling_mean_6m': '6-month average (recent trend)',\n",
    "            'demand_rolling_mean_3m': '3-month average (short-term)',\n",
    "            'geo_risk_index': 'Geopolitical risk level',\n",
    "            'tariff_risk_index': 'Trade/tariff risk level',\n",
    "            'commodity_cost_pressure': 'Material cost pressure',\n",
    "            'weather_disruption_index': 'Weather disruptions',\n",
    "            'is_q4': 'Fiscal year-end spending effect',\n",
    "            'months_since_start': 'Long-term time trend',\n",
    "            'demand_trend_3m': '3-month demand momentum',\n",
    "            'demand_pct_change_1m': 'Month-over-month growth rate',\n",
    "            'combined_risk_interaction': 'Combined risk multiplier',\n",
    "        }\n",
    "\n",
    "        lines = [f\"DEMAND DRIVER ANALYSIS - Top {top_n} Features\", \"=\" * 60, \"\"]\n",
    "        for _, r in df.iterrows():\n",
    "            f_name = r['feature']\n",
    "            imp = r['importance']\n",
    "            lines.append(f\"  {int(r['rank']):>2}. {f_name}\")\n",
    "            lines.append(f\"      Score: {imp:.4f}  |  {interp.get(f_name, 'Model feature')}\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        # Summary insight\n",
    "        top_feat = df.iloc[0]['feature']\n",
    "        if 'lag' in top_feat or 'rolling' in top_feat:\n",
    "            lines.append(\"KEY INSIGHT: Historical patterns dominate -- demand shows strong momentum/seasonality.\")\n",
    "        elif 'risk' in top_feat:\n",
    "            lines.append(\"KEY INSIGHT: Risk signals dominate -- demand is highly sensitive to geopolitical/trade factors.\")\n",
    "        elif 'commodity' in top_feat:\n",
    "            lines.append(\"KEY INSIGHT: Commodity prices dominate -- material costs significantly influence demand.\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing demand drivers: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tools: Scenarios\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def scenario_geopolitical_risk(risk_level: str = \"HIGH\", region: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Analyze impact of a geopolitical risk scenario on defense demand.\n",
    "\n",
    "    Args:\n",
    "        risk_level: MODERATE, ELEVATED, HIGH, or CRITICAL\n",
    "        region: EUROPE, MIDEAST, INDO_PACIFIC, AMERICAS, or ALL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"demand_signals\")\n",
    "        if df.empty:\n",
    "            return \"Demand signals table not available.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        baseline = df.tail(12)['total_obligations_usd'].mean()\n",
    "\n",
    "        mult = {\"MODERATE\": 1.0, \"ELEVATED\": 1.15, \"HIGH\": 1.35, \"CRITICAL\": 1.75}.get(risk_level.upper(), 1.0)\n",
    "        proj = baseline * mult\n",
    "        inc = proj - baseline\n",
    "\n",
    "        lines = [\n",
    "            \"GEOPOLITICAL RISK SCENARIO\",\n",
    "            \"=\" * 50,\n",
    "            f\"  Level: {risk_level.upper()}  |  Region: {region.upper()}\",\n",
    "            f\"  Demand multiplier: {mult:.2f}x\", \"\",\n",
    "            f\"  Baseline monthly: ${baseline:,.0f}\",\n",
    "            f\"  Projected monthly: ${proj:,.0f}  ({(mult-1)*100:+.0f}%)\",\n",
    "            f\"  Annual impact: ${inc * 12:,.0f}\", \"\",\n",
    "            \"RECOMMENDED ACTIONS:\",\n",
    "        ]\n",
    "        if risk_level.upper() == \"CRITICAL\":\n",
    "            lines += [\"  - Activate surge capacity\", \"  - Increase safety stock 75%\", \"  - Expedite critical orders\", \"  - Qualify backup suppliers\"]\n",
    "        elif risk_level.upper() == \"HIGH\":\n",
    "            lines += [\"  - Increase safety stock 35%\", \"  - Accelerate procurement\", \"  - Monitor supplier capacity\"]\n",
    "        elif risk_level.upper() == \"ELEVATED\":\n",
    "            lines += [\"  - Increase safety stock 15%\", \"  - Review contingency plans\"]\n",
    "        else:\n",
    "            lines += [\"  - Continue normal operations\"]\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def scenario_tariff_increase(tariff_increase_pct: float = 25.0, product_category: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Analyze cost impact of tariff increases on supply chain.\n",
    "\n",
    "    Args:\n",
    "        tariff_increase_pct: Percentage tariff increase (default 25%)\n",
    "        product_category: VEHICLES, ELECTRONICS, STEEL, ALUMINUM, or ALL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"demand_signals\")\n",
    "        if df.empty:\n",
    "            return \"Demand signals table not available.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        baseline = df.tail(12)['total_obligations_usd'].mean()\n",
    "\n",
    "        import_pct = 0.30\n",
    "        imported = baseline * import_pct\n",
    "        tariff_cost = imported * tariff_increase_pct / 100\n",
    "        total_pct = tariff_cost / baseline * 100\n",
    "\n",
    "        lines = [\n",
    "            \"TARIFF INCREASE SCENARIO\",\n",
    "            \"=\" * 50,\n",
    "            f\"  Tariff increase: {tariff_increase_pct}%  |  Category: {product_category.upper()}\", \"\",\n",
    "            f\"  Monthly spend: ${baseline:,.0f}\",\n",
    "            f\"  Import content: {import_pct*100:.0f}% (${imported:,.0f})\",\n",
    "            f\"  Additional tariff cost: ${tariff_cost:,.0f}/mo ({total_pct:.1f}% of total)\",\n",
    "            f\"  Annual impact: ${tariff_cost * 12:,.0f}\", \"\",\n",
    "            \"MITIGATION:\",\n",
    "        ]\n",
    "        if tariff_increase_pct >= 50:\n",
    "            lines += [\"  - Evaluate domestic sourcing\", \"  - Lock long-term contracts now\", \"  - Apply for tariff exclusions\"]\n",
    "        elif tariff_increase_pct >= 25:\n",
    "            lines += [\"  - Accelerate supplier diversification\", \"  - Review make-vs-buy\", \"  - Explore bonded warehouses\"]\n",
    "        else:\n",
    "            lines += [\"  - Monitor developments\", \"  - Update cost models\"]\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def scenario_weather_disruption(disruption_type: str = \"SEVERE_WINTER\", affected_region: str = \"MIDWEST\") -> str:\n",
    "    \"\"\"\n",
    "    Analyze supply chain impact of weather disruptions.\n",
    "\n",
    "    Args:\n",
    "        disruption_type: SEVERE_WINTER, HURRICANE, FLOODING, or EXTREME_HEAT\n",
    "        affected_region: MIDWEST, SOUTHEAST, GULF_COAST, or WEST_COAST\n",
    "    \"\"\"\n",
    "    try:\n",
    "        impacts = {\n",
    "            \"SEVERE_WINTER\": {\"delay\": 7, \"prod_impact\": 15, \"subsystems\": [\"POWERTRAIN\", \"SUSPENSION\", \"MATERIALS\"]},\n",
    "            \"HURRICANE\":     {\"delay\": 14, \"prod_impact\": 25, \"subsystems\": [\"ELECTRONICS\", \"TIRES\", \"ARMOR\"]},\n",
    "            \"FLOODING\":      {\"delay\": 10, \"prod_impact\": 20, \"subsystems\": [\"MATERIALS\", \"HYDRAULICS\", \"ELECTRICAL\"]},\n",
    "            \"EXTREME_HEAT\":  {\"delay\": 3,  \"prod_impact\": 10, \"subsystems\": [\"RUBBER\", \"ELECTRONICS\"]},\n",
    "        }\n",
    "        imp = impacts.get(disruption_type.upper(), impacts[\"SEVERE_WINTER\"])\n",
    "\n",
    "        lines = [\n",
    "            \"WEATHER DISRUPTION SCENARIO\",\n",
    "            \"=\" * 50,\n",
    "            f\"  Event: {disruption_type.replace('_', ' ')}  |  Region: {affected_region.replace('_', ' ')}\", \"\",\n",
    "            f\"  Transport delays: {imp['delay']} days\",\n",
    "            f\"  Production impact: {imp['prod_impact']}% reduction\",\n",
    "            f\"  Affected subsystems: {', '.join(imp['subsystems'])}\", \"\",\n",
    "            \"CONTINGENCY ACTIONS:\",\n",
    "        ]\n",
    "        if imp['delay'] >= 10:\n",
    "            lines += [\"  - Activate emergency logistics\", \"  - Pre-position critical inventory\", \"  - Engage backup carriers\"]\n",
    "        else:\n",
    "            lines += [\"  - Monitor forecasts\", \"  - Communicate with suppliers\", \"  - Review safety stock\"]\n",
    "        lines += [\"\", f\"  Expected recovery: {imp['delay'] + 7} days\"]\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def build_whatif_scenario(\n",
    "    geo_risk_change_pct: float = 0.0,\n",
    "    tariff_change_pct: float = 0.0,\n",
    "    commodity_price_change_pct: float = 0.0,\n",
    "    demand_shock_pct: float = 0.0,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a custom what-if scenario by adjusting multiple risk factors simultaneously.\n",
    "\n",
    "    Args:\n",
    "        geo_risk_change_pct: % change in geopolitical risk (e.g. 50 for +50%)\n",
    "        tariff_change_pct: % change in tariffs\n",
    "        commodity_price_change_pct: % change in commodity prices\n",
    "        demand_shock_pct: Direct demand shock (e.g. -10 for -10%)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"demand_signals\")\n",
    "        if df.empty:\n",
    "            return \"Demand signals table not available.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        recent = df.tail(12)\n",
    "        baseline = recent['total_obligations_usd'].mean()\n",
    "\n",
    "        # Simplified elasticity model\n",
    "        geo_eff    = geo_risk_change_pct / 100 * 0.30      # risk up -> defense spend up\n",
    "        tariff_eff = tariff_change_pct / 100 * -0.05       # tariff up -> cost pressure\n",
    "        comm_eff   = commodity_price_change_pct / 100 * -0.02\n",
    "        direct     = demand_shock_pct / 100\n",
    "        total_pct  = (geo_eff + tariff_eff + comm_eff + direct) * 100\n",
    "        projected  = baseline * (1 + total_pct / 100)\n",
    "        change     = projected - baseline\n",
    "\n",
    "        lines = [\n",
    "            \"CUSTOM WHAT-IF SCENARIO\",\n",
    "            \"=\" * 60, \"\",\n",
    "            f\"  Baseline monthly demand: ${baseline:,.0f}\", \"\",\n",
    "            \"  Adjustments:\",\n",
    "        ]\n",
    "        for lbl, val in [(\"Geopolitical risk\", geo_risk_change_pct), (\"Tariff risk\", tariff_change_pct),\n",
    "                         (\"Commodity prices\", commodity_price_change_pct), (\"Direct demand shock\", demand_shock_pct)]:\n",
    "            if val != 0:\n",
    "                lines.append(f\"    {lbl}: {val:+.0f}%\")\n",
    "        lines += [\n",
    "            \"\", \"  Impact breakdown:\",\n",
    "            f\"    Geopolitical effect: {geo_eff*100:+.2f}%\",\n",
    "            f\"    Tariff effect:      {tariff_eff*100:+.2f}%\",\n",
    "            f\"    Commodity effect:    {comm_eff*100:+.2f}%\",\n",
    "            f\"    Direct shock:        {direct*100:+.2f}%\",\n",
    "            f\"    {'\u2500'*35}\",\n",
    "            f\"    NET DEMAND IMPACT:   {total_pct:+.2f}%\", \"\",\n",
    "            f\"  Projected monthly: ${projected:,.0f}  (${change:+,.0f})\",\n",
    "            f\"  Annual impact:     ${change * 12:,.0f}\",\n",
    "        ]\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tools: Intelligence (NEW)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def query_suppliers(\n",
    "    name: str = \"\",\n",
    "    state: str = \"\",\n",
    "    subsystem: str = \"\",\n",
    "    company_size: str = \"\",\n",
    "    top_n: int = 15,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Search the defense supplier base from SAM.gov entity data.\n",
    "\n",
    "    Args:\n",
    "        name: Partial supplier name to search (case-insensitive)\n",
    "        state: US state abbreviation to filter (e.g. WI, TX, CA)\n",
    "        subsystem: Subsystem category (e.g. ARMOR, POWERTRAIN, ELECTRONICS)\n",
    "        company_size: Company size filter (e.g. SMALL, LARGE)\n",
    "        top_n: Max results to return (default 15)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"suppliers\")\n",
    "        if df.empty:\n",
    "            return \"Supplier table not available. Run 04_sam_entity_ingestion_v2 first.\"\n",
    "\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "        if name:\n",
    "            mask &= df['supplier_name'].str.contains(name, case=False, na=False)\n",
    "        if state:\n",
    "            mask &= df['state'].str.upper() == state.upper()\n",
    "        if subsystem:\n",
    "            mask &= df['subsystem_category'].str.contains(subsystem, case=False, na=False)\n",
    "        if company_size:\n",
    "            mask &= df['company_size'].str.contains(company_size, case=False, na=False)\n",
    "\n",
    "        filtered = df[mask].head(top_n)\n",
    "\n",
    "        if filtered.empty:\n",
    "            return f\"No suppliers found matching criteria (name={name!r}, state={state!r}, subsystem={subsystem!r}, size={company_size!r}).\"\n",
    "\n",
    "        lines = [f\"SUPPLIER SEARCH RESULTS ({len(filtered)} of {mask.sum()} matches)\", \"=\" * 60, \"\"]\n",
    "        for _, r in filtered.iterrows():\n",
    "            lines.append(f\"  {r['supplier_name']}\")\n",
    "            lines.append(f\"    UEI: {r.get('uei','N/A')}  |  CAGE: {r.get('cage_code','N/A')}\")\n",
    "            lines.append(f\"    Location: {r.get('city','')}, {r.get('state','')}, {r.get('country','')}\")\n",
    "            lines.append(f\"    Subsystem: {r.get('subsystem_category','N/A')}  |  Size: {r.get('company_size','N/A')}\")\n",
    "            dist = r.get('distance_to_nearest_oshkosh_facility_km')\n",
    "            if pd.notna(dist):\n",
    "                lines.append(f\"    Distance to Oshkosh HQ: {dist:,.0f} km\")\n",
    "            lines.append(f\"    NAICS: {r.get('naics_code_primary','N/A')}\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        # Summary stats\n",
    "        if mask.sum() > 0:\n",
    "            full = df[mask]\n",
    "            lines.append(\"  SUMMARY:\")\n",
    "            lines.append(f\"    Total matching: {mask.sum()}\")\n",
    "            if 'company_size' in full.columns:\n",
    "                sizes = full['company_size'].value_counts()\n",
    "                lines.append(f\"    By size: {dict(sizes)}\")\n",
    "            if 'region_group' in full.columns:\n",
    "                regions = full['region_group'].value_counts().head(5)\n",
    "                lines.append(f\"    Top regions: {dict(regions)}\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error querying suppliers: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def search_contracts(\n",
    "    vendor_name: str = \"\",\n",
    "    psc_code: str = \"\",\n",
    "    fiscal_year: int = 0,\n",
    "    min_amount: float = 0,\n",
    "    top_n: int = 15,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Search FPDS contract data for defense contracts.\n",
    "\n",
    "    Args:\n",
    "        vendor_name: Partial vendor name (case-insensitive)\n",
    "        psc_code: Product Service Code prefix (e.g. '23' for vehicles)\n",
    "        fiscal_year: Filter by fiscal year (e.g. 2024). 0 = all years\n",
    "        min_amount: Minimum obligated amount in USD\n",
    "        top_n: Max results to return (default 15)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"fpds_contracts\")\n",
    "        if df.empty:\n",
    "            return \"FPDS contracts table not available. Run 02_fpds_ingestion_v2 first.\"\n",
    "\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "        if vendor_name:\n",
    "            mask &= df['vendor_name'].str.contains(vendor_name, case=False, na=False)\n",
    "        if psc_code:\n",
    "            mask &= df['psc_code'].astype(str).str.startswith(psc_code)\n",
    "        if fiscal_year > 0 and 'fiscal_year' in df.columns:\n",
    "            mask &= df['fiscal_year'] == fiscal_year\n",
    "        if min_amount > 0 and 'obligated_amount' in df.columns:\n",
    "            df['obligated_amount'] = pd.to_numeric(df['obligated_amount'], errors='coerce')\n",
    "            mask &= df['obligated_amount'] >= min_amount\n",
    "\n",
    "        filtered = df[mask].sort_values('obligated_amount', ascending=False).head(top_n)\n",
    "\n",
    "        if filtered.empty:\n",
    "            return f\"No contracts found matching criteria.\"\n",
    "\n",
    "        lines = [f\"CONTRACT SEARCH RESULTS ({len(filtered)} of {mask.sum()} matches)\", \"=\" * 60, \"\"]\n",
    "        total_val = 0\n",
    "        for _, r in filtered.iterrows():\n",
    "            amt = float(r.get('obligated_amount', 0) or 0)\n",
    "            total_val += amt\n",
    "            lines.append(f\"  Contract: {r.get('contract_id', 'N/A')}\")\n",
    "            lines.append(f\"    Vendor: {r.get('vendor_name', 'N/A')}\")\n",
    "            lines.append(f\"    Amount: ${amt:,.0f}  |  FY: {r.get('fiscal_year', 'N/A')}\")\n",
    "            lines.append(f\"    PSC: {r.get('psc_code', 'N/A')}  |  NAICS: {r.get('naics_code', 'N/A')}\")\n",
    "            desc = str(r.get('description', ''))[:100]\n",
    "            if desc and desc != 'None':\n",
    "                lines.append(f\"    Desc: {desc}\")\n",
    "            lines.append(f\"    Signed: {r.get('signed_date', 'N/A')}  |  Completion: {r.get('ultimate_completion_date', 'N/A')}\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        lines.append(f\"  TOTAL VALUE (shown): ${total_val:,.0f}\")\n",
    "        lines.append(f\"  ALL MATCHES: {mask.sum()} contracts\")\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching contracts: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def compare_dod_metrics(metric_type: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Compare current performance against DoD supply chain metrics (RO, AAO, Days of Supply, NMCS Risk).\n",
    "\n",
    "    Args:\n",
    "        metric_type: RO, AAO, DAYS_OF_SUPPLY, NMCS_RISK, or ALL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"dod_metrics\")\n",
    "        if df.empty:\n",
    "            return \"DoD metrics table not available. Run transformation notebooks first.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        latest = df.sort_values('month').iloc[-1]\n",
    "        mt = metric_type.upper()\n",
    "\n",
    "        lines = [\n",
    "            \"DoD SUPPLY CHAIN METRICS\",\n",
    "            \"=\" * 50,\n",
    "            f\"  As of: {latest['month'].strftime('%B %Y')}\", \"\",\n",
    "        ]\n",
    "\n",
    "        if mt in (\"RO\", \"ALL\"):\n",
    "            ro = latest['requirements_objective_proxy']\n",
    "            rro = latest['risk_adjusted_ro']\n",
    "            lines += [f\"  REQUIREMENTS OBJECTIVE (RO)\", f\"    Current: ${ro:,.0f}  |  Risk-Adjusted: ${rro:,.0f}\", \"\"]\n",
    "\n",
    "        if mt in (\"AAO\", \"ALL\"):\n",
    "            aao = latest['approved_acquisition_objective_proxy']\n",
    "            lines += [f\"  APPROVED ACQUISITION OBJECTIVE (AAO)\", f\"    Current: ${aao:,.0f}  (includes 2-yr forecast)\", \"\"]\n",
    "\n",
    "        if mt in (\"DAYS_OF_SUPPLY\", \"ALL\"):\n",
    "            dos = latest['days_of_supply_proxy']\n",
    "            status = \"Healthy\" if dos >= 60 else \"Monitor\" if dos >= 30 else \"CRITICAL\"\n",
    "            lines += [f\"  DAYS OF SUPPLY\", f\"    Current: {dos:.0f} days  |  Target: 60+  |  Status: {status}\", \"\"]\n",
    "\n",
    "        if mt in (\"NMCS_RISK\", \"ALL\"):\n",
    "            nmcs = latest['nmcs_risk_indicator']\n",
    "            lines += [f\"  NMCS RISK\", f\"    Level: {nmcs}\", \"\"]\n",
    "\n",
    "        if mt == \"ALL\":\n",
    "            vol = latest.get('demand_volatility_category', 'N/A')\n",
    "            cv = latest.get('coefficient_of_variation', 0)\n",
    "            rec = latest.get('forecast_method_recommendation', 'N/A')\n",
    "            lines += [f\"  DEMAND VOLATILITY\", f\"    Category: {vol}  |  CV: {cv:.2f}  |  Recommended model: {rec}\"]\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def get_commodity_prices(category: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Get current defense-critical commodity prices with trends.\n",
    "\n",
    "    Args:\n",
    "        category: ENERGY, PRECIOUS_METALS, INDUSTRIAL_METALS, BATTERY_MATERIALS, or ALL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = _safe_load(\"commodity\")\n",
    "        if df.empty:\n",
    "            return \"Commodity prices table not available.\"\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        latest_month = df['month'].max()\n",
    "        latest = df[df['month'] == latest_month]\n",
    "\n",
    "        if category.upper() != \"ALL\":\n",
    "            latest = latest[latest['category'].str.upper() == category.upper()]\n",
    "\n",
    "        lines = [\n",
    "            \"DEFENSE MATERIALS PRICE MONITOR\",\n",
    "            \"=\" * 50,\n",
    "            f\"  As of: {latest_month.strftime('%B %Y')}\", \"\",\n",
    "        ]\n",
    "\n",
    "        for cat in latest['category'].unique():\n",
    "            cat_data = latest[latest['category'] == cat]\n",
    "            lines.append(f\"  {cat.upper()}\")\n",
    "            for _, r in cat_data.iterrows():\n",
    "                trend = \"+\" if r.get('pct_change_1mo', 0) > 0 else \"-\"\n",
    "                lines.append(f\"    {r['commodity_name']}: ${r['close_price']:,.2f}\")\n",
    "                lines.append(f\"      1mo: {r.get('pct_change_1mo', 0):+.1f}%  |  3mo: {r.get('pct_change_3mo', 0):+.1f}%  |  Use: {r.get('defense_use', 'N/A')}\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        avg_pressure = latest['cost_pressure_score'].mean()\n",
    "        level = \"HIGH\" if avg_pressure > 10 else \"MODERATE\" if avg_pressure > 0 else \"FAVORABLE\"\n",
    "        lines.append(f\"  COST PRESSURE: {level} (score: {avg_pressure:.1f})\")\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def get_macro_context(indicator: str = \"ALL\") -> str:\n",
    "    \"\"\"\n",
    "    Get macroeconomic context from World Bank, NY Fed GSCPI, and WTO data.\n",
    "\n",
    "    Args:\n",
    "        indicator: GDP, INFLATION, TRADE, GSCPI, WTO, or ALL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ind = indicator.upper()\n",
    "        lines = [\"MACROECONOMIC CONTEXT\", \"=\" * 60, \"\"]\n",
    "\n",
    "        # NY Fed Global Supply Chain Pressure Index\n",
    "        if ind in (\"GSCPI\", \"ALL\"):\n",
    "            gscpi = _safe_load(\"gscpi\")\n",
    "            if not gscpi.empty:\n",
    "                if 'as_of_date' in gscpi.columns:\n",
    "                    gscpi['as_of_date'] = pd.to_datetime(gscpi['as_of_date'])\n",
    "                    gscpi = gscpi.sort_values('as_of_date')\n",
    "                latest = gscpi.tail(1).iloc[0] if len(gscpi) > 0 else None\n",
    "                if latest is not None:\n",
    "                    val = latest.get('value', 0)\n",
    "                    date = latest.get('as_of_date', 'N/A')\n",
    "                    if hasattr(date, 'strftime'):\n",
    "                        date = date.strftime('%Y-%m')\n",
    "                    level = \"ELEVATED\" if float(val) > 1 else \"NORMAL\" if float(val) > -1 else \"LOW\"\n",
    "                    lines += [\n",
    "                        \"  NY FED GLOBAL SUPPLY CHAIN PRESSURE INDEX (GSCPI)\",\n",
    "                        f\"    Latest value: {float(val):.2f}  ({date})\",\n",
    "                        f\"    Level: {level}\",\n",
    "                        f\"    (0 = historical avg; >1 = elevated pressure; <-1 = low pressure)\", \"\",\n",
    "                    ]\n",
    "                    # Trend\n",
    "                    if len(gscpi) >= 3:\n",
    "                        recent_vals = gscpi.tail(3)['value'].astype(float).values\n",
    "                        if recent_vals[-1] > recent_vals[0]:\n",
    "                            lines.append(f\"    Trend: INCREASING (3-month)\")\n",
    "                        else:\n",
    "                            lines.append(f\"    Trend: DECREASING (3-month)\")\n",
    "                        lines.append(\"\")\n",
    "\n",
    "        # WTO Trade Barometer\n",
    "        if ind in (\"WTO\", \"TRADE\", \"ALL\"):\n",
    "            wto = _safe_load(\"wto\")\n",
    "            if not wto.empty:\n",
    "                if 'as_of_date' in wto.columns:\n",
    "                    wto['as_of_date'] = pd.to_datetime(wto['as_of_date'])\n",
    "                    wto = wto.sort_values('as_of_date')\n",
    "                latest_wto = wto.tail(5)\n",
    "                if len(latest_wto) > 0:\n",
    "                    lines.append(\"  WTO GOODS TRADE BAROMETER\")\n",
    "                    for _, r in latest_wto.iterrows():\n",
    "                        name = r.get('indicator_name', r.get('indicator_code', 'N/A'))\n",
    "                        val = r.get('value', 'N/A')\n",
    "                        date = r.get('as_of_date', 'N/A')\n",
    "                        if hasattr(date, 'strftime'):\n",
    "                            date = date.strftime('%Y-%m')\n",
    "                        lines.append(f\"    {name}: {val}  ({date})\")\n",
    "                    lines.append(f\"    (100 = trend; >100 = above-trend growth)\")\n",
    "                    lines.append(\"\")\n",
    "\n",
    "        # World Bank indicators\n",
    "        if ind in (\"GDP\", \"INFLATION\", \"ALL\"):\n",
    "            wdi = _safe_load(\"wdi\")\n",
    "            if not wdi.empty and 'indicator_code' in wdi.columns:\n",
    "                lines.append(\"  WORLD BANK DEVELOPMENT INDICATORS\")\n",
    "                for code, label in [(\"NY.GDP.MKTP.KD.ZG\", \"GDP Growth\"), (\"FP.CPI.TOTL.ZG\", \"Inflation (CPI)\")]:\n",
    "                    if ind != \"ALL\" and label.split()[0].upper() != ind:\n",
    "                        continue\n",
    "                    subset = wdi[wdi['indicator_code'] == code]\n",
    "                    if not subset.empty:\n",
    "                        if 'as_of_date' in subset.columns:\n",
    "                            subset = subset.copy()\n",
    "                            subset['as_of_date'] = pd.to_datetime(subset['as_of_date'])\n",
    "                            subset = subset.sort_values('as_of_date')\n",
    "                        latest_row = subset.tail(1).iloc[0]\n",
    "                        val = latest_row.get('value', 'N/A')\n",
    "                        date = latest_row.get('as_of_date', 'N/A')\n",
    "                        if hasattr(date, 'strftime'):\n",
    "                            date = date.strftime('%Y')\n",
    "                        lines.append(f\"    {label}: {val}%  ({date})\")\n",
    "                lines.append(\"\")\n",
    "\n",
    "        if len(lines) <= 3:\n",
    "            lines.append(\"  No macroeconomic data available. Run ingestion notebooks 09-13 first.\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving macro context: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tools: Dashboard (NEW)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def get_supply_chain_health() -> str:\n",
    "    \"\"\"\n",
    "    Generate a holistic supply chain health dashboard scoring demand, risk, suppliers, and materials.\n",
    "    No arguments required.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scores = {}\n",
    "\n",
    "        # Dimension 1: Demand stability\n",
    "        demand = _safe_load(\"demand_signals\")\n",
    "        if not demand.empty:\n",
    "            demand['month'] = pd.to_datetime(demand['month'])\n",
    "            recent = demand.sort_values('month').tail(6)\n",
    "            cv = recent['total_obligations_usd'].std() / recent['total_obligations_usd'].mean()\n",
    "            scores['Demand Stability'] = max(0, min(100, 100 - cv * 200))\n",
    "        else:\n",
    "            scores['Demand Stability'] = None\n",
    "\n",
    "        # Dimension 2: Risk environment\n",
    "        if not demand.empty:\n",
    "            recent = demand.sort_values('month').tail(3)\n",
    "            risk_cols = [c for c in ['geo_risk_index', 'tariff_risk_index', 'weather_disruption_index', 'commodity_cost_pressure']\n",
    "                         if c in recent.columns]\n",
    "            if risk_cols:\n",
    "                avg_risk = recent[risk_cols].mean().mean()\n",
    "                scores['Risk Environment'] = max(0, min(100, 100 - avg_risk * 10))\n",
    "            else:\n",
    "                scores['Risk Environment'] = 50\n",
    "        else:\n",
    "            scores['Risk Environment'] = None\n",
    "\n",
    "        # Dimension 3: Supplier base\n",
    "        suppliers = _safe_load(\"suppliers\")\n",
    "        if not suppliers.empty:\n",
    "            n_suppliers = len(suppliers)\n",
    "            n_regions = suppliers['region_group'].nunique() if 'region_group' in suppliers.columns else 1\n",
    "            # More suppliers & regions = healthier\n",
    "            supplier_score = min(100, n_suppliers / 2 + n_regions * 10)\n",
    "            scores['Supplier Base'] = supplier_score\n",
    "        else:\n",
    "            scores['Supplier Base'] = None\n",
    "\n",
    "        # Dimension 4: Commodity costs\n",
    "        commodity = _safe_load(\"commodity\")\n",
    "        if not commodity.empty:\n",
    "            commodity['month'] = pd.to_datetime(commodity['month'])\n",
    "            latest = commodity[commodity['month'] == commodity['month'].max()]\n",
    "            avg_pressure = latest['cost_pressure_score'].mean()\n",
    "            scores['Material Costs'] = max(0, min(100, 80 - avg_pressure * 2))\n",
    "        else:\n",
    "            scores['Material Costs'] = None\n",
    "\n",
    "        # Dimension 5: Forecast confidence\n",
    "        if not demand.empty:\n",
    "            recent12 = demand.sort_values('month').tail(12)\n",
    "            y = recent12['total_obligations_usd'].values\n",
    "            cv12 = y.std() / y.mean()\n",
    "            _, _, r_val, _, _ = stats.linregress(np.arange(len(y)), y)\n",
    "            scores['Forecast Reliability'] = (max(0, 100 - cv12 * 200) * 0.5 + (r_val ** 2) * 100 * 0.5)\n",
    "        else:\n",
    "            scores['Forecast Reliability'] = None\n",
    "\n",
    "        # Dimension 6: DoD readiness\n",
    "        dod = _safe_load(\"dod_metrics\")\n",
    "        if not dod.empty:\n",
    "            dod['month'] = pd.to_datetime(dod['month'])\n",
    "            latest_dod = dod.sort_values('month').iloc[-1]\n",
    "            dos = latest_dod.get('days_of_supply_proxy', 0)\n",
    "            nmcs = str(latest_dod.get('nmcs_risk_indicator', ''))\n",
    "            dos_score = min(100, dos / 60 * 100)\n",
    "            nmcs_penalty = 30 if 'HIGH' in nmcs else 15 if 'ELEVATED' in nmcs else 0\n",
    "            scores['DoD Readiness'] = max(0, dos_score - nmcs_penalty)\n",
    "        else:\n",
    "            scores['DoD Readiness'] = None\n",
    "\n",
    "        # Build output\n",
    "        lines = [\"SUPPLY CHAIN HEALTH DASHBOARD\", \"=\" * 60, \"\"]\n",
    "\n",
    "        valid_scores = {k: v for k, v in scores.items() if v is not None}\n",
    "        overall = np.mean(list(valid_scores.values())) if valid_scores else 0\n",
    "\n",
    "        overall_label = \"HEALTHY\" if overall >= 75 else \"CAUTION\" if overall >= 50 else \"AT RISK\" if overall >= 25 else \"CRITICAL\"\n",
    "        lines.append(f\"  OVERALL HEALTH: {overall:.0f}/100 ({overall_label})\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "        for dim, score in scores.items():\n",
    "            if score is not None:\n",
    "                bar_len = int(score / 5)\n",
    "                bar = \"#\" * bar_len + \".\" * (20 - bar_len)\n",
    "                label = \"Good\" if score >= 75 else \"Fair\" if score >= 50 else \"Poor\" if score >= 25 else \"Critical\"\n",
    "                lines.append(f\"  {dim:<22s} [{bar}] {score:5.0f}  ({label})\")\n",
    "            else:\n",
    "                lines.append(f\"  {dim:<22s} [   data unavailable   ]\")\n",
    "\n",
    "        lines += [\n",
    "            \"\", \"ATTENTION AREAS:\",\n",
    "        ]\n",
    "        for dim, score in sorted(valid_scores.items(), key=lambda x: x[1]):\n",
    "            if score < 50:\n",
    "                lines.append(f\"  - {dim}: {score:.0f}/100 -- needs attention\")\n",
    "\n",
    "        if all(s >= 75 for s in valid_scores.values()):\n",
    "            lines.append(\"  All dimensions healthy.\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error generating health dashboard: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@tool\n",
    "def generate_executive_briefing() -> str:\n",
    "    \"\"\"\n",
    "    Generate a concise executive briefing covering demand outlook, risk environment,\n",
    "    supply chain health, and recommended actions. No arguments required.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lines = [\n",
    "            \"EXECUTIVE SUPPLY CHAIN BRIEFING\",\n",
    "            f\"  Date: {datetime.now().strftime('%B %d, %Y')}\",\n",
    "            \"=\" * 60, \"\",\n",
    "        ]\n",
    "\n",
    "        # 1. Demand outlook\n",
    "        demand = _safe_load(\"demand_signals\")\n",
    "        if not demand.empty:\n",
    "            demand['month'] = pd.to_datetime(demand['month'])\n",
    "            demand = demand.sort_values('month')\n",
    "            recent3 = demand.tail(3)['total_obligations_usd']\n",
    "            recent12 = demand.tail(12)['total_obligations_usd']\n",
    "            prior3 = demand.tail(6).head(3)['total_obligations_usd']\n",
    "\n",
    "            qoq = (recent3.mean() - prior3.mean()) / prior3.mean() * 100 if prior3.mean() > 0 else 0\n",
    "\n",
    "            lines += [\n",
    "                \"1. DEMAND OUTLOOK\",\n",
    "                f\"   Last quarter avg:  ${recent3.mean():,.0f}\",\n",
    "                f\"   12-month avg:      ${recent12.mean():,.0f}\",\n",
    "                f\"   QoQ change:        {qoq:+.1f}%\",\n",
    "                f\"   Trend:             {'Growing' if qoq > 2 else 'Declining' if qoq < -2 else 'Stable'}\",\n",
    "                \"\",\n",
    "            ]\n",
    "\n",
    "        # 2. Risk snapshot\n",
    "        if not demand.empty:\n",
    "            latest = demand.iloc[-1]\n",
    "            lines.append(\"2. RISK SNAPSHOT\")\n",
    "            for col, label in [('geo_risk_index','Geopolitical'), ('tariff_risk_index','Tariff'),\n",
    "                               ('commodity_cost_pressure','Commodity'), ('weather_disruption_index','Weather')]:\n",
    "                val = latest.get(col)\n",
    "                if pd.notna(val):\n",
    "                    level = \"High\" if float(val) > 7 else \"Moderate\" if float(val) > 3 else \"Low\"\n",
    "                    lines.append(f\"   {label:<14s} {float(val):5.1f}  ({level})\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        # 3. Forecast\n",
    "        forecast = _safe_load(\"prophet_forecasts\")\n",
    "        if not forecast.empty:\n",
    "            forecast['month'] = pd.to_datetime(forecast['month'])\n",
    "            future = forecast[forecast['month'] > datetime.now()].head(3)\n",
    "            if not future.empty:\n",
    "                lines.append(\"3. FORECAST (Next Quarter)\")\n",
    "                for _, r in future.iterrows():\n",
    "                    lines.append(f\"   {r['month'].strftime('%b %Y')}: ${r['forecast_demand_usd']:,.0f}\")\n",
    "                lines.append(\"\")\n",
    "\n",
    "        # 4. DoD readiness\n",
    "        dod = _safe_load(\"dod_metrics\")\n",
    "        if not dod.empty:\n",
    "            dod['month'] = pd.to_datetime(dod['month'])\n",
    "            latest_dod = dod.sort_values('month').iloc[-1]\n",
    "            lines += [\n",
    "                \"4. DoD READINESS\",\n",
    "                f\"   Days of Supply:  {latest_dod.get('days_of_supply_proxy', 'N/A'):.0f}  (target: 60+)\",\n",
    "                f\"   NMCS Risk:       {latest_dod.get('nmcs_risk_indicator', 'N/A')}\",\n",
    "                \"\",\n",
    "            ]\n",
    "\n",
    "        # 5. Supply chain pressure\n",
    "        gscpi = _safe_load(\"gscpi\")\n",
    "        if not gscpi.empty:\n",
    "            if 'as_of_date' in gscpi.columns:\n",
    "                gscpi['as_of_date'] = pd.to_datetime(gscpi['as_of_date'])\n",
    "                gscpi = gscpi.sort_values('as_of_date')\n",
    "            gscpi_val = float(gscpi.tail(1).iloc[0].get('value', 0))\n",
    "            gscpi_level = \"Elevated\" if gscpi_val > 1 else \"Normal\" if gscpi_val > -1 else \"Low\"\n",
    "            lines += [\n",
    "                \"5. GLOBAL SUPPLY CHAIN PRESSURE\",\n",
    "                f\"   NY Fed GSCPI:    {gscpi_val:.2f}  ({gscpi_level})\",\n",
    "                \"\",\n",
    "            ]\n",
    "\n",
    "        # 6. Key actions\n",
    "        lines.append(\"6. RECOMMENDED ACTIONS\")\n",
    "        actions = []\n",
    "        if not demand.empty:\n",
    "            latest_risks = demand.iloc[-1]\n",
    "            if float(latest_risks.get('geo_risk_index', 0) or 0) > 7:\n",
    "                actions.append(\"Increase safety stock -- elevated geopolitical risk\")\n",
    "            if float(latest_risks.get('tariff_risk_index', 0) or 0) > 7:\n",
    "                actions.append(\"Review tariff exposure and diversify sourcing\")\n",
    "            if float(latest_risks.get('commodity_cost_pressure', 0) or 0) > 7:\n",
    "                actions.append(\"Lock in commodity contracts at current prices\")\n",
    "        if not dod.empty and str(latest_dod.get('nmcs_risk_indicator', '')) == 'HIGH_RISK':\n",
    "            actions.append(\"Address NMCS risk -- expedite critical part orders\")\n",
    "        if not actions:\n",
    "            actions.append(\"No urgent actions. Continue standard operations.\")\n",
    "        for a in actions:\n",
    "            lines.append(f\"   - {a}\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error generating briefing: {e}\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Agent Assembly\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Register all tools \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "all_tools = [\n",
    "    # Forecasting\n",
    "    get_demand_forecast,\n",
    "    compare_forecast_models,\n",
    "    assess_forecast_confidence,\n",
    "    # Analysis\n",
    "    detect_anomalies,\n",
    "    detect_trends,\n",
    "    explain_demand_drivers,\n",
    "    # Scenarios\n",
    "    scenario_geopolitical_risk,\n",
    "    scenario_tariff_increase,\n",
    "    scenario_weather_disruption,\n",
    "    build_whatif_scenario,\n",
    "    # Intelligence\n",
    "    query_suppliers,\n",
    "    search_contracts,\n",
    "    compare_dod_metrics,\n",
    "    get_commodity_prices,\n",
    "    get_macro_context,\n",
    "    # Dashboard\n",
    "    get_supply_chain_health,\n",
    "    generate_executive_briefing,\n",
    "]\n",
    "\n",
    "print(f\"Registered {len(all_tools)} tools:\")\n",
    "for t in all_tools:\n",
    "    print(f\"  - {t.name}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a senior supply chain intelligence analyst for Oshkosh Defense, a major U.S. defense contractor producing tactical and armored vehicles (JLTV, FHTV, FMTV, M-ATV). You have deep expertise in:\n",
    "\n",
    "- DoD acquisition lifecycle (RO, AAO, NMCS, Days of Supply)\n",
    "- Defense supply chain risk management (geopolitical, tariff, weather, commodity)\n",
    "- Federal procurement (FAR, DFARS, USAspending, FPDS, SAM.gov)\n",
    "- Demand forecasting (Prophet, ARIMA, Random Forest, ensemble methods)\n",
    "- Material cost dynamics (steel, aluminum, lithium, rare earths)\n",
    "\n",
    "You have access to 17 specialized tools that query live pipeline data from Unity Catalog tables covering:\n",
    "- Prime award and subaward contract data from USAspending/FPDS\n",
    "- SAM.gov defense supplier base (geolocation, size, NAICS, subsystem)\n",
    "- Trade/tariff risk events from the Federal Register\n",
    "- Commodity prices from Yahoo Finance\n",
    "- Weather disruption indices from Meteostat\n",
    "- World Bank WDI/WGI macroeconomic indicators\n",
    "- NY Fed Global Supply Chain Pressure Index\n",
    "- WTO Goods Trade Barometer\n",
    "- Prophet, ARIMA, and Random Forest demand forecasts\n",
    "- DoD metrics (Requirements Objective, Days of Supply, NMCS Risk)\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "1. Always use tools to fetch real data -- never fabricate numbers\n",
    "2. When asked about suppliers, contracts, or specific data, use the appropriate search tool\n",
    "3. Provide actionable insights, not just raw data\n",
    "4. Reference DoD terminology and metrics where relevant\n",
    "5. Quantify impacts in dollars and percentages when possible\n",
    "6. For complex questions, use multiple tools to build a comprehensive answer\n",
    "7. If a tool returns no data, explain what pipeline step needs to run\n",
    "8. When comparing scenarios, be explicit about assumptions\n",
    "9. Flag high-risk situations prominently with recommended actions\n",
    "10. Tailor detail level to the question -- executive summary for broad questions, deep dive for specific ones\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent with Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Conversation memory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "conversation_history = []\n",
    "\n",
    "def _get_history():\n",
    "    \"\"\"Return the last N turns of conversation for context.\"\"\"\n",
    "    max_turns = 10\n",
    "    return conversation_history[-(max_turns * 2):]\n",
    "\n",
    "# \u2500\u2500 Build agent \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_PROMPT),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "if _create_tool_calling_agent is not None and _AgentExecutor is not None:\n",
    "    agent = _create_tool_calling_agent(llm, all_tools, prompt)\n",
    "    agent_executor = _AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=all_tools,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "        max_iterations=10,\n",
    "    )\n",
    "    print(f\"Agent ready: {len(all_tools)} tools, AgentExecutor, conversation memory\")\n",
    "else:\n",
    "    # Fallback executor with memory support\n",
    "    _tools_by_name = {t.name: t for t in all_tools}\n",
    "    class _MemoryToolCallingExecutor:\n",
    "        def __init__(self, llm, tools, verbose=True):\n",
    "            self.llm = llm\n",
    "            self.tools = tools\n",
    "            self.verbose = verbose\n",
    "\n",
    "        def invoke(self, inputs):\n",
    "            user_input = inputs.get(\"input\", \"\")\n",
    "            chat_history = inputs.get(\"chat_history\", [])\n",
    "\n",
    "            messages = [SystemMessage(content=SYSTEM_PROMPT)]\n",
    "            messages.extend(chat_history)\n",
    "            messages.append(HumanMessage(content=user_input))\n",
    "\n",
    "            max_rounds = 10\n",
    "            for _ in range(max_rounds):\n",
    "                response = self.llm.bind_tools(self.tools).invoke(messages)\n",
    "                if self.verbose and response.content:\n",
    "                    print(response.content[:300], \"...\" if len(response.content) > 300 else \"\")\n",
    "                if not getattr(response, \"tool_calls\", None):\n",
    "                    return {\"output\": response.content or \"\"}\n",
    "\n",
    "                messages.append(response)\n",
    "                for tc in response.tool_calls:\n",
    "                    name = tc.get(\"name\", None) if isinstance(tc, dict) else getattr(tc, \"name\", None)\n",
    "                    args = tc.get(\"args\", {}) if isinstance(tc, dict) else getattr(tc, \"args\", {}) or {}\n",
    "                    tid = tc.get(\"id\", \"\") if isinstance(tc, dict) else getattr(tc, \"id\", \"\")\n",
    "                    found_tool = _tools_by_name.get(name)\n",
    "                    if found_tool:\n",
    "                        if self.verbose:\n",
    "                            print(f\"  [tool] {name}({args})\")\n",
    "                        result = found_tool.invoke(args)\n",
    "                        messages.append(ToolMessage(content=str(result), tool_call_id=tid))\n",
    "\n",
    "            return {\"output\": (response.content or \"\") + \"\\n[Max rounds reached.]\"}\n",
    "\n",
    "    agent_executor = _MemoryToolCallingExecutor(llm, all_tools, verbose=True)\n",
    "    print(f\"Agent ready: {len(all_tools)} tools, bind_tools fallback, conversation memory\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: ask()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def ask(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a question to the agent with conversation memory.\n",
    "    \n",
    "    Usage:\n",
    "        answer = ask(\"What is the demand forecast for next quarter?\")\n",
    "        print(answer)\n",
    "    \"\"\"\n",
    "    # Add user message to history\n",
    "    conversation_history.append(HumanMessage(content=question))\n",
    "\n",
    "    # Run agent\n",
    "    response = agent_executor.invoke({\n",
    "        \"input\": question,\n",
    "        \"chat_history\": _get_history()[:-1],  # exclude current question (already in input)\n",
    "    })\n",
    "\n",
    "    answer = response[\"output\"]\n",
    "\n",
    "    # Add assistant response to history\n",
    "    conversation_history.append(AIMessage(content=answer))\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "def reset_memory():\n",
    "    \"\"\"Clear conversation history.\"\"\"\n",
    "    conversation_history.clear()\n",
    "    print(\"Conversation memory cleared.\")\n",
    "\n",
    "\n",
    "print(\"Use ask('your question') to chat with the agent.\")\n",
    "print(\"Use reset_memory() to start a new conversation.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Interactive Chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Queries\n",
    "\n",
    "Run any of the cells below, or type your own question in a new cell:\n",
    "```python\n",
    "print(ask(\"your question here\"))\n",
    "```\n",
    "\n",
    "**Sample questions:**\n",
    "- \"Give me an executive briefing on the supply chain\"\n",
    "- \"What is the demand forecast for next quarter?\"\n",
    "- \"Show me suppliers in Wisconsin\"\n",
    "- \"Search for contracts with PSC code 23\"\n",
    "- \"What are the top demand drivers?\"\n",
    "- \"How is global supply chain pressure trending?\"\n",
    "- \"What if geopolitical risk increases 50% and tariffs go up 25%?\"\n",
    "- \"Generate a full supply chain health dashboard\"\n",
    "- \"Compare Prophet vs ARIMA vs Random Forest forecasts\"\n",
    "- \"How confident should we be in the 3-month forecast?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 1: Executive briefing\n",
    "print(ask(\"Give me a concise executive briefing on the current state of our supply chain.\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 2: Supplier search (multi-turn)\n",
    "print(ask(\"Show me our defense suppliers in Wisconsin and Texas. How many are small businesses?\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 3: Follow-up with memory\n",
    "print(ask(\"Based on those suppliers, which subsystem categories have the least diversification?\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 4: Multi-tool scenario\n",
    "print(ask(\"What if geopolitical risk spikes 75%, tariffs rise 30%, and steel prices jump 20%? What's the combined impact and what should we do?\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 5: Health dashboard\n",
    "print(ask(\"Generate a supply chain health dashboard and highlight anything below 50%.\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tool Reference\n",
    "\n",
    "| # | Tool | Category | Description |\n",
    "|---|------|----------|-------------|\n",
    "| 1 | `get_demand_forecast` | Forecasting | Retrieve demand forecast with confidence intervals |\n",
    "| 2 | `compare_forecast_models` | Forecasting | Compare Prophet, ARIMA, and Random Forest side-by-side |\n",
    "| 3 | `assess_forecast_confidence` | Forecasting | Score forecast reliability (0-100) |\n",
    "| 4 | `detect_anomalies` | Analysis | Find demand anomalies vs historical baseline |\n",
    "| 5 | `detect_trends` | Analysis | Detect growth, seasonality, volatility, correlations |\n",
    "| 6 | `explain_demand_drivers` | Analysis | Feature importance from Random Forest model |\n",
    "| 7 | `scenario_geopolitical_risk` | Scenarios | Model geopolitical risk impact on demand |\n",
    "| 8 | `scenario_tariff_increase` | Scenarios | Analyze tariff cost impact |\n",
    "| 9 | `scenario_weather_disruption` | Scenarios | Model weather disruption scenarios |\n",
    "| 10 | `build_whatif_scenario` | Scenarios | Custom multi-factor what-if builder |\n",
    "| 11 | `query_suppliers` | Intelligence | Search SAM.gov supplier base |\n",
    "| 12 | `search_contracts` | Intelligence | Search FPDS contract data |\n",
    "| 13 | `compare_dod_metrics` | Intelligence | Check DoD supply chain metrics (RO, AAO, NMCS) |\n",
    "| 14 | `get_commodity_prices` | Intelligence | Monitor defense-critical material prices |\n",
    "| 15 | `get_macro_context` | Intelligence | World Bank, NY Fed GSCPI, WTO indicators |\n",
    "| 16 | `get_supply_chain_health` | Dashboard | Holistic health score across 6 dimensions |\n",
    "| 17 | `generate_executive_briefing` | Dashboard | One-page exec briefing with actions |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Deploy as Model Serving endpoint** \u2014 register the agent with MLflow and serve via Databricks Model Serving for API access\n",
    "2. **Connect to Databricks Genie** \u2014 enable natural language queries over the gold tables\n",
    "3. **Add Slack/Teams integration** \u2014 pipe `ask()` through a webhook for chat-based supply chain queries\n",
    "4. **Schedule executive briefings** \u2014 run `generate_executive_briefing` on a daily/weekly Databricks Job\n",
    "5. **Add alerting** \u2014 trigger notifications when `get_supply_chain_health` detects scores below threshold\n"
   ]
  }
 ]
}