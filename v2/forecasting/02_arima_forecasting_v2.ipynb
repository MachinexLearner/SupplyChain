{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Demand Forecasting with MLflow\n",
    "\n",
    "**Executive summary:** Trains SARIMAX demand forecast with auto-ARIMA and exogenous variables; logs to MLflow and writes gold forecasts. Management: alternative to Prophet for comparison; use for demand planning.\n",
    "\n",
    "**Depends on:** `supply_chain.gold.oshkosh_monthly_demand_signals` (run transformation notebooks first).\n",
    "\n",
    "This notebook implements demand forecasting using ARIMA/SARIMAX models with:\n",
    "- Automatic parameter selection (auto-ARIMA)\n",
    "- Seasonal components for fiscal year patterns\n",
    "- Exogenous variables support\n",
    "- MLflow experiment tracking\n",
    "\n",
    "**Model**: SARIMAX (Seasonal ARIMA with eXogenous variables)\n",
    "**Target**: Monthly demand obligations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages. Use NumPy 1.x (>=1.26.4,<2) for numpy.exceptions and compatibility with pmdarima/statsmodels.\n",
    "# After this runs: if you see \"Core Python package version(s) changed\" or \"Failed to set environment metadata\",\n",
    "# detach and re-attach the notebook to the cluster (or restart the cluster) then run the notebook again.\n",
    "%pip install \"numpy>=1.26.4,<2\" \"pandas>=2.0,<3\" pmdarima statsmodels mlflow scikit-learn matplotlib\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Restart Python so the installed NumPy is loaded (required for numpy.exceptions / pmdarima).\n",
    "try:\n",
    "    import numpy as _np\n",
    "    _v = tuple(int(x) for x in getattr(_np, \"__version__\", \"0.0\").split(\".\")[:2])\n",
    "    if _v < (1, 26) or _v >= (2, 0) or not hasattr(_np, \"exceptions\"):\n",
    "        dbutils.library.restartPython()\n",
    "except Exception:\n",
    "    dbutils.library.restartPython()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pmdarima as pm\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql import functions as F\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configuration - Unity Catalog\n",
    "CATALOG = \"supply_chain\"\n",
    "DEMAND_SIGNALS_TABLE = f\"{CATALOG}.gold.oshkosh_monthly_demand_signals\"\n",
    "FORECAST_OUTPUT_TABLE = f\"{CATALOG}.gold.arima_forecasts\"\n",
    "# When DBFS root is disabled, use a workspace path (e.g. /Workspace/Users/<you>/models/arima_demand_forecast)\n",
    "MODEL_PATH = \"/models/arima_demand_forecast\"\n",
    "\n",
    "# MLflow configuration\n",
    "EXPERIMENT_NAME = \"/Shared/supply_chain_platform/experiments/demand_forecasting\"\n",
    "\n",
    "# Forecast parameters\n",
    "FORECAST_HORIZON_MONTHS = 12\n",
    "TEST_SIZE_MONTHS = 12  # Hold out last 12 months for testing\n",
    "\n",
    "# ARIMA parameters\n",
    "SEASONAL_PERIOD = 12  # Monthly data with yearly seasonality\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set up MLflow experiment\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"MLflow experiment: {EXPERIMENT_NAME}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load demand signals (Unity Catalog). Use SQL to avoid \"Path must be absolute\" when table name is mistaken for a path.\n",
    "try:\n",
    "    demand_spark = spark.sql(f\"SELECT * FROM {DEMAND_SIGNALS_TABLE}\")\n",
    "    demand_df = demand_spark.toPandas()\n",
    "    print(f\"Loaded {len(demand_df)} demand signal records\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading demand signals: {e}\")\n",
    "    demand_df = None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Prepare data for ARIMA\n",
    "    arima_df = demand_df[['month', 'total_obligations_usd', \n",
    "                          'geo_risk_index', 'tariff_risk_index',\n",
    "                          'commodity_cost_pressure', 'weather_disruption_index']].copy()\n",
    "    \n",
    "    arima_df['month'] = pd.to_datetime(arima_df['month'])\n",
    "    arima_df = arima_df.sort_values('month')\n",
    "    arima_df = arima_df.set_index('month')\n",
    "    \n",
    "    # Remove rows with zero demand\n",
    "    arima_df = arima_df[arima_df['total_obligations_usd'] > 0]\n",
    "    \n",
    "    print(f\"Prepared {len(arima_df)} records for ARIMA\")\n",
    "    print(f\"Date range: {arima_df.index.min()} to {arima_df.index.max()}\")\n",
    "    print(arima_df.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Split data\n",
    "    train_size = len(arima_df) - TEST_SIZE_MONTHS\n",
    "    \n",
    "    train_df = arima_df.iloc[:train_size]\n",
    "    test_df = arima_df.iloc[train_size:]\n",
    "    \n",
    "    # Target variable\n",
    "    y_train = train_df['total_obligations_usd']\n",
    "    y_test = test_df['total_obligations_usd']\n",
    "    \n",
    "    # Exogenous variables\n",
    "    exog_cols = ['geo_risk_index', 'tariff_risk_index', 'commodity_cost_pressure', 'weather_disruption_index']\n",
    "    X_train = train_df[exog_cols]\n",
    "    X_test = test_df[exog_cols]\n",
    "    \n",
    "    print(f\"Training set: {len(train_df)} records ({train_df.index.min()} to {train_df.index.max()})\")\n",
    "    print(f\"Test set: {len(test_df)} records ({test_df.index.min()} to {test_df.index.max()})\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-ARIMA Parameter Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    print(\"Running auto-ARIMA to find optimal parameters...\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"arima_demand_forecast\"):\n",
    "        # Auto-ARIMA to find best parameters\n",
    "        auto_model = auto_arima(\n",
    "            y_train,\n",
    "            X=X_train,\n",
    "            seasonal=True,\n",
    "            m=SEASONAL_PERIOD,  # Monthly seasonality\n",
    "            start_p=0, start_q=0,\n",
    "            max_p=3, max_q=3,\n",
    "            start_P=0, start_Q=0,\n",
    "            max_P=2, max_Q=2,\n",
    "            d=None,  # Auto-detect differencing\n",
    "            D=None,  # Auto-detect seasonal differencing\n",
    "            trace=True,\n",
    "            error_action='ignore',\n",
    "            suppress_warnings=True,\n",
    "            stepwise=True,\n",
    "            information_criterion='aic'\n",
    "        )\n",
    "        \n",
    "        # Get best parameters\n",
    "        order = auto_model.order\n",
    "        seasonal_order = auto_model.seasonal_order\n",
    "        \n",
    "        print(f\"\\nBest ARIMA order: {order}\")\n",
    "        print(f\"Best seasonal order: {seasonal_order}\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"arima_order\", str(order))\n",
    "        mlflow.log_param(\"seasonal_order\", str(seasonal_order))\n",
    "        mlflow.log_param(\"seasonal_period\", SEASONAL_PERIOD)\n",
    "        mlflow.log_param(\"training_samples\", len(y_train))\n",
    "        mlflow.log_param(\"exogenous_variables\", str(exog_cols))\n",
    "        \n",
    "        # Get run ID\n",
    "        run_id = mlflow.active_run().info.run_id\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SARIMAX Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Train SARIMAX model with optimal parameters\n",
    "    print(\"Training SARIMAX model...\")\n",
    "    \n",
    "    sarimax_model = SARIMAX(\n",
    "        y_train,\n",
    "        exog=X_train,\n",
    "        order=order,\n",
    "        seasonal_order=seasonal_order,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    \n",
    "    sarimax_results = sarimax_model.fit(disp=False)\n",
    "    \n",
    "    print(\"\\n=== Model Summary ===\")\n",
    "    print(sarimax_results.summary())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # In-sample predictions (fitted values)\n",
    "    fitted_values = sarimax_results.fittedvalues\n",
    "    \n",
    "    # Out-of-sample forecast for test period\n",
    "    forecast_test = sarimax_results.get_forecast(\n",
    "        steps=len(test_df),\n",
    "        exog=X_test\n",
    "    )\n",
    "    \n",
    "    forecast_mean = forecast_test.predicted_mean\n",
    "    forecast_ci = forecast_test.conf_int(alpha=0.05)\n",
    "    \n",
    "    print(\"Test Period Forecast:\")\n",
    "    forecast_results = pd.DataFrame({\n",
    "        'actual': y_test,\n",
    "        'forecast': forecast_mean,\n",
    "        'lower_ci': forecast_ci.iloc[:, 0],\n",
    "        'upper_ci': forecast_ci.iloc[:, 1]\n",
    "    })\n",
    "    print(forecast_results)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, forecast_mean)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, forecast_mean))\n",
    "    mape = mean_absolute_percentage_error(y_test, forecast_mean)\n",
    "    \n",
    "    # Calculate coverage (% of actuals within confidence interval)\n",
    "    coverage = np.mean(\n",
    "        (y_test >= forecast_ci.iloc[:, 0]) & \n",
    "        (y_test <= forecast_ci.iloc[:, 1])\n",
    "    )\n",
    "    \n",
    "    print(\"=== Model Evaluation Metrics ===\")\n",
    "    print(f\"MAE: {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"MAPE: {mape:.2%}\")\n",
    "    print(f\"Coverage (95% CI): {coverage:.2%}\")\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"test_mae\", mae)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_mape\", mape)\n",
    "    mlflow.log_metric(\"test_coverage\", coverage)\n",
    "    mlflow.log_metric(\"aic\", sarimax_results.aic)\n",
    "    mlflow.log_metric(\"bic\", sarimax_results.bic)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Plot actual vs forecast\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Full time series with forecast\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(y_train.index, y_train, label='Training Data', color='blue')\n",
    "    ax1.plot(y_test.index, y_test, label='Actual (Test)', color='green')\n",
    "    ax1.plot(forecast_mean.index, forecast_mean, label='Forecast', color='red', linestyle='--')\n",
    "    ax1.fill_between(\n",
    "        forecast_ci.index,\n",
    "        forecast_ci.iloc[:, 0],\n",
    "        forecast_ci.iloc[:, 1],\n",
    "        color='red', alpha=0.2, label='95% CI'\n",
    "    )\n",
    "    ax1.set_title('SARIMAX Demand Forecast')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Monthly Obligations (USD)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Test period detail\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(y_test.index, y_test, 'go-', label='Actual', markersize=8)\n",
    "    ax2.plot(forecast_mean.index, forecast_mean, 'r^--', label='Forecast', markersize=8)\n",
    "    ax2.fill_between(\n",
    "        forecast_ci.index,\n",
    "        forecast_ci.iloc[:, 0],\n",
    "        forecast_ci.iloc[:, 1],\n",
    "        color='red', alpha=0.2\n",
    "    )\n",
    "    ax2.set_title('Test Period: Actual vs Forecast')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Monthly Obligations (USD)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/tmp/arima_forecast_plot.png', dpi=150, bbox_inches='tight')\n",
    "    mlflow.log_artifact('/tmp/arima_forecast_plot.png')\n",
    "    \n",
    "    display(fig)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Residual diagnostics\n",
    "    fig2 = sarimax_results.plot_diagnostics(figsize=(14, 10))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/tmp/arima_diagnostics.png', dpi=150, bbox_inches='tight')\n",
    "    mlflow.log_artifact('/tmp/arima_diagnostics.png')\n",
    "    \n",
    "    display(fig2)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Future Forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Create future exogenous variables (use last known values)\n",
    "    last_exog = X_test.iloc[-1]\n",
    "    \n",
    "    future_exog = pd.DataFrame(\n",
    "        [last_exog.values] * FORECAST_HORIZON_MONTHS,\n",
    "        columns=exog_cols,\n",
    "        index=pd.date_range(\n",
    "            start=arima_df.index[-1] + pd.DateOffset(months=1),\n",
    "            periods=FORECAST_HORIZON_MONTHS,\n",
    "            freq='M'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Generate future forecast\n",
    "    future_forecast = sarimax_results.get_forecast(\n",
    "        steps=FORECAST_HORIZON_MONTHS,\n",
    "        exog=future_exog\n",
    "    )\n",
    "    \n",
    "    future_mean = future_forecast.predicted_mean\n",
    "    future_ci = future_forecast.conf_int(alpha=0.05)\n",
    "    \n",
    "    print(\"=== Future Forecast (Next 12 Months) ===\")\n",
    "    future_results = pd.DataFrame({\n",
    "        'forecast': future_mean,\n",
    "        'lower_ci': future_ci.iloc[:, 0],\n",
    "        'upper_ci': future_ci.iloc[:, 1]\n",
    "    })\n",
    "    print(future_results)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Forecast Results\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    # Combine historical fitted values and future forecast\n",
    "    all_forecasts = pd.DataFrame({\n",
    "        'month': list(fitted_values.index) + list(forecast_mean.index) + list(future_mean.index),\n",
    "        'forecast_demand_usd': list(fitted_values.values) + list(forecast_mean.values) + list(future_mean.values),\n",
    "        'is_forecast': [False] * len(fitted_values) + [True] * (len(forecast_mean) + len(future_mean))\n",
    "    })\n",
    "    \n",
    "    # Add confidence intervals for forecast periods\n",
    "    all_forecasts['forecast_lower'] = None\n",
    "    all_forecasts['forecast_upper'] = None\n",
    "    \n",
    "    # Add metadata\n",
    "    all_forecasts['model_type'] = 'SARIMAX'\n",
    "    all_forecasts['arima_order'] = str(order)\n",
    "    all_forecasts['seasonal_order'] = str(seasonal_order)\n",
    "    all_forecasts['model_run_id'] = run_id\n",
    "    all_forecasts['forecast_generated_at'] = datetime.now()\n",
    "    \n",
    "    # Convert to Spark and save (Unity Catalog)\n",
    "    forecast_spark = spark.createDataFrame(all_forecasts)\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.gold\")\n",
    "    forecast_spark.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(FORECAST_OUTPUT_TABLE)\n",
    "    \n",
    "    print(f\"Saved {len(all_forecasts)} forecast records to {FORECAST_OUTPUT_TABLE}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if demand_df is not None:\n",
    "    print(\"=== ARIMA/SARIMAX Model Summary ===\")\n",
    "    print(f\"\\nModel Configuration:\")\n",
    "    print(f\"  - ARIMA Order (p,d,q): {order}\")\n",
    "    print(f\"  - Seasonal Order (P,D,Q,s): {seasonal_order}\")\n",
    "    print(f\"  - Exogenous Variables: {exog_cols}\")\n",
    "    \n",
    "    print(f\"\\nTraining Data:\")\n",
    "    print(f\"  - Records: {len(y_train)}\")\n",
    "    print(f\"  - Date Range: {y_train.index.min().date()} to {y_train.index.max().date()}\")\n",
    "    \n",
    "    print(f\"\\nTest Performance:\")\n",
    "    print(f\"  - MAE: {mae:,.2f}\")\n",
    "    print(f\"  - RMSE: {rmse:,.2f}\")\n",
    "    print(f\"  - MAPE: {mape:.2%}\")\n",
    "    print(f\"  - Coverage: {coverage:.2%}\")\n",
    "    \n",
    "    print(f\"\\nModel Fit Statistics:\")\n",
    "    print(f\"  - AIC: {sarimax_results.aic:.2f}\")\n",
    "    print(f\"  - BIC: {sarimax_results.bic:.2f}\")\n",
    "    \n",
    "    print(f\"\\nMLflow Run ID: {run_id}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Table\n",
    "Forecasts are written to Unity Catalog by saveAsTable(FORECAST_OUTPUT_TABLE) above.\n",
    "No manual registration needed. If DBFS root is disabled, do not use CREATE TABLE ... LOCATION '/path'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run `03_model_comparison` to compare Prophet vs ARIMA\n",
    "2. Proceed to agent tools notebooks\n"
   ]
  }
 ]
}